---
title: Dealing with missing values
author: Michael Fuchs
date: '2019-03-18'
slug: dealing-with-missing-values
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries-and-the-data">2 Loading the Libraries and the Data</a></li>
<li><a href="#checking-for-missing-values">3 Checking for missing values</a></li>
<li><a href="#droping-of-missing-values">4 Droping of Missing Values</a></li>
<li><a href="#imputations">5 Imputations</a>
<ul>
<li><a href="#for-numeric-features">5.1 for <strong>NUMERIC</strong> Features</a>
<ul>
<li><a href="#replace-np.nan-with-specific-values">5.1.1 Replace np.NaN with specific values</a></li>
<li><a href="#replace-np.nan-with-mean">5.1.2 Replace np.NaN with MEAN</a></li>
<li><a href="#replace-np.nan-with-median">5.1.3 Replace np.NaN with MEDIAN</a></li>
<li><a href="#replace-np.nan-with-most_frequent">5.1.4 Replace np.NaN with most_frequent</a></li>
</ul></li>
<li><a href="#for-categorical-features">5.2 for <strong>CATEGORICAL</strong> Features</a>
<ul>
<li><a href="#replace-np.nan-with-most_frequent-1">5.2.1 Replace np.NaN with most_frequent</a></li>
<li><a href="#replace-np.nan-with-specific-values-1">5.2.2 Replace np.NaN with specific values</a></li>
</ul></li>
<li><a href="#for-specific-values">5.3 for specific Values</a>
<ul>
<li><a href="#single-values">5.3.1 single values</a></li>
<li><a href="#multiple-values">5.3.2 multiple values</a></li>
</ul></li>
</ul></li>
<li><a href="#further-imputation-methods">6 Further Imputation Methods</a>
<ul>
<li><a href="#with-ffill">6.1 with ffill</a></li>
<li><a href="#with-backfill">6.2 with backfill</a></li>
<li><a href="#note-on-this-chapter">6.3 Note on this Chapter</a></li>
</ul></li>
<li><a href="#knnimputer">7 KNNImputer</a>
<ul>
<li><a href="#on-single-columns">7.1 on single columns</a></li>
<li><a href="#on-multiple-columns">7.2 on multiple columns</a></li>
<li><a href="#note-on-this-chapter-1">7.3 Note on this Chapter</a></li>
</ul></li>
<li><a href="#imputation-in-practice">8 Imputation in Practice</a>
<ul>
<li><a href="#simpleimputer-in-practice">8.1 SimpleImputer in Practice</a>
<ul>
<li><a href="#train-test-split">8.1.1 Train-Test Split</a></li>
<li><a href="#fittransform-trainx">8.1.2 Fit&amp;Transform (trainX)</a></li>
<li><a href="#model-training">8.1.3 Model Training</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>In the real world, there is virtually no record that has no missing values. Dealing with missing values can be done differently. In the following several methods will be presented how to deal with them.</p>
</div>
<div id="loading-the-libraries-and-the-data" class="section level1">
<h1>2 Loading the Libraries and the Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

from sklearn.impute import KNNImputer

from sklearn.model_selection import train_test_split
import pickle as pk
import random</code></pre>
<pre class="r"><code>df = pd.DataFrame({&#39;Name&#39;: [&#39;Anton&#39;, &#39;Moni&#39;, np.NaN, &#39;Renate&#39;, &#39;Justus&#39;],
                   &#39;Age&#39;: [32,22,62,np.NaN,18],
                   &#39;Salary&#39;: [np.NaN, np.NaN,4500,2500,3800],
                   &#39;Job&#39;: [&#39;Student&#39;, np.NaN, &#39;Manager&#39;, &#39;Teacher&#39;, &#39;Student&#39;]})
df</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p1.png" /></p>
</div>
<div id="checking-for-missing-values" class="section level1">
<h1>3 Checking for missing values</h1>
<pre class="r"><code>df.isnull().sum()</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p2.png" /></p>
<pre class="r"><code>def mv_overview_func(df):
    &#39;&#39;&#39;
    Gives an overview of the total number and percentage of missing values in a data set
    
    Args:
        df (DataFrame): Dataframe to which the function is to be applied
        
    Returns:
        Overview of the total number and percentage of missing values
    &#39;&#39;&#39;
    # Total missing values
    mis_val = df.isnull().sum()
    # Percentage of missing values
    mis_val_percent = 100 * df.isnull().sum() / len(df)
    # Data Types
    data_types = df.dtypes
    # Make a table with the results
    mis_val_table = pd.concat([mis_val, mis_val_percent, data_types], axis=1)
    # Rename the columns
    mis_val_table_ren_columns = mis_val_table.rename(
    columns = {0 : &#39;Missing Values&#39;, 1 : &#39;% of Total Values&#39;, 2 : &#39;Data Type&#39;})
    # Sort the table by percentage of missing descending
    mis_val_table_ren_columns = mis_val_table_ren_columns[
        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        &#39;% of Total Values&#39;, ascending=False).round(1)
    # Print some summary information
    print (&quot;Your selected dataframe has &quot; + str(df.shape[1]) + &quot; columns.\n&quot;      
            &quot;There are &quot; + str(mis_val_table_ren_columns.shape[0]) +
            &quot; columns that have missing values.&quot;)
    # Return the dataframe with missing information
    return mis_val_table_ren_columns</code></pre>
<pre class="r"><code>mv_overview_func(df)</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p3.png" /></p>
</div>
<div id="droping-of-missing-values" class="section level1">
<h1>4 Droping of Missing Values</h1>
<pre class="r"><code>df_drop = df.copy()
df_drop</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p4.png" /></p>
<p>All rows with minimum one NaN will be dropped:</p>
<pre class="r"><code>df_drop.dropna()</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p5.png" /></p>
<p>All rows from the defined columns with a NaN will be dropped:</p>
<pre class="r"><code>df_drop.dropna(subset=[&#39;Name&#39;, &#39;Age&#39;])</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p6.png" /></p>
</div>
<div id="imputations" class="section level1">
<h1>5 Imputations</h1>
<div id="for-numeric-features" class="section level2">
<h2>5.1 for <strong>NUMERIC</strong> Features</h2>
<div id="replace-np.nan-with-specific-values" class="section level3">
<h3>5.1.1 Replace np.NaN with specific values</h3>
<pre class="r"><code>df_replace_1 = df.copy()
df_replace_1</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p7.png" /></p>
<p>Missing values from only one column (here ‘Name’) are replaced:</p>
<pre class="r"><code>df_replace_1[&#39;Name&#39;] = df_replace_1[&#39;Name&#39;].fillna(0)
df_replace_1</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p8.png" /></p>
<p>Missing values from the complete dataset will be replaced:</p>
<pre class="r"><code>df_replace_1.fillna(0, inplace=True)
df_replace_1</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p9.png" /></p>
<p>Does that make sense? Probably not. So let’s look at imputations that follow a certain logic.</p>
</div>
<div id="replace-np.nan-with-mean" class="section level3">
<h3>5.1.2 Replace np.NaN with MEAN</h3>
<p>A popular metric for replacing missing values is the use of mean.</p>
<pre class="r"><code>df_replace_2 = df.copy()
df_replace_2</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p10.png" /></p>
<pre class="r"><code>df_replace_2[&#39;Age&#39;].mean()</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p11.png" /></p>
<p>Here all missing values of the column ‘Age’ are replaced by their mean value.</p>
<pre class="r"><code>df_replace_2[&#39;Age&#39;] = df_replace_2[&#39;Age&#39;].fillna(df_replace_2[&#39;Age&#39;].mean())
df_replace_2</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p12.png" /></p>
<p><strong>scikit-learn - SimpleImputer</strong></p>
<p>Always keep in mind that you will need all the steps you take to prepare for model training to make predictions later.</p>
<p>What do I mean by that exactly?
If the data set you have available for model training already has missing values, it is quite possible that future data sets for which predictions are to be made will also contain missing values.
In order for the prediction model to work, these missing values must be replaced by metrics that were also used in the model training.</p>
<pre class="r"><code>df_replace_3 = df.copy()
df_replace_3</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p13.png" /></p>
<pre class="r"><code>imp_age_mean = SimpleImputer(missing_values=np.nan, strategy=&#39;mean&#39;)

imp_age_mean.fit(df_replace_3[[&#39;Age&#39;]])
df_replace_3[&#39;Age&#39;] = imp_age_mean.transform(df_replace_3[[&#39;Age&#39;]])
df_replace_3</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p14.png" /></p>
<p>In the steps shown before, I used the .fit and .transform functions separately. If it’s not about model training, you can also combine these two steps and save yourself another line of code.</p>
<pre class="r"><code>df_replace_4 = df.copy()
df_replace_4</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p15.png" /></p>
<pre class="r"><code>imp_age_mean = SimpleImputer(missing_values=np.nan, strategy=&#39;mean&#39;)

df_replace_4[&#39;Age&#39;] = imp_age_mean.fit_transform(df_replace_4[[&#39;Age&#39;]])
df_replace_4</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p16.png" /></p>
<p>This way you can see which value is behind imp_age_mean concretely:</p>
<pre class="r"><code> imp_age_mean.statistics_</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p17.png" /></p>
</div>
<div id="replace-np.nan-with-median" class="section level3">
<h3>5.1.3 Replace np.NaN with MEDIAN</h3>
<p>Other metrics such as the median can also be used instead of missing values:</p>
<pre class="r"><code>df_replace_5 = df.copy()
df_replace_5</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p18.png" /></p>
<pre class="r"><code>imp_age_median = SimpleImputer(missing_values=np.nan, strategy=&#39;median&#39;)

df_replace_5[&#39;Age&#39;] = imp_age_median.fit_transform(df_replace_5[[&#39;Age&#39;]])
df_replace_5</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p19.png" /></p>
<pre class="r"><code>imp_age_median.statistics_</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p20.png" /></p>
</div>
<div id="replace-np.nan-with-most_frequent" class="section level3">
<h3>5.1.4 Replace np.NaN with most_frequent</h3>
<p>For some variables, it makes sense to use the most frequently occurring value for NaNs instead of mean or median.</p>
<pre class="r"><code>df_replace_6 = df.copy()
df_replace_6</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p21.png" /></p>
<pre class="r"><code>imp_age_mfreq = SimpleImputer(missing_values=np.nan, strategy=&#39;most_frequent&#39;)

df_replace_6[&#39;Age&#39;] = imp_age_mfreq.fit_transform(df_replace_6[[&#39;Age&#39;]])
df_replace_6</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p22.png" /></p>
<p>Since there is no value in the variable ‘Age’ that occurs twice or more often, the lowest value is automatically taken. The same would apply if there were two equally frequent values.</p>
</div>
</div>
<div id="for-categorical-features" class="section level2">
<h2>5.2 for <strong>CATEGORICAL</strong> Features</h2>
<div id="replace-np.nan-with-most_frequent-1" class="section level3">
<h3>5.2.1 Replace np.NaN with most_frequent</h3>
<p>The most_frequent function can be used for numeric variables as well as categorical variables.</p>
<pre class="r"><code>df_replace_7 = df.copy()
df_replace_7</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p23.png" /></p>
<pre class="r"><code>imp_job_mfreq = SimpleImputer(missing_values=np.nan, strategy=&#39;most_frequent&#39;)

df_replace_7[&#39;Job&#39;] = imp_job_mfreq.fit_transform(df_replace_7[[&#39;Job&#39;]])
df_replace_7</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p24.png" /></p>
<p>Here we see that with a frequency of 2, the job ‘student’ is the most common, so this is used for the missing value here.</p>
<pre class="r"><code>imp_job_mfreq.statistics_</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p25.png" /></p>
<p>But what happens if we just don’t have a most frequent value in a categorical column like in our example within the column ‘Name’?</p>
<pre class="r"><code>df_replace_8 = df.copy()
df_replace_8</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p26.png" /></p>
<pre class="r"><code>imp_name_mfreq = SimpleImputer(missing_values=np.nan, strategy=&#39;most_frequent&#39;)

df_replace_8[&#39;Name&#39;] = imp_name_mfreq.fit_transform(df_replace_8[[&#39;Name&#39;]])
df_replace_8</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p27.png" /></p>
<p>Again, the principle that the lowest value is used applies. In our example, this is the name Anton, since it begins with A and thus comes before all other names in the alphabet.</p>
</div>
<div id="replace-np.nan-with-specific-values-1" class="section level3">
<h3>5.2.2 Replace np.NaN with specific values</h3>
<pre class="r"><code>df_replace_9 = df.copy()
df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p28.png" /></p>
<p>However, we also have the option of using certain values:</p>
<pre class="r"><code>imp_job_const = SimpleImputer(missing_values=np.nan, 
                              strategy=&#39;constant&#39;,
                              fill_value=&#39;others&#39;)

df_replace_9[&#39;Job&#39;] = imp_job_const.fit_transform(df_replace_9[[&#39;Job&#39;]])
df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p29.png" /></p>
</div>
</div>
<div id="for-specific-values" class="section level2">
<h2>5.3 for specific Values</h2>
<p>Not only a certain kind of values like NaN values can be replaced, this is also possible with specific values.</p>
<div id="single-values" class="section level3">
<h3>5.3.1 single values</h3>
<p>For the following example we take the last version of the last used data set, here df_replace_9:</p>
<pre class="r"><code>df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p30.png" /></p>
<pre class="r"><code>rep_job_const = SimpleImputer(missing_values=&#39;others&#39;, 
                              strategy=&#39;constant&#39;,
                              fill_value=&#39;not_in_scope&#39;)

df_replace_9[&#39;Job&#39;] = rep_job_const.fit_transform(df_replace_9[[&#39;Job&#39;]])
df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p31.png" /></p>
<p>As we can see, ‘others’ became ‘not_in_scope’.</p>
</div>
<div id="multiple-values" class="section level3">
<h3>5.3.2 multiple values</h3>
<p>Unfortunately, we cannot work with lists for multiple values. But with the use of the pipeline function it works. We use for our following example again the last state of the dataset ‘df_replace_9’:</p>
<pre class="r"><code>rep_pipe = Pipeline([(&#39;si1&#39;,SimpleImputer(missing_values = &#39;Manager&#39;, 
                                          strategy=&#39;constant&#39;,
                                          fill_value=&#39;not_relevant&#39;)),
                     (&#39;si2&#39;, SimpleImputer(missing_values = &#39;Teacher&#39;, 
                                           strategy=&#39;constant&#39;, 
                                           fill_value=&#39;not_relevant&#39;))])

df_replace_9[&#39;Job&#39;] = rep_pipe.fit_transform(df_replace_9[[&#39;Job&#39;]])
df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p32.png" /></p>
<p>In my opinion, however, this approach has two disadvantages. Firstly, the values used are not saved (so cannot be reused automatically) and secondly, this is a lot of code to write. With an if-else function you would be faster:</p>
<pre class="r"><code>def rep_func(col):

    if col == &#39;Student&#39;:
        return &#39;useless&#39;
    if col == &#39;not_relevant&#39;:
        return &#39;useless&#39;
    else:
        return &#39;useless&#39;

df_replace_9[&#39;Job&#39;] = df_replace_9[&#39;Job&#39;].apply(rep_func)
df_replace_9</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p33.png" /></p>
<p>But again, the values used cannot be easily reused. You would have to create your own dictionary.</p>
</div>
</div>
</div>
<div id="further-imputation-methods" class="section level1">
<h1>6 Further Imputation Methods</h1>
<p>In the following chapter I would like to present some more imputation methods.
They differ from the previous ones because they use different values instead of NaN values and not specific values as before.</p>
<p>In some cases, this can lead to getting a little closer to the truth and thus improve the model training.</p>
<div id="with-ffill" class="section level2">
<h2>6.1 with ffill</h2>
<p>Here, the missing value is replaced by the preceding non-missing value.</p>
<pre class="r"><code>df_replace_10 = df.copy()
df_replace_10</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p34.png" /></p>
<pre class="r"><code>df_replace_10[&#39;Age&#39;] = df_replace_10[&#39;Age&#39;].fillna(method=&#39;ffill&#39;)
df_replace_10</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p35.png" /></p>
<p>The ffill function also works for categorical variables.</p>
<pre class="r"><code>df_replace_10[&#39;Job&#39;] = df_replace_10[&#39;Job&#39;].fillna(method=&#39;ffill&#39;)
df_replace_10</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p36.png" /></p>
<p>The condition here is that there is a first value. Let’s have a look at the column ‘Salary’. Here we have two missing values right at the beginning. Here ffill does not work:</p>
<pre class="r"><code>df_replace_10[&#39;Salary&#39;] = df_replace_10[&#39;Salary&#39;].fillna(method=&#39;ffill&#39;)
df_replace_10</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p37.png" /></p>
</div>
<div id="with-backfill" class="section level2">
<h2>6.2 with backfill</h2>
<p>What does not work with ffill works with backfill. Backfill replaces the missing value with the upcoming non-missing value.</p>
<pre class="r"><code>df_replace_10[&#39;Salary&#39;] = df_replace_10[&#39;Salary&#39;].fillna(method=&#39;backfill&#39;)
df_replace_10</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p38.png" /></p>
</div>
<div id="note-on-this-chapter" class="section level2">
<h2>6.3 Note on this Chapter</h2>
<p>Due to the fact that different values are used for the missing values, it is not possible to define a uniform metric that should replace future missing values from the column.</p>
<p>However, one can proceed as follows for a model training. You start by using the functions ffill or backfill and then calculate a desired metric of your choice (e.g. mean) and save it for future missing values from the respective column.</p>
<p>I will explain the just described procedure in chapter 8.2 in more detail.</p>
</div>
</div>
<div id="knnimputer" class="section level1">
<h1>7 KNNImputer</h1>
<p>Here, the KNN algorithm is used to replace missing values.
If you want to know how KNN works exactly, check out this post of mine: <a href="https://michael-fuchs-python.netlify.app/2019/12/27/introduction-to-knn-classifier/">Introduction to KNN Classifier.</a> For this chapter, I have again created a sample data set:</p>
<pre class="r"><code>df_knn = pd.DataFrame({&#39;Name&#39;: [&#39;Anton&#39;, &#39;Moni&#39;, &#39;Sven&#39;, &#39;Renate&#39;, &#39;Justus&#39;, 
                                &#39;Sarah&#39;, &#39;Jon&#39;, &#39;Alex&#39;, &#39;Jenny&#39;, &#39;Jo&#39;],
                       &#39;Age&#39;: [32,22,62,np.NaN,18,63,np.NaN,44,23,71],
                       &#39;Salary&#39;: [4000, np.NaN,4500,2500,3800,5500,7000,np.NaN,4800,3700]})
df_knn</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p39.png" /></p>
<div id="on-single-columns" class="section level2">
<h2>7.1 on single columns</h2>
<pre class="r"><code>df_knn_1 = df_knn.copy()


imp_age_knn = KNNImputer(n_neighbors=2)

df_knn_1[&#39;Age&#39;] = imp_age_knn.fit_transform(df_knn_1[[&#39;Age&#39;]])
df_knn_1</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p40.png" /></p>
<pre class="r"><code>imp_salary_knn = KNNImputer(n_neighbors=2)

df_knn_1[&#39;Salary&#39;] = imp_salary_knn.fit_transform(df_knn_1[[&#39;Salary&#39;]])
df_knn_1</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p41.png" /></p>
<p>So far so good. However, this is not how the KNNImputer is used in practice. I will show you why in the following chapter.</p>
</div>
<div id="on-multiple-columns" class="section level2">
<h2>7.2 on multiple columns</h2>
<pre class="r"><code>df_knn_2 = df_knn.copy()
df_knn_2</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p42.png" /></p>
<pre class="r"><code>imp_age_salary_knn = KNNImputer(n_neighbors=2)

df_knn_2[[&#39;Age&#39;, &#39;Salary&#39;]] = imp_age_salary_knn.fit_transform(df_knn_2[[&#39;Age&#39;, &#39;Salary&#39;]])
df_knn_2</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p43.png" /></p>
<p>As you can see from the comparison below, the two methods use different values from the KNNImputer (see index 1,3 and 7).</p>
<pre class="r"><code>print()
print(&#39;df_knn_1&#39;)
print()
print(df_knn_1)
print(&#39;-------------------------&#39;)
print()
print(&#39;df_knn_2&#39;)
print()
print(df_knn_2)</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p44.png" /></p>
<p>It should be mentioned here that sometimes it is better to choose this statistical approach in order to achieve better results in the later model training.</p>
</div>
<div id="note-on-this-chapter-1" class="section level2">
<h2>7.3 Note on this Chapter</h2>
<p>KNNImputer stores the calculated metrics for each column added to it. <strong>The number and the order of the columns must remain the same!</strong></p>
</div>
</div>
<div id="imputation-in-practice" class="section level1">
<h1>8 Imputation in Practice</h1>
<p>As already announced, I would like to show again how I use the replacement of missing values in practice during model training. It should be noted that I use a simple illustrative example below. In practice, there would most likely be additional steps like using encoders or feature scaling. This will be omitted at this point. But I will show in which case which order should be followed.</p>
<p>In the following, I use a modified version of the created dataset from the KNN example:</p>
<pre class="r"><code>df_practice = df_knn.copy()
Target_Var = [0,0,1,0,1,1,0,1,1,0]
df_practice[&#39;Target_Var&#39;] = Target_Var

df_practice</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p45.png" /></p>
<div id="simpleimputer-in-practice" class="section level2">
<h2>8.1 SimpleImputer in Practice</h2>
<div id="train-test-split" class="section level3">
<h3>8.1.1 Train-Test Split</h3>
<pre class="r"><code>df_practice_simpl_imp = df_practice.copy()
df_practice_simpl_imp</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p46.png" /></p>
<p>In model training, I first divide the data set into a training part and a test part.</p>
<pre class="r"><code>x = df_practice_simpl_imp.drop(&#39;Target_Var&#39;, axis=1)
y = df_practice_simpl_imp[&#39;Target_Var&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)</code></pre>
<pre class="r"><code>print()
print(&#39;trainX&#39;)
print()
print(trainX)
print(&#39;-------------------------&#39;)
print()
print(&#39;testX&#39;)
print()
print(testX)</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p47.png" /></p>
</div>
<div id="fittransform-trainx" class="section level3">
<h3>8.1.2 Fit&amp;Transform (trainX)</h3>
<p>Then I check if there are any Missing Values in trainX.</p>
<pre class="r"><code>trainX.isnull().sum()</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p48.png" /></p>
<p>As we can see, we need to replace missing values in the columns ‘Age’ and ‘Salary’. For this I use the SimpleImputer with the strategy=‘mean’.</p>
<pre class="r"><code># Fit and Transform trainX column &#39;Age&#39; with strategy=&#39;mean&#39;
imp_age_mean1 = SimpleImputer(missing_values=np.nan, strategy=&#39;mean&#39;)
imp_age_mean1.fit(trainX[[&#39;Age&#39;]])
trainX[&#39;Age&#39;] = imp_age_mean1.transform(trainX[[&#39;Age&#39;]])

# Fit and Transform trainX column &#39;Salary&#39; with strategy=&#39;mean&#39;
imp_salary_mean1 = SimpleImputer(missing_values=np.nan, strategy=&#39;mean&#39;)
imp_salary_mean1.fit(trainX[[&#39;Salary&#39;]])
trainX[&#39;Salary&#39;] = imp_salary_mean1.transform(trainX[[&#39;Salary&#39;]])

print(trainX)
print()
print(&#39;Number of missing values:&#39;)
print(trainX.isnull().sum())</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p49.png" /></p>
<p>When I use the SimpleImputer, <strong>I save it separately</strong> to be able to use it again later.</p>
<pre class="r"><code>pk.dump(imp_age_mean1, open(&#39;imp_age_mean1.pkl&#39;, &#39;wb&#39;))
pk.dump(imp_salary_mean1, open(&#39;imp_salary_mean1.pkl&#39;, &#39;wb&#39;))</code></pre>
</div>
<div id="model-training" class="section level3">
<h3>8.1.3 Model Training</h3>
<p>I <strong>won’t do</strong> the model training at this point, because that would still require me to either remove the categorical variable ‘name’ or convert it to a numeric one. This would only cause confusion at this point.
Let’s assume we have done the model training like this.</p>
<pre class="r"><code>dt = DecisionTreeClassifier()
dt.fit(trainX, trainY)</code></pre>
<p>The execution of the prediction function (apart from the still existing categorical variable) would not work like this.</p>
<pre class="r"><code>y_pred = df.predict(testX)</code></pre>
<p>Because we also have Missing Values in the testX part.</p>
<pre class="r"><code>testX.isnull().sum()</code></pre>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p50.png" /></p>
<p>In order to be able to test the created model, we also need to replace them. For this purpose, we saved the metrics of the two SimpleImputers used in the previous step and can use them again here.</p>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p.png" /></p>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p.png" /></p>
<p><img src="/post/2019-03-18-dealing-with-missing-values_files/p4p.png" /></p>
</div>
</div>
</div>
