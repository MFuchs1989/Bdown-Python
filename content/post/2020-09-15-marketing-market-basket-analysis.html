---
title: Marketing - Market Basket Analysis
author: Michael Fuchs
date: '2020-09-15'
slug: marketing-market-basket-analysis
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#market-basket-analysis">2 Market Basket Analysis</a></li>
<li><a href="#import-the-libraries-and-the-data">3 Import the libraries and the data</a></li>
<li><a href="#data-pre-processing">4 Data pre-processing</a></li>
<li><a href="#executing-the-apriori-algorithm">5 Executing the Apriori Algorithm</a></li>
<li><a href="#deriving-association-rules">6 Deriving Association Rules</a></li>
<li><a href="#conclusion">7 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Another exciting topic in marketing analytics is Market Basket Analysis. This is the topic of this publication.
At the beginning of this post I will be introducing some key terms and metrics aimed at giving a sense of what “association” in a rule means and some ways to quantify the strength of this association. Then I will show how to generate these rules from the dataset ‘Online Retail’ using the Apriori Algorithm.</p>
<p>For this post the dataset <em>Online Retail</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Bdown-Python/tree/master/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="market-basket-analysis" class="section level1">
<h1>2 Market Basket Analysis</h1>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82s1.png" /></p>
<p><strong>Definition Market Basket Analysis</strong></p>
<p>Market Basket Analysis is a analysis technique which identifies the strength of association between pairs of products purchased together and identify patterns of co-occurrence.</p>
<p>Market Basket Analysis creates If-Then scenario rules (association rules), for example, if item A is purchased then item B is likely to be purchased. The rules are probabilistic in nature or, in other words, they are derived from the frequencies of co-occurrence in the observations. Frequency is the proportion of baskets that contain the items of interest. The rules can be used in pricing strategies, product placement, and various types of cross-selling strategies.</p>
<p><strong>How association rules work</strong></p>
<p>Association rule mining, at a basic level, involves the use of machine learning models to analyze data for patterns, or co-occurrences, in a database. It identifies frequent if-then associations, which themselves are the association rules.</p>
<p>An association rule has two parts: an antecedent (if) and a consequent (then). An antecedent is an item found within the data. A consequent is an item found in combination with the antecedent.</p>
<p>Association rules are created by searching data for frequent if-then patterns and using the criteria support and confidence to identify the most important relationships. Support is an indication of how frequently the items appear in the data. Confidence indicates the number of times the if-then statements are found true. A third metric, called lift, can be used to compare confidence with expected confidence, or how many times an if-then statement is expected to be found true.</p>
<p>Association rules are calculated from itemsets, which are made up of two or more items. If rules are built from analyzing all the possible itemsets, there could be so many rules that the rules hold little meaning. With that, association rules are typically created from rules well-represented in data.</p>
<p><strong>Important Probabilistic Metrics</strong></p>
<p>Association Rules is one of the very important concepts of machine learning being used in Market Basket Analysis.</p>
<p>Market Basket Analysis is built upon the computation of several probabilistic metrics.
The five major metrics covered here are support, confidence, lift, leverage and conviction.</p>
<p><em>Support</em>:
Percentage of orders that contain the item set.</p>
<ul>
<li>Support = Freq(X,Y)/N</li>
</ul>
<p><em>Confidence</em>:
Given two items, X and Y, confidence measures the percentage of times that item Y is purchased, given that item X was purchased.</p>
<ul>
<li>Confidence = Freq(X,Y)/Freq(X)</li>
</ul>
<p><em>Lift</em>:
Unlike the confidence metric whose value may vary depending on direction [eg: confidence(X -&gt;Y) may be different from confidence(Y -&gt;X)], lift has no direction. This means that the lift(X,Y) is always equal to the lift(Y,X).</p>
<ul>
<li>Lift(X,Y) = Lift(Y,X) = Support(X,Y) / [Support(X) * Support(Y)]</li>
</ul>
<p><em>Leverage</em>:
Leverage measures the difference of X and Y appearing together in the data set and what would be expected if X and Y where statistically dependent. The rational in a sales setting is to find out how many more units (items X and Y together) are sold than expected from the independent sells.</p>
<ul>
<li>Leverage(X -&gt; Y) = P(X and Y) - (P(X)P(Y))</li>
</ul>
<p><em>Conviction</em>:
Conviction compares the probability that X appears without Y if they were dependent with the actual frequency of the appearance of X without Y. In that respect it is similar to lift (see section about lift on this page), however, it contrast to lift it is a directed measure. Furthermore, conviction is monotone in confidence and lift.</p>
<ul>
<li>Conviction(X -&gt; Y) = P(X)P(not Y)/P(X and not Y)=(1-sup(Y))/(1-conf(X -&gt; Y))</li>
</ul>
<p><strong>Difference between Association and Recommendation</strong></p>
<p>Association rules do not extract an individual’s preference, rather find relationships between sets of elements of every distinct transaction. This is what makes them different than Collaborative filtering which is used in recommendation systems.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>3 Import the libraries and the data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np


import mlxtend.preprocessing
import mlxtend.frequent_patterns

import matplotlib.pyplot as plt</code></pre>
<pre class="r"><code>df = pd.read_excel(&quot;Online Retail.xlsx&quot;, sheet_name=&quot;Online Retail&quot;)
df</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p1.png" /></p>
</div>
<div id="data-pre-processing" class="section level1">
<h1>4 Data pre-processing</h1>
<pre class="r"><code>&#39;&#39;&#39;
Create an indicator column stipulating whether the invoice number begins with &#39;C&#39;
&#39;&#39;&#39;

df[&#39;Is_C_Present&#39;] = (
    online[&#39;InvoiceNo&#39;]
    .astype(str)
    .apply(lambda x: 1 if x.find(&#39;C&#39;) != -1 else 0))

df</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p2.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Filter out all transactions having either zero or a negative number of items.
Remove all invoice numbers starting with &#39;C&#39; (using columns &#39;Is_C_Present&#39;).
Subset the dataframe down to &#39;InvoiceNo&#39; and &#39;Descritpion&#39;.
Drop all rows with at least one missing value.
&#39;&#39;&#39;


df_clean = (
    df
    # filter out non-positive quantity values
    .loc[df[&quot;Quantity&quot;] &gt; 0]
    # remove InvoiceNos starting with C
    .loc[df[&#39;Is_C_Present&#39;] != 1]
    # column filtering
    .loc[:, [&quot;InvoiceNo&quot;, &quot;Description&quot;]]
    # dropping all rows with at least one missing value
    .dropna()
)

df_clean</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p3.png" /></p>
<pre class="r"><code>print(
    &quot;Data dimension (row count, col count): {dim}&quot;
    .format(dim=df_clean.shape)
)
print(
    &quot;Count of unique invoice numbers: {cnt}&quot;
    .format(cnt=df_clean.InvoiceNo.nunique())
)</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p4.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Transform the data into a list of lists called invoice_item_list

&#39;&#39;&#39;

invoice_item_list = []
for num in list(set(df_clean.InvoiceNo.tolist())):
    # filter data set down to one invoice number
    tmp_df = df_clean.loc[df_clean[&#39;InvoiceNo&#39;] == num]
    # extract item descriptions and convert to list
    tmp_items = tmp_df.Description.tolist()
    # append list invoice_item_list
    invoice_item_list.append(tmp_items)

print(invoice_item_list[1:3])</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p5.png" /></p>
<p>To be able to run any models the data, currently in the list of lists form, needs to be encoded and recast as a dataframe. Outputted from the encoder is a multidimensional array, where each row is the length of the total number of unique items in the transaction dataset and the elements are Boolean variables, indicating whether that particular item is linked to the invoice number that row presents. With the data encoded, we can recast it as a dataframe where the rows are the invoice numbers and the columns are the unique items in the transaction dataset.</p>
<pre class="r"><code># Initialize and fit the transaction encoder
online_encoder = mlxtend.preprocessing.TransactionEncoder()
online_encoder_array = online_encoder.fit_transform(invoice_item_list)

# Recast the encoded array as a dataframe
online_encoder_df = pd.DataFrame(online_encoder_array, columns=online_encoder.columns_)

# Print the results
online_encoder_df</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p6.png" /></p>
</div>
<div id="executing-the-apriori-algorithm" class="section level1">
<h1>5 Executing the Apriori Algorithm</h1>
<p>The Apriori algorithm is one of the most common techniques in Market Basket Analysis.</p>
<p>It is used to analyze the frequent itemsets in a transactional database, which then is used to generate association rules between the products.</p>
<pre class="r"><code>&#39;&#39;&#39;
Run the Apriori Algorithm with min_support = 0.01 (by default 0.5)
&#39;&#39;&#39;

apriori_model = mlxtend.frequent_patterns.apriori(online_encoder_df, min_support=0.01)
apriori_model</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p7.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Run the same model again, but this time with use_colnames=True.
This will replace the numerical designations with the actual item names.
&#39;&#39;&#39;

apriori_model_colnames = mlxtend.frequent_patterns.apriori(
    online_encoder_df, 
    min_support=0.01,
    use_colnames=True
)

apriori_model_colnames</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p8.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Add an additional column to the output of apriori_model_colnames that contains the size of the item set.
This will help with filtering and further analysis. 
&#39;&#39;&#39;

apriori_model_colnames[&#39;length&#39;] = (
    apriori_model_colnames[&#39;itemsets&#39;].apply(lambda x: len(x))
)

apriori_model_colnames</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p9.png" /></p>
<pre class="r"><code>apriori_model_colnames[
    apriori_model_colnames[&#39;itemsets&#39;] == frozenset(
        {&#39;12 PENCIL SMALL TUBE WOODLAND&#39;})]</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p10.png" /></p>
<p>The output gives us the support value for ‘12 PENCIL SMALL TUBE WOODLAND’. The support value says that this specific item appears in 1,76% of the transactions.</p>
<pre class="r"><code>apriori_model_colnames[
    (apriori_model_colnames[&#39;length&#39;] == 2) &amp; 
    (apriori_model_colnames[&#39;support&#39;] &gt;= 0.02) &amp;
    (apriori_model_colnames[&#39;support&#39;] &lt; 0.021)
]</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p11.png" /></p>
<p>This dataframe contains all the item sets (pairs of items bought together) whose support value is in the range between 2% and 2.1% of transactions.</p>
<p>When you are filtering on support, it is wise to specify a range instead of a sprecific value since it is quite possible to pick a value for which there are no item sets.</p>
<pre class="r"><code>apriori_model_colnames.hist(&quot;support&quot;, grid=False, bins=30)
plt.title(&quot;Support&quot;)</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p12.png" /></p>
</div>
<div id="deriving-association-rules" class="section level1">
<h1>6 Deriving Association Rules</h1>
<pre class="r"><code>&#39;&#39;&#39;
Generate derive association rules for the online retail dataset.
Here we use confidence as the measure of interestingness.
Set the minimum threshold to 0.6.
Return all metrics, not just support.
&#39;&#39;&#39;

rules = mlxtend.frequent_patterns.association_rules(
    apriori_model_colnames, 
    metric=&quot;confidence&quot;,
    min_threshold=0.6, 
    support_only=False
)

rules</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p13.png" /></p>
<pre class="r"><code>print(&quot;Number of Associations: {}&quot;.format(rules.shape[0]))</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p14.png" /></p>
<pre class="r"><code>rules.plot.scatter(&quot;support&quot;, &quot;confidence&quot;, alpha=0.5, marker=&quot;*&quot;)
plt.xlabel(&quot;Support&quot;)
plt.ylabel(&quot;Confidence&quot;)
plt.title(&quot;Association Rules&quot;)
plt.show()</code></pre>
<p><img src="/post/2020-09-15-marketing-market-basket-analysis_files/p82p15.png" /></p>
<p>There are not any association rules with both extremly high confidence and extremely high support.</p>
<p>This make sense. If an item set has high support, the items are likely to appear with many other items, making the chances of high confidence very low.</p>
</div>
<div id="conclusion" class="section level1">
<h1>7 Conclusion</h1>
<p>In this publication I have written about what market basket analysis is and how to perform it.</p>
<p>With this kind of analysis from the field of mareting you can now determine which products are most often bought in combination with each other.
With this knowledge it is possible to arrange the products efficiently in the store. In the best case, products that are often bought together are positioned in the opposite direction in the store so that customers are forced to walk past as many other products as possible.</p>
<p>Furthermore, one can now consider targeted discount campaigns. If you discount a product that is often bought in combination with others, you increase the chance of buying these products in combination, whereby a small discount is granted on only one.</p>
<p><strong>References</strong></p>
<p>Besemer, S. P. (1998). Creative product analysis matrix: testing the model structure and a comparison among products–three novel chairs. Creativity Research Journal, 11(4), 333-346.</p>
<p>Miller, T. W. (2015). Marketing data science: modeling techniques in predictive analytics with R and Python. FT Press.</p>
<p>Provost, F., &amp; Fawcett, T. (2013). Data Science for Business: What you need to know about data mining and data-analytic thinking. " O’Reilly Media, Inc.".</p>
<p>Wedel, M., Kamakura, W., &amp; Böckenholt, U. (2000). Marketing data, models and decisions. International Journal of Research in Marketing, 17(2-3), 203-208.</p>
<p>Hwang, Y. (2019). Hands-On Data Science for Marketing: Improve your marketing strategies with machine learning using Python and R. Packt Publishing Ltd.</p>
<p>Johnston, B., Jones, A. &amp; Kruger, C. (2019). Applied Unsupervised Learning with Python : Discover hidden patterns and relationships in unstructured data with Python.
Packt Publishing Ltd.</p>
<p>Xu, Z., Frankwick, G. L., &amp; Ramirez, E. (2016). Effects of big data analytics and traditional marketing analytics on new product success: A knowledge fusion perspective. Journal of Business Research, 69(5), 1562-1566.</p>
</div>
