---
title: Metrics for Regression Analysis
author: Michael Fuchs
date: '2019-06-30'
slug: metrics-for-regression-analysis
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries-and-the-data">2 Loading the libraries and the data</a></li>
<li><a href="#data-pre-processing">3 Data pre-processing</a>
<ul>
<li><a href="#train-test-split">3.1 Train-Test Split</a></li>
<li><a href="#scaling">3.2 Scaling</a></li>
</ul></li>
<li><a href="#model-fitting">4 Model fitting</a></li>
<li><a href="#model-evaluation">5 Model Evaluation</a>
<ul>
<li><a href="#r²">5.1 R²</a></li>
<li><a href="#mean-absolute-error-mae">5.2 Mean Absolute Error (MAE)</a></li>
<li><a href="#mean-squared-error-mse">5.3 Mean Squared Error (MSE)</a></li>
<li><a href="#root-mean-squared-error-rmse">5.4 Root Mean Squared Error (RMSE)</a></li>
<li><a href="#mean-absolute-percentage-error-mape">5.5 Mean Absolute Percentage Error (MAPE)</a></li>
<li><a href="#summary-of-the-metrics">5.6 Summary of the Metrics</a></li>
</ul></li>
<li><a href="#conclusion">6 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>In my post <a href="https://michael-fuchs-python.netlify.app/2019/06/28/introduction-to-regression-analysis-and-predictions/">Introduction to regression analysis and predictions</a> I showed how to build regression models and also used evaluation metrics under <a href="https://michael-fuchs-python.netlify.app/2019/06/28/introduction-to-regression-analysis-and-predictions/#linear-regression-with-scikit-learn">chapter 4</a>.</p>
<p>In this publication I would like to present metrics for regression analyses in more detail and show how they can be calculated.</p>
<p>For this post the dataset <em>House Sales in King County, USA</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="loading-the-libraries-and-the-data" class="section level1">
<h1>2 Loading the libraries and the data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import LinearRegression

from sklearn import metrics</code></pre>
<pre class="r"><code>df = pd.read_csv(&#39;house_prices.csv&#39;)
df = df.drop([&#39;id&#39;, &#39;date&#39;, &#39;yr_built&#39;, &#39;yr_renovated&#39;, &#39;zipcode&#39;, &#39;lat&#39;, &#39;long&#39;], axis=1)
df.head()</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p1.png" /></p>
<p>We will do the model training quick and dirty…</p>
</div>
<div id="data-pre-processing" class="section level1">
<h1>3 Data pre-processing</h1>
<div id="train-test-split" class="section level2">
<h2>3.1 Train-Test Split</h2>
<pre class="r"><code>x = df.drop(&#39;price&#39;, axis=1)
y = df[&#39;price&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)</code></pre>
</div>
<div id="scaling" class="section level2">
<h2>3.2 Scaling</h2>
<pre class="r"><code>sc=StandardScaler()

scaler = sc.fit(trainX)

trainX_scaled = scaler.transform(trainX)
testX_scaled = scaler.transform(testX)</code></pre>
</div>
</div>
<div id="model-fitting" class="section level1">
<h1>4 Model fitting</h1>
<pre class="r"><code>lm = LinearRegression()
lm.fit(trainX_scaled, trainY)</code></pre>
</div>
<div id="model-evaluation" class="section level1">
<h1>5 Model Evaluation</h1>
<pre class="r"><code>y_pred = lm.predict(testX_scaled)</code></pre>
<p>Here are the prediction results:</p>
<pre class="r"><code>df_results = pd.DataFrame({&#39;Actual&#39;: testY, &#39;Predicted&#39;: y_pred})
df_results.head()</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p2.png" /></p>
<div id="r²" class="section level2">
<h2>5.1 R²</h2>
<p>The value R² tells us how much variance in the outcome variable can be explained by the predictors. Here: 60.6 %.</p>
<pre class="r"><code>print(&#39;R²: &#39; + str(lm.score(trainX_scaled, trainY)))</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p1184p3.png" /></p>
</div>
<div id="mean-absolute-error-mae" class="section level2">
<h2>5.2 Mean Absolute Error (MAE)</h2>
<p>MAE stands for Mean Absolute Error and is probably the easiest regression error metric to understand. Here, each residual is calculated for each data point, taking only the absolute value of each point. This prevents positive and negative residuals from not canceling each other out. Then the average of all residuals is taken.</p>
<p>Here is a simple example:</p>
<p>We have the actual cost of different rooms.</p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118s1.png" /></p>
<p>Now we contrast this with the Predicted Values.</p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118s2.png" /></p>
<p>Now we calculate the error value as follows:</p>
<p><code>Error = Actual Costs - Predicted Costs</code></p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118s3.png" /></p>
<p>The absolute values are now summed up.</p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118s4.png" /></p>
<p>Now we calculate the mean value of the absolute error values.</p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118s5.png" /></p>
<p>This is our measure of model quality. In this example, we can say that our model predictions are off by about €45.</p>
<p>Simply the MAE can be calculated with the following function:</p>
<pre class="r"><code>print(&#39;Mean Absolute Error:&#39;, metrics.mean_absolute_error(testY, y_pred))</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p4.png" /></p>
<p>Of course, you could also calculate this value manually as in our example above.</p>
<pre class="r"><code>df_results[&#39;error&#39;] = df_results[&#39;Actual&#39;] - df_results[&#39;Predicted&#39;]
df_results.head()</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p5.png" /></p>
<pre class="r"><code>df_results[&#39;error_abs&#39;] = df_results[&#39;error&#39;].abs()
df_results.head()</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p6.png" /></p>
<pre class="r"><code>sum_error_abs = df_results[&#39;error_abs&#39;].sum()
sum_error_abs</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p7.png" /></p>
<pre class="r"><code>no_observations = len(df_results)
no_observations</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p8.png" /></p>
<pre class="r"><code>mae = sum_error_abs / no_observations
mae</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p9.png" /></p>
<p>As we can see, this is the same value as above.</p>
</div>
<div id="mean-squared-error-mse" class="section level2">
<h2>5.3 Mean Squared Error (MSE)</h2>
<p>MSE stands for Mean Squared Error and is just like the Mean Absolute Error, but differs from it in that it squares the difference before summing instead of just taking the absolute value.</p>
<p>Since the difference is squared, the MSE will almost always be greater than the MAE. For this reason, the MSE cannot be directly compared to the MAE. Only the error metric of our model can be compared to that of a competing model. The effect of the quadratic term in the MSE equation is most apparent when there are outliers in the data set. Whereas in MAE this residual contributes proportionally to the total error, in MSE the error grows quadratically. Thus, existing outliers contribute to a much higher total error in MSE than they would in MAE.</p>
<pre class="r"><code>print(&#39;Mean Squared Error:&#39;, metrics.mean_squared_error(testY, y_pred))</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p10.png" /></p>
</div>
<div id="root-mean-squared-error-rmse" class="section level2">
<h2>5.4 Root Mean Squared Error (RMSE)</h2>
<p>RMSE stands for Root Mean Squared Error and this is the square root of the MSE.
We know that the MSE is squared. Thus, its units do not match those of the original output. To convert the error metric back to similar units, the RMSE is used. This simplifies the interpretation again. Both MSE and RMSE are affected by outliers. Their common goal is to measure how large the residuals are distributed. Their values lie in the range between zero and positive infinity.</p>
<pre class="r"><code>print(&#39;Root Mean Squared Error:&#39;, metrics.mean_squared_error(testY, y_pred, squared=False))</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p11.png" /></p>
</div>
<div id="mean-absolute-percentage-error-mape" class="section level2">
<h2>5.5 Mean Absolute Percentage Error (MAPE)</h2>
<p>Another possible evaluation metric is the use of percentages. Here, each prediction is scaled against the value it is supposed to estimate.
MAPE stands for Mean Absolute Percentage Error and is the percentage equivalent of MAE.</p>
<p>MAPE indicates how far the predictions of the model used deviate on average from the corresponding outputs.
Both MAPE and MAE are accompanied by a clear interpretation, as percentages are easier to conceptualize for most people.</p>
<p>Both MAPE and MAE are robust to the effects of outliers. This is due to the use of absolute values.</p>
<pre class="r"><code>print(&#39;Mean Absolute Percentage Error:&#39;, metrics.mean_absolute_percentage_error(testY, y_pred))</code></pre>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p12.png" /></p>
</div>
<div id="summary-of-the-metrics" class="section level2">
<h2>5.6 Summary of the Metrics</h2>
<p>Here is again a summary of the metrics presented:</p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p13.png" /></p>
<p><img src="/post/2019-06-30-metrics-for-regression-analysis_files/p118p14.png" /></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>6 Conclusion</h1>
<p>In this post, I showed which evaluation metrics you can use in a regression analysis and how to interpret and calculate them.</p>
</div>
