---
title: NLP - Text Vectorization
author: Michael Fuchs
date: '2021-08-01'
slug: nlp-text-vectorization
categories: []
tags: []
output:
  blogdown::html_page:
    toc: yes
    toc_depth: 5
---



# 1 Introduction

Now that we have cleaned up and prepared our text dataset in the previous posts, we come to the next topic: **Text Vectorization**

Most machine learning algorithms cannot handle string variables. We have to convert them into a format that is readable for machine learning algorithms. Text vectorization is the mapping of vocabulary or tokens from a data set to a corresponding vector of real numbers. These vectors can be used as input to machine learning models. 

In the following, I will use a simple example to show several ways in which vectorization can be done. 

Finally, I will apply a vectorization method to the dataset (['Amazon_Unlocked_Mobile_small_pre_processed.csv'](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/NLP/Text%20Pre-Processing%20-%20All%20in%20One)) created and processed in the [last post](https://michael-fuchs-python.netlify.app/2021/06/23/nlp-text-pre-processing-all-in-one/) and train a machine learning model on it. 


# 2 Import the Libraries and the Data


```{r, eval=F, echo=T}
import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
```



```{r, eval=F, echo=T}
df = pd.DataFrame({'Rating': [2,5,3],
                   'Text': ["This is a brown horse",
                            "This horse likes to play",
                            "The horse is in the stable"]})
df
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p1.png)


# 3 Text Vectorization

## 3.1 Bag-of-Words(BoW)

CountVectorizer() is one of the simplest methods of text vectorization.

It creates a sparse matrix consisting of a set of dummy variables. These indicate whether a certain word occurs in the document or not. The CountVectorizer function matches the word vocabulary, learns it, and creates a document term matrix where the individual cells indicate the frequency of that word in a given document.
This is also called term frequency where the columns are dedicated to each word in the corpus. 


### 3.1.2 Functionality


```{r, eval=F, echo=T}
cv = CountVectorizer()

cv_vectorizer = cv.fit(df['Text'])
text_cv_vectorized = cv_vectorizer.transform(df['Text'])

text_cv_vectorized_array = text_cv_vectorized.toarray()

print(text_cv_vectorized_array)
print()
print(text_cv_vectorized_array.shape)
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p2.png)

10 different words were found in the text corpus. These can also be output as follows:

```{r, eval=F, echo=T}
cv_vectorizer.get_feature_names()
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p3.png)



```{r, eval=F, echo=T}
cv_vectorizer.vocabulary_
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p4.png)

To make the output a bit more readable we can have it displayed as a dataframe:


```{r, eval=F, echo=T}
cv_vectorized_matrix = pd.DataFrame(text_cv_vectorized.toarray(), 
                                    columns=cv_vectorizer.get_feature_names())
cv_vectorized_matrix
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p5.png)

How are the rows and columns in the matrix shown above to be read?

+ The rows indicate the documents in the corpus and
+ The columns indicate the tokens in the dictionary



### 3.1.3 Creation of the final Data Set

Finally, I create a new data set on which to train machine learning algorithms. This time I use the generated array directly to create the final data frame:

```{r, eval=F, echo=T}
cv_df = pd.DataFrame(text_cv_vectorized_array, 
                     columns = cv_vectorizer.get_feature_names()).add_prefix('Counts_')

df_new_cv = pd.concat([df, cv_df], axis=1, sort=False)
df_new_cv
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p6.png)

However, the bag-of-words method also has two crucial disadvantages: 

+ BoW does not preserve the order of words and
+ It does not allow to draw useful conclusions for downstream NLP tasks


### 3.1.4 Test of a Sample Record

Let's test a sample record:


```{r, eval=F, echo=T}
new_input = ["Hi this is Mikel."]
new_input
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p7.png)



```{r, eval=F, echo=T}
new_input_cv_vectorized = cv_vectorizer.transform(new_input)
new_input_cv_vectorized_array = new_input_cv_vectorized.toarray()
new_input_cv_vectorized_array
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p8.png)



```{r, eval=F, echo=T}
new_input_matrix = pd.DataFrame(new_input_cv_vectorized_array, 
                                columns = cv_vectorizer.get_feature_names())

new_input_matrix
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p9.png)


The words 'is' and 'this' have been learned by the CountVectorizer and thus get a count here. 

```{r, eval=F, echo=T}
new_input = ["You say goodbye and I say hello", "hello world"]
new_input
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p10.png)




```{r, eval=F, echo=T}
new_input_cv_vectorized = cv_vectorizer.transform(new_input)
new_input_cv_vectorized_array = new_input_cv_vectorized.toarray()
new_input_cv_vectorized_array
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p11.png)



```{r, eval=F, echo=T}
new_input_matrix = pd.DataFrame(new_input_cv_vectorized_array, 
                                columns = cv_vectorizer.get_feature_names())

new_input_matrix
```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p12.png)



In our second example, I did not use any of the words CountVectorizer learned. Therefore all values are 0.


## 3.2  N-grams




```{r, eval=F, echo=T}

```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p.png)
























```{r, eval=F, echo=T}

```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p.png)
































```{r, eval=F, echo=T}

```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p.png)






























```{r, eval=F, echo=T}

```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p.png)






























```{r, eval=F, echo=T}

```

![](/post/2021-08-01-nlp-text-vectorization_files/p135p.png)














































































