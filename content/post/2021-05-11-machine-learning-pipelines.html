---
title: Machine Learning Pipelines
author: Michael Fuchs
date: '2021-05-11'
slug: machine-learning-pipelines
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries-and-classes">2 Loading the libraries and classes</a></li>
<li><a href="#loading-the-data">3 Loading the data</a></li>
<li><a href="#ml-pipelines">4 ML Pipelines</a>
<ul>
<li><a href="#a-simple-pipeline">4.1 A simple Pipeline</a></li>
<li><a href="#determination-of-the-best-scaler">4.2 Determination of the best Scaler</a>
<ul>
<li><a href="#creation-of-the-pipeline">4.2.1 Creation of the Pipeline</a></li>
<li><a href="#creation-of-a-pipeline-dictionary">4.2.2 Creation of a Pipeline Dictionary</a></li>
<li><a href="#fit-the-pipeline">4.2.3 Fit the Pipeline</a></li>
<li><a href="#evaluate-the-pipeline">4.2.3 Evaluate the Pipeline</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121s1.png" /></p>
<p>Some time ago I had written the post <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/">The Data Science Process (CRISP-DM)</a>, which was about the correct development of Machine Learning algorithms. As you have seen here, this is quite a time-consuming matter if done correctly.</p>
<p>In order to quickly check which algorithm fits the data best, it is recommended to use machine learning pipelines. Once you have found a promising algorithm, you can start fine tuning with it and go through the process as described <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/#data-science-best-practice-guidlines-for-ml-model-development">here</a>.</p>
<p>For this post the dataset <em>bird</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="loading-the-libraries-and-classes" class="section level1">
<h1>2 Loading the libraries and classes</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split


from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import RobustScaler

from sklearn.decomposition import PCA


from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import Pipeline

from sklearn.metrics import accuracy_score</code></pre>
<pre class="r"><code>class Color:
   PURPLE = &#39;\033[95m&#39;
   CYAN = &#39;\033[96m&#39;
   DARKCYAN = &#39;\033[36m&#39;
   BLUE = &#39;\033[94m&#39;
   GREEN = &#39;\033[92m&#39;
   YELLOW = &#39;\033[93m&#39;
   RED = &#39;\033[91m&#39;
   BOLD = &#39;\033[1m&#39;
   UNDERLINE = &#39;\033[4m&#39;
   END = &#39;\033[0m&#39;</code></pre>
</div>
<div id="loading-the-data" class="section level1">
<h1>3 Loading the data</h1>
<pre class="r"><code>bird_df = pd.read_csv(&#39;bird.csv&#39;).dropna()
bird_df</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p1.png" /></p>
<p>Description of predictors:</p>
<ul>
<li>Length and Diameter of Humerus</li>
<li>Length and Diameter of Ulna</li>
<li>Length and Diameter of Femur</li>
<li>Length and Diameter of Tibiotarsus</li>
<li>Length and Diameter of Tarsometatarsus</li>
</ul>
<pre class="r"><code>bird_df[&#39;type&#39;].value_counts()</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p2.png" /></p>
<p>Description of the target variable:</p>
<ul>
<li>SW: Swimming Birds</li>
<li>W: Wading Birds</li>
<li>T: Terrestrial Birds</li>
<li>R: Raptors</li>
<li>P: Scansorial Birds</li>
<li>SO: Singing Birds</li>
</ul>
<pre class="r"><code>bird_df[&#39;type&#39;].nunique()</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p3.png" /></p>
<pre class="r"><code>x = bird_df.drop([&#39;type&#39;, &#39;id&#39;], axis=1)
y = bird_df[&#39;type&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)</code></pre>
</div>
<div id="ml-pipelines" class="section level1">
<h1>4 ML Pipelines</h1>
<div id="a-simple-pipeline" class="section level2">
<h2>4.1 A simple Pipeline</h2>
<p>Let’s start with a simple pipeline.</p>
<p>In the following, I would like to perform a classification of bird species using <a href="https://michael-fuchs-python.netlify.app/2019/10/31/introduction-to-logistic-regression/">Logistic Regression</a>. For this purpose, the data should be scaled beforehand using the StandardScaler of scikit-learn.</p>
<p><strong>Creation of the pipeline:</strong></p>
<pre class="r"><code>pipe_lr = Pipeline([
    (&#39;ss&#39;, StandardScaler()),
    (&#39;lr&#39;, LogisticRegression())
    ])</code></pre>
<p><strong>Fit and Evaluate the Pipeline:</strong></p>
<pre class="r"><code>pipe_lr.fit(trainX, trainY)</code></pre>
<pre class="r"><code>y_pred = pipe_lr.predict(testX)


print(&#39;Test Accuracy: {:.2f}&#39;.format(accuracy_score(testY, y_pred)))</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p4.png" /></p>
<p>OK, .75% not bad. Let’s see if we can improve the result by choosing a different scaler.</p>
</div>
<div id="determination-of-the-best-scaler" class="section level2">
<h2>4.2 Determination of the best Scaler</h2>
<div id="creation-of-the-pipeline" class="section level3">
<h3>4.2.1 Creation of the Pipeline</h3>
<pre class="r"><code>pipe_lr_wo = Pipeline([
    (&#39;lr&#39;, LogisticRegression())
    ])

pipe_lr_ss = Pipeline([
    (&#39;ss&#39;, StandardScaler()),
    (&#39;lr&#39;, LogisticRegression())
    ])

pipe_lr_mms = Pipeline([
    (&#39;mms&#39;, MinMaxScaler()),
    (&#39;lr&#39;, LogisticRegression())
    ])

pipe_lr_rs = Pipeline([
    (&#39;rs&#39;, RobustScaler()),
    (&#39;lr&#39;, LogisticRegression())
    ])</code></pre>
</div>
<div id="creation-of-a-pipeline-dictionary" class="section level3">
<h3>4.2.2 Creation of a Pipeline Dictionary</h3>
<p>To be able to present the later results better, I always create a suitable dictionary at this point.</p>
<pre class="r"><code>pipe_dic = {
    0: &#39;LogReg wo scaler&#39;,
    1: &#39;LogReg with StandardScaler&#39;,
    2: &#39;LogReg with MinMaxScaler&#39;,
    3: &#39;LogReg with RobustScaler&#39;,
    }

pipe_dic</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p5.png" /></p>
</div>
<div id="fit-the-pipeline" class="section level3">
<h3>4.2.3 Fit the Pipeline</h3>
<p>To be able to fit the pipelines, I first need to group the pipelines into a list:</p>
<pre class="r"><code>pipelines = [pipe_lr_wo, pipe_lr_ss, pipe_lr_mms, pipe_lr_rs]</code></pre>
<p>Now we are going to fit the created pipelines:</p>
<pre class="r"><code>for pipe in pipelines:
    pipe.fit(trainX, trainY)</code></pre>
</div>
<div id="evaluate-the-pipeline" class="section level3">
<h3>4.2.3 Evaluate the Pipeline</h3>
<pre class="r"><code>for idx, val in enumerate(pipelines):
    print(&#39;%s pipeline Test Accuracy: %.2f&#39; % (pipe_dic[idx], accuracy_score(testY, val.predict(testX))))</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p6.png" /></p>
<p>We can also use the .score function:</p>
<pre class="r"><code>for idx, val in enumerate(pipelines):
    print(&#39;%s pipeline Test Accuracy: %.2f&#39; % (pipe_dic[idx], val.score(testX, testY)))</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p7.png" /></p>
<p>I always like to have the results displayed in a dataframe so I can sort and filter:</p>
<pre class="r"><code>result = []

for idx, val in enumerate(pipelines):
    result.append(accuracy_score(testY, val.predict(testX)))

    
result_df = pd.DataFrame(list(pipe_dic.items()),columns = [&#39;Idx&#39;,&#39;Estimator&#39;])

# Add Test Accuracy to result_df
result_df[&#39;Test_Accuracy&#39;] = result
# print result_df
result_df </code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p8.png" /></p>
<p>Let’s take a look at our best model:</p>
<pre class="r"><code>best_model = result_df.sort_values(by=&#39;Test_Accuracy&#39;, ascending=False)
best_model</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p9.png" /></p>
<pre class="r"><code>print(best_model[&#39;Estimator&#39;].iloc[0] +
      &#39; Classifier has the best Test Accuracy of &#39; + 
      str(round(best_model[&#39;Test_Accuracy&#39;].iloc[0], 2)) + &#39;%&#39;)</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p10.png" /></p>
<p>Or the print statement still a little bit spiffed up:</p>
<pre class="r"><code>print(Color.RED + best_model[&#39;Estimator&#39;].iloc[0] + Color.END +
      &#39; Classifier has the best Test Accuracy of &#39; + 
      Color.GREEN + Color.BOLD + str(round(best_model[&#39;Test_Accuracy&#39;].iloc[0], 2)) + &#39;%&#39;)</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p11.png" /></p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p.png" /></p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p.png" /></p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p.png" /></p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p.png" /></p>
</div>
</div>
</div>
