---
title: Machine Learning Pipelines
author: Michael Fuchs
date: '2021-05-11'
slug: machine-learning-pipelines
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries-and-classes">2 Loading the libraries and classes</a></li>
<li><a href="#loading-the-data">3 Loading the data</a></li>
<li><a href="#ml-pipelines">4 ML Pipelines</a>
<ul>
<li><a href="#a-simple-pipeline">4.1 A simple Pipeline</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>test22</p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121s1.png" /></p>
<p>Some time ago I had written the post <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/">The Data Science Process (CRISP-DM)</a>, which was about the correct development of Machine Learning algorithms. As you have seen here, this is quite a time-consuming matter if done correctly.</p>
<p>In order to quickly check which algorithm fits the data best, it is recommended to use machine learning pipelines. Once you have found a promising algorithm, you can start fine tuning with it and go through the process as described <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/#data-science-best-practice-guidlines-for-ml-model-development">here</a>.</p>
<p>For this post the dataset <em>bird</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="loading-the-libraries-and-classes" class="section level1">
<h1>2 Loading the libraries and classes</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split


from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import RobustScaler

from sklearn.decomposition import PCA


from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.pipeline import Pipeline

from sklearn.metrics import accuracy_score</code></pre>
<pre class="r"><code>class Color:
   PURPLE = &#39;\033[95m&#39;
   CYAN = &#39;\033[96m&#39;
   DARKCYAN = &#39;\033[36m&#39;
   BLUE = &#39;\033[94m&#39;
   GREEN = &#39;\033[92m&#39;
   YELLOW = &#39;\033[93m&#39;
   RED = &#39;\033[91m&#39;
   BOLD = &#39;\033[1m&#39;
   UNDERLINE = &#39;\033[4m&#39;
   END = &#39;\033[0m&#39;</code></pre>
</div>
<div id="loading-the-data" class="section level1">
<h1>3 Loading the data</h1>
<pre class="r"><code>bird_df = pd.read_csv(&#39;bird.csv&#39;).dropna()
bird_df</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p1.png" /></p>
<p>Description of predictors:</p>
<ul>
<li>Length and Diameter of Humerus</li>
<li>Length and Diameter of Ulna</li>
<li>Length and Diameter of Femur</li>
<li>Length and Diameter of Tibiotarsus</li>
<li>Length and Diameter of Tarsometatarsus</li>
</ul>
<pre class="r"><code>bird_df[&#39;type&#39;].value_counts()</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p2.png" /></p>
<p>Description of the target variable:</p>
<ul>
<li>SW: Swimming Birds</li>
<li>W: Wading Birds</li>
<li>T: Terrestrial Birds</li>
<li>R: Raptors</li>
<li>P: Scansorial Birds</li>
<li>SO: Singing Birds</li>
</ul>
<pre class="r"><code>bird_df[&#39;type&#39;].nunique()</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p3.png" /></p>
<pre class="r"><code>x = bird_df.drop([&#39;type&#39;, &#39;id&#39;], axis=1)
y = bird_df[&#39;type&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)</code></pre>
</div>
<div id="ml-pipelines" class="section level1">
<h1>4 ML Pipelines</h1>
<div id="a-simple-pipeline" class="section level2">
<h2>4.1 A simple Pipeline</h2>
<p>Let’s start with a simple pipeline.</p>
<p>In the following, I would like to perform a classification of bird species using <a href="https://michael-fuchs-python.netlify.app/2019/10/31/introduction-to-logistic-regression/">Logistic Regression</a>. For this purpose, the data should be scaled beforehand using the StandardScaler of scikit-learn.</p>
<p><strong>Creation of the pipeline:</strong></p>
<pre class="r"><code>pipe_lr = Pipeline([
    (&#39;ss&#39;, StandardScaler()),
    (&#39;lr&#39;, LogisticRegression())
    ])</code></pre>
<p><strong>Fit and Evaluate the Pipeline:</strong></p>
<pre class="r"><code>pipe_lr.fit(trainX, trainY)</code></pre>
<pre class="r"><code>y_pred = pipe_lr.predict(testX)


print(&#39;Test Accuracy: {:.2f}&#39;.format(accuracy_score(testY, y_pred)))</code></pre>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p4.png" /></p>
<p><img src="/post/2021-05-11-machine-learning-pipelines_files/p121p.png" /></p>
</div>
</div>
