---
title: Ensemble Modeling - Bagging
author: Michael Fuchs
date: '2020-03-07'
slug: ensemble-modeling-bagging
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#background-information-on-bagging">2 Background Information on Bagging</a></li>
<li><a href="#loading-the-libraries-and-the-data">3 Loading the libraries and the data</a></li>
<li><a href="#data-pre-processing">4 Data pre-processing</a></li>
<li><a href="#decision-tree-classifier">5 Decision Tree Classifier</a></li>
<li><a href="#bagging-classifier">6 Bagging Classifier</a></li>
<li><a href="#random-forest-classifier">7 Random Forest Classifier</a>
<ul>
<li><a href="#train-the-random-forest-classifier">7.1 Train the Random Forest Classifier</a></li>
<li><a href="#evaluate-the-forest-classifier">7.2 Evaluate the Forest Classifier</a>
<ul>
<li><a href="#stratifiedkfold">7.2.1 StratifiedKFold</a></li>
<li><a href="#kfold">7.2.2 KFold</a></li>
</ul></li>
<li><a href="#hyperparameter-optimization-via-randomized-search">7.3 Hyperparameter optimization via Randomized Search</a></li>
<li><a href="#determination-of-feature-importance">7.4 Determination of feature importance</a></li>
</ul></li>
<li><a href="#conclusion">8 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>So far we have dealt very intensively with the use of different classification algorithms. Now let’s come to some ensemble methods.
Ensemble learning is a machine learning paradigm where multiple models (often called “weak learners”) are trained to solve the same problem and combined to get better results.</p>
<p>There are three most common types of ensembles:</p>
<ul>
<li>Bagging</li>
<li>Boosting</li>
<li>Stacking</li>
</ul>
<p>In this post we will start with bagging, and then move on to boosting and stacking in separate publications.</p>
<p>For this post the dataset <em>Bank Data</em> from the platform <a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">“UCI Machine Learning Repository”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="background-information-on-bagging" class="section level1">
<h1>2 Background Information on Bagging</h1>
<p>The term bagging is derived from a technique calles bootstrap aggregation. In a nutshell: The bootstrap method refers to random sampling with replacement (please see figure below). Several small data records (resamples) are removed from an existing data record. It doesn’t matter whether an observation is taken out twice or not. With the help of these resamples, individual models are calculated and ultimately combined to form an aggregated prediction.</p>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42s1.png" /></p>
</div>
<div id="loading-the-libraries-and-the-data" class="section level1">
<h1>3 Loading the libraries and the data</h1>
<pre class="r"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier

from sklearn.metrics import accuracy_score


from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score

from sklearn.model_selection import RandomizedSearchCV</code></pre>
<pre class="r"><code>bank = pd.read_csv(&quot;bank.csv&quot;, sep=&quot;;&quot;)
bank.head()</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p1.png" /></p>
<p>The data set before us contains information about whether a customer has signed a contract or not.</p>
<pre class="r"><code>bank[&#39;y&#39;].value_counts().T</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p2.png" /></p>
<p>Let’s see how well we can predict that in the end.</p>
</div>
<div id="data-pre-processing" class="section level1">
<h1>4 Data pre-processing</h1>
<p>Here we convert all categorical variables into numerical.
If you want to know exactly how it works look at these two posts of mine:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.app/2019/06/16/types-of-encoder/">“Types of Encoder”</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2019/06/14/the-use-of-dummy-variables/">“The use of dummy variables”</a></li>
</ul>
<pre class="r"><code>safe_y = bank[[&#39;y&#39;]]

col_to_exclude = [&#39;y&#39;]
bank = bank.drop(col_to_exclude, axis=1)</code></pre>
<pre class="r"><code>#Just select the categorical variables
cat_col = [&#39;object&#39;]
cat_columns = list(bank.select_dtypes(include=cat_col).columns)
cat_data = bank[cat_columns]
cat_vars = cat_data.columns

#Create dummy variables for each cat. variable
for var in cat_vars:
    cat_list = pd.get_dummies(bank[var], prefix=var)
    bank=bank.join(cat_list)

    
data_vars=bank.columns.values.tolist()
to_keep=[i for i in data_vars if i not in cat_vars]

#Create final dataframe
bank_final=bank[to_keep]
bank_final.columns.values</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p3.png" /></p>
<pre class="r"><code>bank = pd.concat([bank_final, safe_y], axis=1)
bank</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p4.png" /></p>
<p>Let’s check for missing values:</p>
<pre class="r"><code>def missing_values_table(df):
        # Total missing values
        mis_val = df.isnull().sum()
        
        # Percentage of missing values
        mis_val_percent = 100 * df.isnull().sum() / len(df)
        
        # Make a table with the results
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        
        # Rename the columns
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : &#39;Missing Values&#39;, 1 : &#39;% of Total Values&#39;})
        
        # Sort the table by percentage of missing descending
        mis_val_table_ren_columns = mis_val_table_ren_columns[
            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        &#39;% of Total Values&#39;, ascending=False).round(1)
        
        # Print some summary information
        print (&quot;Your selected dataframe has &quot; + str(df.shape[1]) + &quot; columns.\n&quot;      
            &quot;There are &quot; + str(mis_val_table_ren_columns.shape[0]) +
              &quot; columns that have missing values.&quot;)
        
        # Return the dataframe with missing information
        return mis_val_table_ren_columns</code></pre>
<pre class="r"><code>missing_values_table(bank)</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p5.png" /></p>
<p>No missing values. Perfect!
Now let’s split the dataframe for further processing.</p>
<pre class="r"><code>x = bank.drop(&#39;y&#39;, axis=1)
y = bank[&#39;y&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)</code></pre>
</div>
<div id="decision-tree-classifier" class="section level1">
<h1>5 Decision Tree Classifier</h1>
<p>Let’s see how well the Decision Tree Classifier works with our data set.</p>
<pre class="r"><code>dt_params = {
    &#39;criterion&#39;: &#39;entropy&#39;,
    &#39;random_state&#39;: 11
}
dt = DecisionTreeClassifier(**dt_params)</code></pre>
<pre class="r"><code>dt.fit(trainX, trainY)
dt_preds_train = dt.predict(trainX)
dt_preds_test = dt.predict(testX)

print(&#39;Decision Tree:\n&gt; Accuracy on training data = {:.4f}\n&gt; Accuracy on test data = {:.4f}&#39;.format(
    accuracy_score(trainY, dt_preds_train),
    accuracy_score(testY, dt_preds_test)
))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p6.png" /></p>
<p>88% accuracy on the test set. Not bad. Let’s try to improve this result with an ensemble method.</p>
</div>
<div id="bagging-classifier" class="section level1">
<h1>6 Bagging Classifier</h1>
<pre class="r"><code>bc_params = {
    &#39;base_estimator&#39;: dt,
    &#39;n_estimators&#39;: 50,
    &#39;max_samples&#39;: 0.5,
    &#39;random_state&#39;: 11,
    &#39;n_jobs&#39;: -1
}
bc = BaggingClassifier(**bc_params)</code></pre>
<pre class="r"><code>bc.fit(trainX, trainY)
bc_preds_train = bc.predict(trainX)
bc_preds_test = bc.predict(testX)

print(&#39;Bagging Classifier:\n&gt; Accuracy on training data = {:.4f}\n&gt; Accuracy on test data = {:.4f}&#39;.format(
    accuracy_score(trainY, bc_preds_train),
    accuracy_score(testY, bc_preds_test)
))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p7.png" /></p>
<p>Perfect. We could improve the result to 91% accuracy.</p>
</div>
<div id="random-forest-classifier" class="section level1">
<h1>7 Random Forest Classifier</h1>
<p>Random Forest is probably one of the best-known algorithms worldwide and also builds on the bootstrapping method.
Random Forest not only bootstrapping the data points in the overall training dataset, but also bootstrapping the features available for each tree to split on.</p>
<div id="train-the-random-forest-classifier" class="section level2">
<h2>7.1 Train the Random Forest Classifier</h2>
<pre class="r"><code>rf_params = {
    &#39;n_estimators&#39;: 100,
    &#39;criterion&#39;: &#39;entropy&#39;,
    &#39;max_features&#39;: 0.5,
    &#39;min_samples_leaf&#39;: 10,
    &#39;random_state&#39;: 11,
    &#39;n_jobs&#39;: -1
}
rf = RandomForestClassifier(**rf_params)</code></pre>
<pre class="r"><code>rf.fit(trainX, trainY)
rf_preds_train = rf.predict(trainX)
rf_preds_test = rf.predict(testX)

print(&#39;Random Forest Classifier:\n&gt; Accuracy on training data = {:.4f}\n&gt; Accuracy on test data = {:.4f}&#39;.format(
    accuracy_score(trainY, rf_preds_train),
    accuracy_score(testY, rf_preds_test)
))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p8.png" /></p>
<p>As we can see, we were able to increase the model predictive power again.</p>
</div>
<div id="evaluate-the-forest-classifier" class="section level2">
<h2>7.2 Evaluate the Forest Classifier</h2>
<div id="stratifiedkfold" class="section level3">
<h3>7.2.1 StratifiedKFold</h3>
<p>The StratifiedKFold class in scikit-learn implements a combination of the cross-validation and sampling together in one class.</p>
<pre class="r"><code>x = bank.drop(&#39;y&#39;, axis=1).values
y = bank[&#39;y&#39;].values

skf = StratifiedKFold(n_splits=10)

scores = []

for train_index, test_index in skf.split(x, y):
    x_train, x_test = x[train_index], x[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
    rf_skf = RandomForestClassifier(**rf.get_params())
    
    rf_skf.fit(x_train, y_train)
    y_pred = rf_skf.predict(x_test)
    
    scores.append(accuracy_score(y_test, y_pred))
    
scores</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p9.png" /></p>
<pre class="r"><code>print(&#39;StratifiedKFold: Mean Accuracy Score = {}&#39;.format(np.mean(scores)))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p10.png" /></p>
<p>Apparently, the validation method used in connection with the data set used is not suitable.
This could possibly be because the target values are very unbalanced.
Let’s try another metric.</p>
</div>
<div id="kfold" class="section level3">
<h3>7.2.2 KFold</h3>
<pre class="r"><code>scores = cross_val_score(rf, trainX, trainY, cv=5)
scores</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p11.png" /></p>
<pre class="r"><code>print(&#39;KFold: Mean Accuracy Score = {}&#39;.format(np.mean(scores)))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p12.png" /></p>
<p>That looks more realistic.</p>
</div>
</div>
<div id="hyperparameter-optimization-via-randomized-search" class="section level2">
<h2>7.3 Hyperparameter optimization via Randomized Search</h2>
<p>Let’s see how we can improve the model.
We’ve usually done this with Grid Search so far. This time we use Randomized Search.
This method is not so computationally intensive and therefore well suited for random forest.</p>
<pre class="r"><code>rf_rand = RandomForestClassifier()</code></pre>
<pre class="r"><code>param_dist = {&quot;n_estimators&quot;: list(range(10,210,10)),
              &quot;max_depth&quot;: list(range(3,20)),
              &quot;max_features&quot;: list(range(1, 10)),
              &quot;min_samples_split&quot;: list(range(2, 11)),
              &quot;bootstrap&quot;: [True, False],
              &quot;criterion&quot;: [&quot;gini&quot;, &quot;entropy&quot;]}</code></pre>
<pre class="r"><code>n_iter_search = 50

random_search = RandomizedSearchCV(rf_rand, param_distributions=param_dist, scoring=&#39;accuracy&#39;,
                                   n_iter=n_iter_search)
random_search.fit(trainX, trainY)</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p13.png" /></p>
<pre class="r"><code># View best hyperparameters
print(&#39;Best number of estimators:&#39;, random_search.best_estimator_.get_params()[&#39;n_estimators&#39;])
print(&#39;Best min_samples_split:&#39;, random_search.best_estimator_.get_params()[&#39;max_depth&#39;])</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p14.png" /></p>
<pre class="r"><code>random_search.best_params_</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p15.png" /></p>
<pre class="r"><code>results = pd.DataFrame(random_search.cv_results_).sort_values(&#39;rank_test_score&#39;)
for i, row in results.head().iterrows():
    print(&quot;Model rank: {}&quot;.format(row.rank_test_score))
    print(&quot;Mean validation score: {:.3f} (std: {:.3f})&quot;.format(row.mean_test_score, row.std_test_score))
    print(&quot;Model Hyperparameters: {}\n&quot;.format(row.params))</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p16.png" /></p>
</div>
<div id="determination-of-feature-importance" class="section level2">
<h2>7.4 Determination of feature importance</h2>
<pre class="r"><code>feat_imps = pd.DataFrame({&#39;importance&#39;: rf.feature_importances_}, index=bank.columns[:-1])
feat_imps.sort_values(by=&#39;importance&#39;, ascending=False, inplace=True)</code></pre>
<pre class="r"><code>feat_imps.plot(kind=&#39;bar&#39;, figsize=(10,7))

plt.legend()
plt.show()</code></pre>
<p><img src="/post/2020-03-07-ensemble-modeling-bagging_files/p42p17.png" /></p>
<p>As we can see, very few features matter. It would therefore be worthwhile to use feature selection.
How you can do this see here: <a href="https://michael-fuchs-python.netlify.app/2020/01/31/feature-selection-methods-for-classification-tasks/">“Feature selection methods for classification tasks”</a></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>8 Conclusion</h1>
<p>In this post I showed what bagging is and how to use this ensemble method.
Furthermore, I went into detail about the use of the Random Forest algorithm.</p>
<p><strong>References</strong></p>
<p>The content of the entire post was created using the following sources:</p>
<p>Johnston, B. &amp; Mathur, I (2019). Applied Supervised Learning with Python. UK: Packt</p>
</div>
