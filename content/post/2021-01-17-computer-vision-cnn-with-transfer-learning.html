---
title: Computer Vision - CNN with Transfer Learning
author: Michael Fuchs
date: '2021-01-17'
slug: computer-vision-cnn-with-transfer-learning
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries">2 Import the libraries</a></li>
<li><a href="#data-pre-processing">3 Data pre-processing</a>
<ul>
<li><a href="#train-validation-test-split">3.1 Train-Validation-Test Split</a></li>
<li><a href="#obtaining-the-lists-of-randomly-selected-images">3.2 Obtaining the lists of randomly selected images</a></li>
<li><a href="#determination-of-the-directories">3.3 Determination of the directories</a></li>
<li><a href="#obtain-the-total-number-of-training-validation-and-test-images">3.4 Obtain the total number of training, validation and test images</a></li>
</ul></li>
<li><a href="#feature-extraction-without-data-augmentation">4 Feature Extraction without Data Augmentation</a>
<ul>
<li><a href="#name-definitions">4.1 Name Definitions</a></li>
<li><a href="#parameter-settings">4.2 Parameter Settings</a></li>
<li><a href="#instantiating-the-vgg19-convolutional-base">4.3 Instantiating the VGG19 convolutional base</a></li>
<li><a href="#feature-extraction">4.4 Feature Extraction</a>
<ul>
<li><a href="#get-output-shape-of-last-layer">4.4.1 Get Output Shape of last Layer</a></li>
<li><a href="#extracting-features-using-the-pretrained-convolutional-base">4.4.2 Extracting features using the pretrained convolutional base</a></li>
<li><a href="#reshape-train--validation--and-test-features">4.4.3 Reshape train-, validation- and test features</a></li>
<li><a href="#instantiating-a-densely-connected-classifier">4.5 Instantiating a densely connected classifier</a></li>
<li><a href="#layer-structure">4.5.1 Layer Structure</a></li>
<li><a href="#configuring-the-model-for-training">4.5.2 Configuring the model for training</a></li>
</ul></li>
<li><a href="#callbacks">4.6 Callbacks</a></li>
<li><a href="#fitting-the-model">4.7 Fitting the model</a></li>
<li><a href="#obtaining-the-best-model-values">4.8 Obtaining the best model values</a></li>
<li><a href="#obtaining-class-assignments">4.9 Obtaining class assignments</a></li>
<li><a href="#validation">4.10 Validation</a></li>
<li><a href="#load-best-model">4.11 Load best model</a></li>
<li><a href="#model-testing">4.12 Model Testing</a></li>
<li><a href="#test-out-of-the-box-pictures">4.13 Test Out of the Box Pictures</a></li>
</ul></li>
<li><a href="#feature-extraction-with-data-augmentation">5 Feature Extraction with Data Augmentation</a>
<ul>
<li><a href="#name-definitions-1">5.1 Name Definitions</a></li>
<li><a href="#parameter-settings-1">5.2 Parameter Settings</a></li>
<li><a href="#instantiating-the-vgg19-convolutional-base-1">5.3 Instantiating the VGG19 convolutional base</a></li>
<li><a href="#instantiating-a-densely-connected-classifier-1">5.4 Instantiating a densely connected classifier</a>
<ul>
<li><a href="#layer-structure-1">5.4.1 Layer Structure</a></li>
<li><a href="#configuring-the-model-for-training-1">5.4.2 Configuring the model for training</a></li>
<li><a href="#using-imagedatagenerator">5.4.3 Using ImageDataGenerator</a></li>
</ul></li>
<li><a href="#callbacks-1">5.5 Callbacks</a></li>
<li><a href="#fitting-the-model-1">5.6 Fitting the model</a></li>
<li><a href="#obtaining-the-best-model-values-1">5.7 Obtaining the best model values</a></li>
<li><a href="#obtaining-class-assignments-1">5.8 Obtaining class assignments</a></li>
<li><a href="#validation-1">5.9 Validation</a></li>
<li><a href="#load-best-model-1">5.10 Load best model</a></li>
<li><a href="#model-testing-1">5.11 Model Testing</a></li>
<li><a href="#test-out-of-the-box-pictures-1">5.12 Test Out of the Box Pictures</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>In my post <a href="https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/">Computer Vision - Convolutional Neural Network</a> I showed how to train a Convolutional Neural Network for binary image classification. Now I will try to improve this model again using Transfer Learning.</p>
<p>For this publication I used the images from the <em>cats and dogs</em> dataset from the statistics platform <a href="https://www.kaggle.com/c/dogs-vs-cats/data">“Kaggle”</a>. You can download the used data from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries" class="section level1">
<h1>2 Import the libraries</h1>
<pre class="r"><code>from preprocessing_CNN import Train_Validation_Test_Split

import numpy as np
import pandas as pd

import os
import shutil

import pickle as pk

import cv2 
import matplotlib.pyplot as plt
%matplotlib inline 

from keras import layers
from keras import models
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model

from keras.applications import VGG19</code></pre>
</div>
<div id="data-pre-processing" class="section level1">
<h1>3 Data pre-processing</h1>
<p>How the data for a CNN model training must be prepared I have already explained in this post: <a href="https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/">Computer Vision - Convolutional Neural Network</a></p>
<p>The exact functionality of the code I have explained in this post: <a href="https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/#train-validation-test-split">Automate the Boring Stuff</a></p>
<p>Please download the two folders <em>cats</em> and <em>dogs</em> from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a> and navigate to the project’s root directory in the terminal. The notebook must be started from the location where the two files are stored.</p>
<div id="train-validation-test-split" class="section level2">
<h2>3.1 Train-Validation-Test Split</h2>
<p>For this please download the preprocessing_CNN.py file from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a> and place this file next to the folders <em>cats</em> and <em>dogs</em> and start your Jupyter notebook from here.</p>
<pre class="r"><code>c_train, d_train, c_val, d_val, c_test, d_test = Train_Validation_Test_Split(&#39;cats&#39;, &#39;dogs&#39;)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p1.png" /></p>
</div>
<div id="obtaining-the-lists-of-randomly-selected-images" class="section level2">
<h2>3.2 Obtaining the lists of randomly selected images</h2>
<pre class="r"><code>list_cats_training = c_train
list_dogs_training = d_train

list_cats_validation = c_val
list_dogs_validation = d_val

list_cats_test = c_test
list_dogs_test = d_test</code></pre>
</div>
<div id="determination-of-the-directories" class="section level2">
<h2>3.3 Determination of the directories</h2>
<pre class="r"><code>root_directory = os.getcwd()

train_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train&#39;)
validation_dir = os.path.join(root_directory, &#39;cats_and_dogs\\validation&#39;)
test_dir = os.path.join(root_directory, &#39;cats_and_dogs\\test&#39;)</code></pre>
</div>
<div id="obtain-the-total-number-of-training-validation-and-test-images" class="section level2">
<h2>3.4 Obtain the total number of training, validation and test images</h2>
<pre class="r"><code>num_cats_img_train = len(list_cats_training)
num_dogs_img_train = len(list_dogs_training)

num_train_images_total = num_cats_img_train + num_dogs_img_train

print(&#39;Total training cat images: &#39; + str(num_cats_img_train))
print(&#39;Total training dog images: &#39; + str(num_dogs_img_train))
print()
print(&#39;Total training images: &#39; + str(num_train_images_total))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p2.png" /></p>
<pre class="r"><code>num_cats_img_validation = len(list_cats_validation)
num_dogs_img_validation = len(list_dogs_validation)

num_validation_images_total = num_cats_img_validation + num_dogs_img_validation

print(&#39;Total validation cat images: &#39; + str(num_cats_img_validation))
print(&#39;Total validation dog images: &#39; + str(num_dogs_img_validation))
print()
print(&#39;Total validation images: &#39; + str(num_validation_images_total))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p3.png" /></p>
<pre class="r"><code>num_cats_img_test = len(list_cats_test)
num_dogs_img_test = len(list_dogs_test)

num_test_images_total = num_cats_img_test + num_dogs_img_test

print(&#39;Total test cat images: &#39; + str(num_cats_img_test))
print(&#39;Total test dog images: &#39; + str(num_dogs_img_test))
print()
print(&#39;Total test images: &#39; + str(num_test_images_total))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p4.png" /></p>
</div>
</div>
<div id="feature-extraction-without-data-augmentation" class="section level1">
<h1>4 Feature Extraction without Data Augmentation</h1>
<div id="name-definitions" class="section level2">
<h2>4.1 Name Definitions</h2>
<pre class="r"><code>checkpoint_no = &#39;ckpt_1_CNN_with_TF_VGG19&#39;
model_name = &#39;Cats_Dogs_CNN_TF_VGG19_epoch_30&#39;</code></pre>
</div>
<div id="parameter-settings" class="section level2">
<h2>4.2 Parameter Settings</h2>
<pre class="r"><code>img_height = 150
img_width = 150
input_shape = (img_height, img_width, 3)

n_batch_size = 32

n_epochs = 30

print(&#39;Input Shape: &#39;+&#39;(&#39;+str(img_height)+&#39;, &#39;+str(img_width)+&#39;, &#39; + str(3)+&#39;)&#39;)
print(&#39;Batch Size: &#39; + str(n_batch_size))
print()
print(&#39;Number of Epochs: &#39; + str(n_epochs))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p5.png" /></p>
</div>
<div id="instantiating-the-vgg19-convolutional-base" class="section level2">
<h2>4.3 Instantiating the VGG19 convolutional base</h2>
<pre class="r"><code>VGG19_base = VGG19(weights=&#39;imagenet&#39;,
                  include_top=False,
                  input_shape=input_shape)

conv_base = VGG19_base</code></pre>
<pre class="r"><code>conv_base.summary()</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p6.png" /></p>
</div>
<div id="feature-extraction" class="section level2">
<h2>4.4 Feature Extraction</h2>
<div id="get-output-shape-of-last-layer" class="section level3">
<h3>4.4.1 Get Output Shape of last Layer</h3>
<pre class="r"><code>df_temp = pd.DataFrame()

for layer in conv_base.layers:
    layer_output_shape = layer.output_shape

    df1 = {&#39;Output_Shape&#39;: layer_output_shape}
    df_temp = df_temp.append(df1, ignore_index=True)

df_temp</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p7.png" /></p>
<pre class="r"><code>df_temp = df_temp.loc[df_temp.index == df_temp.index.max()]
df_temp = df_temp[&#39;Output_Shape&#39;].iloc[0]
df_temp</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p8.png" /></p>
<pre class="r"><code>df_temp2 = pd.DataFrame(df_temp).T
df_temp2.columns= [&#39;batch_size&#39;, &#39;pooled_rows&#39;, &#39;pooled_cols&#39;, &#39;channels&#39;]
df_temp2[&#39;pooled_rows&#39;] = df_temp2[&#39;pooled_rows&#39;].astype(&#39;int64&#39;)
df_temp2[&#39;pooled_cols&#39;] = df_temp2[&#39;pooled_cols&#39;].astype(&#39;int64&#39;)
df_temp2[&#39;channels&#39;] = df_temp2[&#39;channels&#39;].astype(&#39;int64&#39;)
df_temp2</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p9.png" /></p>
<pre class="r"><code>n_pooled_rows = df_temp2[&#39;pooled_rows&#39;].iloc[0]
n_pooled_cols = df_temp2[&#39;pooled_cols&#39;].iloc[0]
n_channels = df_temp2[&#39;channels&#39;].iloc[0]

print(&#39;Number of pooled rows: &#39; + str(n_pooled_rows))
print(&#39;Number of pooled cols: &#39; + str(n_pooled_cols))
print(&#39;Number of channels: &#39; + str(n_channels))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p10.png" /></p>
</div>
<div id="extracting-features-using-the-pretrained-convolutional-base" class="section level3">
<h3>4.4.2 Extracting features using the pretrained convolutional base</h3>
<pre class="r"><code>datagen = ImageDataGenerator(rescale=1./255)


def extract_features(directory, sample_count):
    features = np.zeros(shape=(sample_count, n_pooled_rows, n_pooled_cols, n_channels))
    labels = np.zeros(shape=(sample_count))
    generator = datagen.flow_from_directory(
        directory,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)
    
    class_assignments = generator.class_indices
    
    i = 0
    for inputs_batch, labels_batch in generator:
        features_batch = conv_base.predict(inputs_batch)
        features[i * n_batch_size : (i + 1) * n_batch_size] = features_batch
        labels[i * n_batch_size : (i + 1) * n_batch_size] = labels_batch
        i += 1
        if i * n_batch_size &gt;= sample_count:
            break
    return features, labels, class_assignments</code></pre>
<pre class="r"><code>train_features, train_labels, train_class_assignments = extract_features(train_dir, num_train_images_total)
validation_features, validation_labels, validation_class_assignments = extract_features(validation_dir, num_validation_images_total)
test_features, test_labels, test_class_assignments = extract_features(test_dir, num_test_images_total)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p11.png" /></p>
</div>
<div id="reshape-train--validation--and-test-features" class="section level3">
<h3>4.4.3 Reshape train-, validation- and test features</h3>
<p>The extracted features are currently of shape <em>(samples, 4, 4, 512)</em>. We are going to feed them to a densely connected classifier, so first we must flatten them to <em>(samples, 8192)</em>.</p>
<pre class="r"><code>train_features = np.reshape(train_features, (num_train_images_total, 
                                             n_pooled_rows * n_pooled_cols * n_channels))

validation_features = np.reshape(validation_features, (num_validation_images_total, 
                                                       n_pooled_rows * n_pooled_cols * n_channels))

test_features = np.reshape(test_features, (num_test_images_total, 
                                           n_pooled_rows * n_pooled_cols * n_channels))</code></pre>
</div>
<div id="instantiating-a-densely-connected-classifier" class="section level3">
<h3>4.5 Instantiating a densely connected classifier</h3>
</div>
<div id="layer-structure" class="section level3">
<h3>4.5.1 Layer Structure</h3>
<pre class="r"><code>model = models.Sequential()
model.add(layers.Dense(256, activation=&#39;relu&#39;, 
                       input_dim= n_pooled_rows * n_pooled_cols * n_channels))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation=&#39;sigmoid&#39;))</code></pre>
<pre class="r"><code>model.summary()</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p12.png" /></p>
</div>
<div id="configuring-the-model-for-training" class="section level3">
<h3>4.5.2 Configuring the model for training</h3>
<pre class="r"><code>model.compile(loss=&#39;binary_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])</code></pre>
</div>
</div>
<div id="callbacks" class="section level2">
<h2>4.6 Callbacks</h2>
<pre class="r"><code># Prepare a directory to store all the checkpoints.
checkpoint_dir = checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)</code></pre>
<pre class="r"><code>keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + &#39;/&#39; + model_name, 
                                   monitor=&#39;val_loss&#39;, save_best_only=True, mode=&#39;auto&#39;)]</code></pre>
</div>
<div id="fitting-the-model" class="section level2">
<h2>4.7 Fitting the model</h2>
<pre class="r"><code>history = model.fit(
    train_features, train_labels,
    epochs = n_epochs,
    batch_size = n_batch_size,
    validation_data = (validation_features, validation_labels),
    callbacks=keras_callbacks)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p12.png" /></p>
</div>
<div id="obtaining-the-best-model-values" class="section level2">
<h2>4.8 Obtaining the best model values</h2>
<pre class="r"><code>hist_df = pd.DataFrame(history.history)
hist_df[&#39;epoch&#39;] = hist_df.index + 1
cols = list(hist_df.columns)
cols = [cols[-1]] + cols[:-1]
hist_df = hist_df[cols]
hist_df.to_csv(checkpoint_no + &#39;/&#39; + &#39;history_df_&#39; + model_name + &#39;.csv&#39;)
hist_df.head()</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p13.png" /></p>
<pre class="r"><code>values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]
values_of_best_model</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p14.png" /></p>
</div>
<div id="obtaining-class-assignments" class="section level2">
<h2>4.9 Obtaining class assignments</h2>
<pre class="r"><code>class_assignment = train_class_assignments

df = pd.DataFrame([class_assignment], columns=class_assignment.keys())
df_stacked = df.stack()
df_temp = pd.DataFrame(df_stacked).reset_index().drop([&#39;level_0&#39;], axis=1)
df_temp.columns = [&#39;Category&#39;, &#39;Allocated Number&#39;]
df_temp.to_csv(checkpoint_no + &#39;/&#39; + &#39;class_assignment_df_&#39; + model_name + &#39;.csv&#39;)

print(&#39;Class assignment:&#39;, str(class_assignment))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p15.png" /></p>
</div>
<div id="validation" class="section level2">
<h2>4.10 Validation</h2>
<pre class="r"><code>acc = history.history[&#39;accuracy&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, &#39;bo&#39;, label=&#39;Training acc&#39;)
plt.plot(epochs, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;)
plt.title(&#39;Training and validation accuracy&#39;)
plt.legend()

plt.figure()

plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.legend()

plt.show()</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p16.png" /></p>
</div>
<div id="load-best-model" class="section level2">
<h2>4.11 Load best model</h2>
<pre class="r"><code># Loading the automatically saved model
model_reloaded = load_model(checkpoint_no + &#39;/&#39; + model_name)

# Saving the best model in the correct path and format
root_directory = os.getcwd()
checkpoint_dir = os.path.join(root_directory, checkpoint_no)
model_name_temp = os.path.join(checkpoint_dir, model_name + &#39;.h5&#39;)
model_reloaded.save(model_name_temp)

# Deletion of the automatically created folder under Model Checkpoint File.
folder_name_temp = os.path.join(checkpoint_dir, model_name)
shutil.rmtree(folder_name_temp, ignore_errors=True)</code></pre>
<pre class="r"><code>best_model = load_model(model_name_temp)</code></pre>
</div>
<div id="model-testing" class="section level2">
<h2>4.12 Model Testing</h2>
<pre class="r"><code>test_loss, test_acc = best_model.evaluate(test_features, test_labels, 
                                          batch_size = n_batch_size)
print()
print(&#39;Test Accuracy:&#39;, test_acc)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p17.png" /></p>
<pre class="r"><code>pk.dump(img_height, open(checkpoint_dir+ &#39;\\&#39; +&#39;img_height.pkl&#39;, &#39;wb&#39;))
pk.dump(img_width, open(checkpoint_dir+ &#39;\\&#39; +&#39;img_width.pkl&#39;, &#39;wb&#39;))

pk.dump(n_pooled_rows, open(checkpoint_dir+ &#39;\\&#39; +&#39;n_pooled_rows.pkl&#39;, &#39;wb&#39;))
pk.dump(n_pooled_cols, open(checkpoint_dir+ &#39;\\&#39; +&#39;n_pooled_cols.pkl&#39;, &#39;wb&#39;))
pk.dump(n_channels, open(checkpoint_dir+ &#39;\\&#39; +&#39;n_channels.pkl&#39;, &#39;wb&#39;))</code></pre>
</div>
<div id="test-out-of-the-box-pictures" class="section level2">
<h2>4.13 Test Out of the Box Pictures</h2>
<pre class="r"><code># Determine Checkpoint Dir
checkpoint_dir = &#39;ckpt_1_CNN_with_TF_VGG19&#39;

# Load best model
best_model = load_model(checkpoint_dir + &#39;/&#39; + &#39;Cats_Dogs_CNN_TF_VGG19_epoch_30.h5&#39;)

# Load the categories
df = pd.read_csv(checkpoint_dir + &#39;/&#39; + &#39;class_assignment_df_Cats_Dogs_CNN_TF_VGG19_epoch_30.csv&#39;)
df = df.sort_values(by=&#39;Allocated Number&#39;, ascending=True)
CATEGORIES = df[&#39;Category&#39;].to_list()


# Load the used image height and width
img_height_reload = pk.load(open(checkpoint_dir + &#39;/&#39; + &#39;img_height.pkl&#39;,&#39;rb&#39;))
img_width_reload = pk.load(open(checkpoint_dir + &#39;/&#39; + &#39;img_width.pkl&#39;,&#39;rb&#39;))


# Load the used n_pooled_rows, n_pooled_cols and n_channels
n_pooled_rows_reload = pk.load(open(checkpoint_dir + &#39;/&#39; + &#39;n_pooled_rows.pkl&#39;,&#39;rb&#39;))
n_pooled_cols_reload = pk.load(open(checkpoint_dir + &#39;/&#39; + &#39;n_pooled_cols.pkl&#39;,&#39;rb&#39;))
n_channels_reload = pk.load(open(checkpoint_dir + &#39;/&#39; + &#39;n_channels.pkl&#39;,&#39;rb&#39;))

print(&#39;Model Summary :&#39; + str(best_model.summary()))
print()
print()
print(&#39;CATEGORIES : &#39; + str(CATEGORIES))
print()
print(&#39;Used image height: &#39; + str(img_height_reload))
print(&#39;Used image width: &#39; + str(img_width_reload))
print()
print(&#39;Used n_pooled_rows: &#39; + str(n_pooled_rows))
print(&#39;Used n_pooled_cols: &#39; + str(n_pooled_cols))
print(&#39;Used n_channels: &#39; + str(n_channels))</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p18.png" /></p>
<pre class="r"><code>img_pred = cv2.imread(&#39;out of the box pic/test_cat_pic_1.jpg&#39;)

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = np.zeros(shape=(1, n_pooled_rows_reload, n_pooled_cols_reload, n_channels_reload))
img_pred = np.reshape(img_pred, (1, n_pooled_rows_reload * n_pooled_cols_reload * n_channels_reload))

classes = (best_model.predict(img_pred) &gt; 0.5).astype(&quot;int32&quot;)

print()
print(&#39;------------------------------------&#39;)
print(&#39;Predicted Class: &#39; + CATEGORIES[int(classes[0])])
print(&#39;------------------------------------&#39;)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p19.png" /></p>
<pre class="r"><code>img_pred = cv2.imread(&#39;out of the box pic/test_cat_pic_2.jpg&#39;)

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = np.zeros(shape=(1, n_pooled_rows_reload, n_pooled_cols_reload, n_channels_reload))
img_pred = np.reshape(img_pred, (1, n_pooled_rows_reload * n_pooled_cols_reload * n_channels_reload))

classes = (best_model.predict(img_pred) &gt; 0.5).astype(&quot;int32&quot;)

print()
print(&#39;------------------------------------&#39;)
print(&#39;Predicted Class: &#39; + CATEGORIES[int(classes[0])])
print(&#39;------------------------------------&#39;)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p20.png" /></p>
<pre class="r"><code>img_pred = cv2.imread(&#39;out of the box pic/test_dog_pic_1.jpg&#39;)

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = np.zeros(shape=(1, n_pooled_rows_reload, n_pooled_cols_reload, n_channels_reload))
img_pred = np.reshape(img_pred, (1, n_pooled_rows_reload * n_pooled_cols_reload * n_channels_reload))

classes = (best_model.predict(img_pred) &gt; 0.5).astype(&quot;int32&quot;)

print()
print(&#39;------------------------------------&#39;)
print(&#39;Predicted Class: &#39; + CATEGORIES[int(classes[0])])
print(&#39;------------------------------------&#39;)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p21.png" /></p>
<pre class="r"><code>img_pred = cv2.imread(&#39;out of the box pic/test_dog_pic_2.jpg&#39;)

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = np.zeros(shape=(1, n_pooled_rows_reload, n_pooled_cols_reload, n_channels_reload))
img_pred = np.reshape(img_pred, (1, n_pooled_rows_reload * n_pooled_cols_reload * n_channels_reload))

classes = (best_model.predict(img_pred) &gt; 0.5).astype(&quot;int32&quot;)

print()
print(&#39;------------------------------------&#39;)
print(&#39;Predicted Class: &#39; + CATEGORIES[int(classes[0])])
print(&#39;------------------------------------&#39;)</code></pre>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p22.png" /></p>
</div>
</div>
<div id="feature-extraction-with-data-augmentation" class="section level1">
<h1>5 Feature Extraction with Data Augmentation</h1>
<div id="name-definitions-1" class="section level2">
<h2>5.1 Name Definitions</h2>
<pre class="r"><code>checkpoint_no = &#39;ckpt_2_CNN_with_TF_VGG19_with_DataAug&#39;
model_name = &#39;Cats_Dogs_CNN_TF_VGG19_with_DataAug_epoch_30_ES&#39;</code></pre>
</div>
<div id="parameter-settings-1" class="section level2">
<h2>5.2 Parameter Settings</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="instantiating-the-vgg19-convolutional-base-1" class="section level2">
<h2>5.3 Instantiating the VGG19 convolutional base</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="instantiating-a-densely-connected-classifier-1" class="section level2">
<h2>5.4 Instantiating a densely connected classifier</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
<div id="layer-structure-1" class="section level3">
<h3>5.4.1 Layer Structure</h3>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="configuring-the-model-for-training-1" class="section level3">
<h3>5.4.2 Configuring the model for training</h3>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="using-imagedatagenerator" class="section level3">
<h3>5.4.3 Using ImageDataGenerator</h3>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
</div>
<div id="callbacks-1" class="section level2">
<h2>5.5 Callbacks</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="fitting-the-model-1" class="section level2">
<h2>5.6 Fitting the model</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="obtaining-the-best-model-values-1" class="section level2">
<h2>5.7 Obtaining the best model values</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="obtaining-class-assignments-1" class="section level2">
<h2>5.8 Obtaining class assignments</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="validation-1" class="section level2">
<h2>5.9 Validation</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="load-best-model-1" class="section level2">
<h2>5.10 Load best model</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="model-testing-1" class="section level2">
<h2>5.11 Model Testing</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
<div id="test-out-of-the-box-pictures-1" class="section level2">
<h2>5.12 Test Out of the Box Pictures</h2>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
<p><img src="/post/2021-01-17-computer-vision-cnn-with-transfer-learning_files/p106p.png" /></p>
</div>
</div>
