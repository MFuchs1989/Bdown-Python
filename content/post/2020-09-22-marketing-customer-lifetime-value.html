---
title: Marketing - Customer Lifetime Value
author: Michael Fuchs
date: '2020-09-22'
slug: marketing-customer-lifetime-value
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-data">2 Import the libraries and the data</a></li>
<li><a href="#data-pre-processing">3 Data pre-processing</a>
<ul>
<li><a href="#negative-quantity">3.1 Negative Quantity</a></li>
<li><a href="#missing-values-within-customerid">3.2 Missing Values within CustomerID</a></li>
<li><a href="#handling-incomplete-data">3.3 Handling incomplete data</a></li>
<li><a href="#total-sales">3.4 Total Sales</a></li>
<li><a href="#create-final-dataframe">3.5 Create final dataframe</a></li>
</ul></li>
<li><a href="#descriptive-analytics">4 Descriptive Analytics</a>
<ul>
<li><a href="#final-dataframe-for-descriptive-analytics">4.1 Final Dataframe for Descriptive Analytics</a></li>
<li><a href="#visualizations">4.2 Visualizations</a></li>
</ul></li>
<li><a href="#predicting-3-month-clv">5 Predicting 3-Month CLV</a>
<ul>
<li><a href="#final-dataframe-for-prediction-models">5.1 Final Dataframe for Prediction Models</a></li>
<li><a href="#building-sample-set">5.2 Building Sample Set</a></li>
<li><a href="#train-test-split">5.3 Train Test Split</a></li>
<li><a href="#linear-regression">5.4 Linear Regression</a></li>
<li><a href="#model-evaluation">5.5 Model Evaluation</a></li>
</ul></li>
<li><a href="#conclusion">6 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83s1.png" /></p>
<p>In marketing, customer lifetime value is one of the most important metrics to keep in mind.
This metric is especially important to keep track of for acquiring new customers.
The corporate goal of marketing kampagnien is always the acquisition of new customers under the premise of a positive ROI.
For example, if the average CLV of our customer is 100€ and it only costs 50€ to acquire a new customer, then our business will be generationg more revenue as we acquire new customers.
If this is the other way around, our company is making losses. This is to be avoided and for this reason the CLV should always be observed.</p>
<p>There are multiple ways to calculate CLV. One way is to find the customer’s average purchase amount, purchase frequency and lifetime span to do a simple calculation to get the CLV.</p>
<p>Let us assume the following conditions:</p>
<ul>
<li>Customer’s average purchase amount: 100€</li>
<li>Purchase frequency: 5 times per month</li>
</ul>
<p>This makes an average value per month of 500€.
Now let’s come to the lifetime span.
One way to estimate a customer’s lifetime span is to look at the average monthly churn rate, which is the percentage of customers leaving and terminating the relationship whith our business. We can estimate a customer’s lifetime span by dividing one by the churn rate. Assuming 5% of the churn rate, the estimated customer’s lifetime span is 20 years.</p>
<ul>
<li>Lifetime span: 20 years</li>
</ul>
<p>This results in a total amount of 120,000€ (500€ x 20 years x 12 months).</p>
<p>Because we do not typically know the lifetime span of customers, we often try to estimate CLV over the course of a certain period (3 months, 12 months, 24 months …). And that is exactly what we will do in the following.</p>
<p>For this post the dataset <em>Online Retail</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>2 Import the libraries and the data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np


import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics</code></pre>
<pre class="r"><code>df = pd.read_excel(&#39;Online Retail.xlsx&#39;, sheet_name=&#39;Online Retail&#39;)
df</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p1.png" /></p>
</div>
<div id="data-pre-processing" class="section level1">
<h1>3 Data pre-processing</h1>
<div id="negative-quantity" class="section level2">
<h2>3.1 Negative Quantity</h2>
<pre class="r"><code>&#39;&#39;&#39;
Canceled orders could cause negative values in the data record.
To be on the safe side, these are removed.
&#39;&#39;&#39;

df = df.loc[df[&#39;Quantity&#39;] &gt; 0]
df.shape</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p2.png" /></p>
<p>As we can see from the output, this was not the case in this record.</p>
</div>
<div id="missing-values-within-customerid" class="section level2">
<h2>3.2 Missing Values within CustomerID</h2>
<pre class="r"><code>&#39;&#39;&#39;
We need to drop observations with no CustomerID
&#39;&#39;&#39;

df = df[pd.notnull(df[&#39;CustomerID&#39;])]
df.shape</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p3.png" /></p>
</div>
<div id="handling-incomplete-data" class="section level2">
<h2>3.3 Handling incomplete data</h2>
<pre class="r"><code>print(&#39;Invoice Date Range: %s - %s&#39; % (df[&#39;InvoiceDate&#39;].min(), df[&#39;InvoiceDate&#39;].max()))</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p4.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Due to the fact that we only need full months for future analysis, we will shorten this data set accordingly.
&#39;&#39;&#39;

df = df.loc[df[&#39;InvoiceDate&#39;] &lt; &#39;2011-12-01&#39;]
df.shape</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p5.png" /></p>
</div>
<div id="total-sales" class="section level2">
<h2>3.4 Total Sales</h2>
<pre class="r"><code>&#39;&#39;&#39;
For further analysis we need another column Sales.
&#39;&#39;&#39;
df[&#39;Sales&#39;] = df[&#39;Quantity&#39;] * df[&#39;UnitPrice&#39;]
df.head()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p6.png" /></p>
</div>
<div id="create-final-dataframe" class="section level2">
<h2>3.5 Create final dataframe</h2>
<pre class="r"><code>&#39;&#39;&#39;
Here we group the dataframe by CustimerID and InvoiceNo and 
aggregate the Sales column as well as the InvoiceDate.
&#39;&#39;&#39;

orders_df = df.groupby([&#39;CustomerID&#39;, &#39;InvoiceNo&#39;]).agg({
    &#39;Sales&#39;: sum,
    &#39;InvoiceDate&#39;: max
})

orders_df.head()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p7.png" /></p>
</div>
</div>
<div id="descriptive-analytics" class="section level1">
<h1>4 Descriptive Analytics</h1>
<div id="final-dataframe-for-descriptive-analytics" class="section level2">
<h2>4.1 Final Dataframe for Descriptive Analytics</h2>
<pre class="r"><code>&#39;&#39;&#39;
For the preparation of the data for descriptive part we need the following functions:
&#39;&#39;&#39;


def groupby_mean(x):
    return x.mean()

def groupby_count(x):
    return x.count()

def purchase_duration(x):
    return (x.max() - x.min()).days

def avg_frequency(x):
    return (x.max() - x.min()).days/x.count()

groupby_mean.__name__ = &#39;avg&#39;
groupby_count.__name__ = &#39;count&#39;
purchase_duration.__name__ = &#39;purchase_duration&#39;
avg_frequency.__name__ = &#39;purchase_frequency&#39;</code></pre>
<p>We re-group the record by CustomerID and aggregate the Sales and InvoiceDate columns with the previously created functions.</p>
<pre class="r"><code>summary_df = orders_df.reset_index().groupby(&#39;CustomerID&#39;).agg({
    &#39;Sales&#39;: [min, max, sum, groupby_mean, groupby_count],
    &#39;InvoiceDate&#39;: [min, max, purchase_duration, avg_frequency]
})

summary_df.head()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p8.png" /></p>
<p>This still looks a bit messy now but we can / must make it a bit nicer.</p>
<pre class="r"><code>summary_df.columns = [&#39;_&#39;.join(col).lower() for col in summary_df.columns]
summary_df = summary_df.reset_index()
summary_df.head()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p9.png" /></p>
<p>This dataset gives us an idea of the purchases each customer has made. Let’s have a look at CustomerID 12346 (first row). This customer made only one purchase on January 18,2011.</p>
<p>The second customer (12347) has made six purchases within December 7, 2010 and October 31, 2011. The timespan here is about 327 days. The average amount this customer spent on each order is 680. We also see from the record, that this customer made a purchase every 54.5 days.</p>
</div>
<div id="visualizations" class="section level2">
<h2>4.2 Visualizations</h2>
<p>For the visualization part we are only interested in the purchases that the repeat customers have made.</p>
<pre class="r"><code>summary_df = summary_df.loc[summary_df[&#39;invoicedate_purchase_duration&#39;] &gt; 0]
summary_df.shape</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p10.png" /></p>
<p>As we can see, there are only 2692 (of 4298) repeat customers in the record.</p>
<pre class="r"><code>&#39;&#39;&#39;
This plot shows the distributions of the number of purchases that the repeat customers have made
&#39;&#39;&#39;

ax = summary_df.groupby(&#39;sales_count&#39;).count()[&#39;sales_avg&#39;][:20].plot(
    kind=&#39;bar&#39;, 
    color=&#39;skyblue&#39;,
    figsize=(12,7), 
    grid=True
)

ax.set_ylabel(&#39;count&#39;)
plt.title(&#39;Number of purchases that the repeat customers have made&#39;)

plt.show()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p11.png" /></p>
<p>As we can see from this plot, the majority of customers have made 10 or less purchases.
Here a few more metrics about sales_count:</p>
<pre class="r"><code>summary_df[&#39;sales_count&#39;].describe()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p12.png" /></p>
<p>Now we are going to have a look at the average number of days between purchases for these repeat customers.</p>
<pre class="r"><code>&#39;&#39;&#39;
This plot shows the average number of days between purchases for repeat customers.
It is an overall view of how frequently repeat customers made purchases historically.
&#39;&#39;&#39;

ax = summary_df[&#39;invoicedate_purchase_frequency&#39;].hist(
    bins=20,
    color=&#39;skyblue&#39;,
    rwidth=0.7,
    figsize=(12,7)
)

ax.set_xlabel(&#39;avg. number of days between purchases&#39;)
ax.set_ylabel(&#39;count&#39;)
plt.title(&#39;Number of days between purchases for repeat customers&#39;)

plt.show()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p13.png" /></p>
<p>As we can see from this plot, the majority of repeat customers made purchases every 20-50 days.</p>
</div>
</div>
<div id="predicting-3-month-clv" class="section level1">
<h1>5 Predicting 3-Month CLV</h1>
<div id="final-dataframe-for-prediction-models" class="section level2">
<h2>5.1 Final Dataframe for Prediction Models</h2>
<p>We use the final created dataset <em>orders_df</em> at this point (chapter Data pre-processing / Create final dataframe)</p>
<pre class="r"><code># Determine the frequency
clv_freq = &#39;3M&#39;

# Group by CustomerID 
# Break down the data into chunks of 3 months for each customer
# Aggregate the sales column by sum
# Aggregate the sales column by average_sum and count (both with the previous created functions)
data_df = orders_df.reset_index().groupby([
    &#39;CustomerID&#39;,
    pd.Grouper(key=&#39;InvoiceDate&#39;, freq=clv_freq)
]).agg({
    &#39;Sales&#39;: [sum, groupby_mean, groupby_count],
})

# Bring the dataset in a readable format
data_df.columns = [&#39;_&#39;.join(col).lower() for col in data_df.columns]
data_df = data_df.reset_index()
data_df.head()</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p14.png" /></p>
<p>Now we are going to encode the InvoiceDate column values so that they are easier to read than the current date format.</p>
<pre class="r"><code># Set the length of the column InvoiceDate. In our case = 10
length_of_InvoiceDate = 10

date_month_map = {
    str(x)[:length_of_InvoiceDate]: &#39;M_%s&#39; % (i+1) for i, x in enumerate(
        sorted(data_df.reset_index()[&#39;InvoiceDate&#39;].unique(), reverse=True)
    )
}
date_month_map</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p15.png" /></p>
<p>As you can see, we encoded the date values into M_1, M_2 and so on.</p>
<pre class="r"><code>&#39;&#39;&#39;
Apply the generated dictionary to the dataframe for prediction models
&#39;&#39;&#39;

data_df[&#39;M&#39;] = data_df[&#39;InvoiceDate&#39;].apply(lambda x: date_month_map[str(x)[:length_of_InvoiceDate]])
data_df.head(10)</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p16.png" /></p>
</div>
<div id="building-sample-set" class="section level2">
<h2>5.2 Building Sample Set</h2>
<p>Now we are ready to create a sample set with features and target variables. In this case, we are going to use the last 3 months as the target variable and the rest as the features. In other words, we are going to train a machie learning model that predicts the last 3 months’customer value with the rest of the data.</p>
<pre class="r"><code># Exclude M_1 because this will be our predictor variable.
features_df = pd.pivot_table(
    data_df.loc[data_df[&#39;M&#39;] != &#39;M_1&#39;], 
    values=[&#39;sales_sum&#39;, &#39;sales_avg&#39;, &#39;sales_count&#39;], 
    columns=&#39;M&#39;, 
    index=&#39;CustomerID&#39;
)

# Prepare the features dataframe for better view
features_df.columns = [&#39;_&#39;.join(col) for col in features_df.columns]

# Encode NaN values with 0.0
features_df = features_df.fillna(0)
features_df</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p17.png" /></p>
<pre class="r"><code># Just select M_1 because this is our target variable
response_df = data_df.loc[
    data_df[&#39;M&#39;] == &#39;M_1&#39;,
    [&#39;CustomerID&#39;, &#39;sales_sum&#39;]
]

# Rename the columns accordingly
response_df.columns = [&#39;CustomerID&#39;, &#39;CLV_&#39;+clv_freq]
response_df</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p18.png" /></p>
<pre class="r"><code># Join the features_df and response_df  on CustomerID
sample_set_df = features_df.merge(
    response_df, 
    left_index=True, 
    right_on=&#39;CustomerID&#39;,
    how=&#39;left&#39;
)

# Encode NaN values with 0.0
sample_set_df = sample_set_df.fillna(0)

sample_set_df</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p19.png" /></p>
</div>
<div id="train-test-split" class="section level2">
<h2>5.3 Train Test Split</h2>
<pre class="r"><code>target_var = &#39;CLV_&#39;+clv_freq
all_features = [x for x in sample_set_df.columns if x not in [&#39;CustomerID&#39;, target_var]]

print()
print(&#39;Target Variable: &#39; + str(target_var))
print()
print(&#39;----------------------------------------------------&#39;)
print()
print(&#39;Predictor Variables:&#39;)
print(all_features)</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p20.png" /></p>
<pre class="r"><code>&#39;&#39;&#39;
Here we are going to do a train test split with a division of 70% to 30%.
&#39;&#39;&#39;

trainX, testX, trainY, testY  = train_test_split(
    sample_set_df[all_features], 
    sample_set_df[target_var], 
    test_size=0.3
)</code></pre>
</div>
<div id="linear-regression" class="section level2">
<h2>5.4 Linear Regression</h2>
<pre class="r"><code>lm = LinearRegression()
lm.fit(trainX, trainY)</code></pre>
<pre class="r"><code>coef = pd.DataFrame(list(zip(all_features, lm.coef_)))
coef.columns = [&#39;feature&#39;, &#39;Coefficient&#39;]

coef</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p21.png" /></p>
<p>Whith this overview we easily can see which features have negative or positive correlation with the target variable.</p>
<p>For example, the previous 3 month period’s average purchase amount, sales_avg_M_2 (line 1), has positive impacts on the next 3 month customer value. This means that the higher the previous 3 month period’s average purchase amount is, the higher the next 3 month purchase amount will be.</p>
<p>On the other hand, the second and third most recent 3 month period’s average purchase amounts, sales_avg_M_3 and sales_avg_M_4, are negatively correlated with the next 3 month customer value. In other words, the more a customer made purchases 3 months to 9 months ago, the lower value he or she will bring in the next 3 months.</p>
</div>
<div id="model-evaluation" class="section level2">
<h2>5.5 Model Evaluation</h2>
<pre class="r"><code>y_pred = lm.predict(testX)

print(&#39;Mean Absolute Error:&#39;, metrics.mean_absolute_error(testY, y_pred))  
print(&#39;Mean Squared Error:&#39;, metrics.mean_squared_error(testY, y_pred))  
print(&#39;Root Mean Squared Error:&#39;, np.sqrt(metrics.mean_squared_error(testY, y_pred)))</code></pre>
<p><img src="/post/2020-09-22-marketing-customer-lifetime-value_files/p83p22.png" /></p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>6 Conclusion</h1>
<p>In this post I have explained what the customer lifetime value is and how to run descriptive statistics on its underlying metrics.</p>
<p>I also showed how to prepare the data set for a three month prediction of the CLV and train a machine learning model.</p>
<p>I explained how to draw valuable conclusions about past periods from the results of the linear model and evaluate these insights.</p>
<p>Finally, I will say a few words about the advantages of such an analysis for a company:</p>
<p>Since you know the expected revenue or purchase amount from individual customers for the next 3 months, you can set a better informed budget for your marketing campaign. This should not be set too high but also not too low, so that the target customers are still reached but the ROI does not suffer.</p>
<p>On the other hand you can also use these 3 month customer value prediction output values to specifically target these high-value customers for the next 3 months. This can help you to create marketing campaigns with a higher ROI, as those high-value customers, predicted by the machine learning model, are likely to bring in more revenue than the others.</p>
<p><strong>References</strong></p>
<p>Besemer, S. P. (1998). Creative product analysis matrix: testing the model structure and a comparison among products–three novel chairs. Creativity Research Journal, 11(4), 333-346.</p>
<p>Do Ruibin, K., &amp; Vintilescu Borglöv, T. (2018). Predicting Customer Lifetime Value: Understanding its accuracy and drivers from a frequent flyer program perspective.</p>
<p>Glady, N., Baesens, B., &amp; Croux, C. (2009). Modeling churn using customer lifetime value. European Journal of Operational Research, 197(1), 402-411.</p>
<p>Hwang, Y. (2019). Hands-On Data Science for Marketing: Improve your marketing strategies with machine learning using Python and R. Packt Publishing Ltd.</p>
<p>Johnston, B., Jones, A. &amp; Kruger, C. (2019). Applied Unsupervised Learning with Python : Discover hidden patterns and relationships in unstructured data with Python.
Packt Publishing Ltd.</p>
<p>Miller, T. W. (2015). Marketing data science: modeling techniques in predictive analytics with R and Python. FT Press.</p>
<p>Provost, F., &amp; Fawcett, T. (2013). Data Science for Business: What you need to know about data mining and data-analytic thinking. " O’Reilly Media, Inc.".</p>
<p>Wedel, M., Kamakura, W., &amp; Böckenholt, U. (2000). Marketing data, models and decisions. International Journal of Research in Marketing, 17(2-3), 203-208.</p>
<p>Xu, Z., Frankwick, G. L., &amp; Ramirez, E. (2016). Effects of big data analytics and traditional marketing analytics on new product success: A knowledge fusion perspective. Journal of Business Research, 69(5), 1562-1566.</p>
</div>
