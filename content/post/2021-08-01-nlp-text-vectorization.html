---
title: NLP - Text Vectorization
author: Michael Fuchs
date: '2021-08-01'
slug: nlp-text-vectorization
categories: []
tags: []
output:
  blogdown::html_page:
    toc: yes
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-data">2 Import the Libraries and the Data</a></li>
<li><a href="#text-vectorization">3 Text Vectorization</a>
<ul>
<li><a href="#bag-of-wordsbow">3.1 Bag-of-Words(BoW)</a>
<ul>
<li><a href="#functionality">3.1.2 Functionality</a></li>
<li><a href="#creation-of-the-final-data-set">3.1.3 Creation of the final Data Set</a></li>
<li><a href="#test-of-a-sample-record">3.1.4 Test of a Sample Record</a></li>
</ul></li>
<li><a href="#n-grams">3.2 N-grams</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Now that we have cleaned up and prepared our text dataset in the previous posts, we come to the next topic: <strong>Text Vectorization</strong></p>
<p>Most machine learning algorithms cannot handle string variables. We have to convert them into a format that is readable for machine learning algorithms. Text vectorization is the mapping of vocabulary or tokens from a data set to a corresponding vector of real numbers. These vectors can be used as input to machine learning models.</p>
<p>In the following, I will use a simple example to show several ways in which vectorization can be done.</p>
<p>Finally, I will apply a vectorization method to the dataset (<a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/NLP/Text%20Pre-Processing%20-%20All%20in%20One">‘Amazon_Unlocked_Mobile_small_pre_processed.csv’</a>) created and processed in the <a href="https://michael-fuchs-python.netlify.app/2021/06/23/nlp-text-pre-processing-all-in-one/">last post</a> and train a machine learning model on it.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>2 Import the Libraries and the Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score</code></pre>
<pre class="r"><code>df = pd.DataFrame({&#39;Rating&#39;: [2,5,3],
                   &#39;Text&#39;: [&quot;This is a brown horse&quot;,
                            &quot;This horse likes to play&quot;,
                            &quot;The horse is in the stable&quot;]})
df</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p1.png" /></p>
</div>
<div id="text-vectorization" class="section level1">
<h1>3 Text Vectorization</h1>
<div id="bag-of-wordsbow" class="section level2">
<h2>3.1 Bag-of-Words(BoW)</h2>
<p>CountVectorizer() is one of the simplest methods of text vectorization.</p>
<p>It creates a sparse matrix consisting of a set of dummy variables. These indicate whether a certain word occurs in the document or not. The CountVectorizer function matches the word vocabulary, learns it, and creates a document term matrix where the individual cells indicate the frequency of that word in a given document.
This is also called term frequency where the columns are dedicated to each word in the corpus.</p>
<div id="functionality" class="section level3">
<h3>3.1.2 Functionality</h3>
<pre class="r"><code>cv = CountVectorizer()

cv_vectorizer = cv.fit(df[&#39;Text&#39;])
text_cv_vectorized = cv_vectorizer.transform(df[&#39;Text&#39;])

text_cv_vectorized_array = text_cv_vectorized.toarray()

print(text_cv_vectorized_array)
print()
print(text_cv_vectorized_array.shape)</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p2.png" /></p>
<p>10 different words were found in the text corpus. These can also be output as follows:</p>
<pre class="r"><code>cv_vectorizer.get_feature_names()</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p3.png" /></p>
<pre class="r"><code>cv_vectorizer.vocabulary_</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p4.png" /></p>
<p>To make the output a bit more readable we can have it displayed as a dataframe:</p>
<pre class="r"><code>cv_vectorized_matrix = pd.DataFrame(text_cv_vectorized.toarray(), 
                                    columns=cv_vectorizer.get_feature_names())
cv_vectorized_matrix</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p5.png" /></p>
<p>How are the rows and columns in the matrix shown above to be read?</p>
<ul>
<li>The rows indicate the documents in the corpus and</li>
<li>The columns indicate the tokens in the dictionary</li>
</ul>
</div>
<div id="creation-of-the-final-data-set" class="section level3">
<h3>3.1.3 Creation of the final Data Set</h3>
<p>Finally, I create a new data set on which to train machine learning algorithms. This time I use the generated array directly to create the final data frame:</p>
<pre class="r"><code>cv_df = pd.DataFrame(text_cv_vectorized_array, 
                     columns = cv_vectorizer.get_feature_names()).add_prefix(&#39;Counts_&#39;)

df_new_cv = pd.concat([df, cv_df], axis=1, sort=False)
df_new_cv</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p6.png" /></p>
<p>However, the bag-of-words method also has two crucial disadvantages:</p>
<ul>
<li>BoW does not preserve the order of words and</li>
<li>It does not allow to draw useful conclusions for downstream NLP tasks</li>
</ul>
</div>
<div id="test-of-a-sample-record" class="section level3">
<h3>3.1.4 Test of a Sample Record</h3>
<p>Let’s test a sample record:</p>
<pre class="r"><code>new_input = [&quot;Hi this is Mikel.&quot;]
new_input</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p7.png" /></p>
<pre class="r"><code>new_input_cv_vectorized = cv_vectorizer.transform(new_input)
new_input_cv_vectorized_array = new_input_cv_vectorized.toarray()
new_input_cv_vectorized_array</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p8.png" /></p>
<pre class="r"><code>new_input_matrix = pd.DataFrame(new_input_cv_vectorized_array, 
                                columns = cv_vectorizer.get_feature_names())

new_input_matrix</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p9.png" /></p>
<p>The words ‘is’ and ‘this’ have been learned by the CountVectorizer and thus get a count here.</p>
<pre class="r"><code>new_input = [&quot;You say goodbye and I say hello&quot;, &quot;hello world&quot;]
new_input</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p10.png" /></p>
<pre class="r"><code>new_input_cv_vectorized = cv_vectorizer.transform(new_input)
new_input_cv_vectorized_array = new_input_cv_vectorized.toarray()
new_input_cv_vectorized_array</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p11.png" /></p>
<pre class="r"><code>new_input_matrix = pd.DataFrame(new_input_cv_vectorized_array, 
                                columns = cv_vectorizer.get_feature_names())

new_input_matrix</code></pre>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p12.png" /></p>
<p>In our second example, I did not use any of the words CountVectorizer learned. Therefore all values are 0.</p>
</div>
</div>
<div id="n-grams" class="section level2">
<h2>3.2 N-grams</h2>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p.png" /></p>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p.png" /></p>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p.png" /></p>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p.png" /></p>
<p><img src="/post/2021-08-01-nlp-text-vectorization_files/p135p.png" /></p>
</div>
</div>
