---
title: NLP - Text Pre-Processing IV (Single Character Removal)
author: Michael Fuchs
date: '2021-06-05'
slug: nlp-text-pre-processing-iv-single-character-removal
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-data">2 Import the Libraries and the Data</a></li>
<li><a href="#definition-of-required-functions">3 Definition of required Functions</a></li>
<li><a href="#text-pre-processing">4 Text Pre-Processing</a>
<ul>
<li><a href="#text-cleaning">4.1 (Text Cleaning)</a></li>
<li><a href="#tokenization">4.2 (Tokenization)</a></li>
<li><a href="#stop-words">4.3 (Stop Words)</a></li>
<li><a href="#digression-pos-ner">4.4 (Digression: POS &amp; NER)</a></li>
<li><a href="#normalization">4.5 (Normalization)</a></li>
<li><a href="#removing-single-characters">4.6 Removing Single Characters</a>
<ul>
<li><a href="#application-to-the-example-string">4.6.1 <strong>Application</strong> to the Example String</a></li>
<li><a href="#application-to-the-dataframe">4.6.2 <strong>Application</strong> to the DataFrame</a>
<ul>
<li><a href="#with-character-length-1-default-settings">4.6.2.1 With Character Length = 1 (default settings)</a></li>
<li><a href="#with-character-length-2">4.6.2.2 With Character Length = 2</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#conclusion">5 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Now we come to another sub-area regarding text pre-processing: The removal of individual characters.</p>
<p>For this publication the processed dataset <em>Amazon Unlocked Mobile</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used as well as the created Example String. You can download both files from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/NLP/Text%20Pre-Processing%20IV%20(Single%20Character%20Removal)">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>2 Import the Libraries and the Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

import pickle as pk

import warnings
warnings.filterwarnings(&quot;ignore&quot;)


from bs4 import BeautifulSoup
import unicodedata
import re

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize

from nltk.corpus import stopwords


from nltk.corpus import wordnet
from nltk import pos_tag
from nltk import ne_chunk

from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer

from nltk.probability import FreqDist
import matplotlib.pyplot as plt
from wordcloud import WordCloud</code></pre>
<pre class="r"><code>pd.set_option(&#39;display.max_colwidth&#39;, 30)</code></pre>
<pre class="r"><code>df = pd.read_csv(&#39;Amazon_Unlocked_Mobile_small_Part_III.csv&#39;)
df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p1.png" /></p>
<pre class="r"><code>df[&#39;Reviews_lemmatized&#39;] = df[&#39;Reviews_lemmatized&#39;].astype(str)</code></pre>
<pre class="r"><code>clean_text_lemmatized_v_a = pk.load(open(&quot;clean_text_lemmatized_v_a.pkl&quot;,&#39;rb&#39;))
clean_text_lemmatized_v_a</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p2.png" /></p>
</div>
<div id="definition-of-required-functions" class="section level1">
<h1>3 Definition of required Functions</h1>
<p>All functions are summarized here. I will show them again where they are used during this post if they are new and have not been explained yet.</p>
<pre class="r"><code>def word_count_func(text):
    &#39;&#39;&#39;
    Counts words within a string
    
    Args:
        text (str): String to which the function is to be applied, string
    
    Returns:
        Number of words within a string, integer
    &#39;&#39;&#39; 
    return len(text.split())</code></pre>
<pre class="r"><code>def remove_single_char_func(text, threshold=1):
    &#39;&#39;&#39;
    Removes single characters from string, if present
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Removes words whose length falls below the threshold (by default = 1)
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        String with removed words whose length was below the threshold (by default = 1)
    &#39;&#39;&#39; 
    threshold = threshold
    
    words = word_tokenize(text)
    text = &#39; &#39;.join([word for word in words if len(word) &gt; threshold])
    return text</code></pre>
</div>
<div id="text-pre-processing" class="section level1">
<h1>4 Text Pre-Processing</h1>
<div id="text-cleaning" class="section level2">
<h2>4.1 (Text Cleaning)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/22/nlp-text-pre-processing-i-text-cleaning/#text-cleaning">Text Cleaning</a></p>
</div>
<div id="tokenization" class="section level2">
<h2>4.2 (Tokenization)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#tokenization">Text Pre-Processing II-Tokenization</a></p>
</div>
<div id="stop-words" class="section level2">
<h2>4.3 (Stop Words)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#stop-words">Text Pre-Processing II-Stop Words</a></p>
</div>
<div id="digression-pos-ner" class="section level2">
<h2>4.4 (Digression: POS &amp; NER)</h2>
<p>I have already described this part in the previous post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#digression-pos-ner">Text Pre-Processing III-POS &amp; NER</a></p>
</div>
<div id="normalization" class="section level2">
<h2>4.5 (Normalization)</h2>
<p>I have already described this part in the previous post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#normalization">Text Pre-Processing III-Normalization</a></p>
</div>
<div id="removing-single-characters" class="section level2">
<h2>4.6 Removing Single Characters</h2>
<p>In some cases (as is the case with the Example String), single characters may still be present in a string (after using Stop Word Removal etc.).</p>
<p>Let’s look at the following example sentence where I am aware that some characters would no longer be there after our previous steps. This example is just to show how the function works.</p>
<pre class="r"><code>text_for_remove_single_char = \
&quot;This is an example string with numbers like 5 or 10 and single characters like a, b and c.&quot;
text_for_remove_single_char</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p3.png" /></p>
<pre class="r"><code>def remove_single_char_func(text, threshold=1):
    &#39;&#39;&#39;
    Removes single characters from string, if present
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Removes words whose length falls below the threshold (by default = 1)
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        String with removed words whose length was below the threshold (by default = 1)
    &#39;&#39;&#39; 
    threshold = threshold
    
    words = word_tokenize(text)
    text = &#39; &#39;.join([word for word in words if len(word) &gt; threshold])
    return text</code></pre>
<p>Now we apply the function to our example sentence (text_for_remove_single_char) with the default settings (threshold=1).</p>
<pre class="r"><code>remove_single_char_func(text_for_remove_single_char)</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p4.png" /></p>
<p>Depending on the case, the threshold can also be set high (for example, to 2 characters).</p>
<pre class="r"><code>remove_single_char_func(text_for_remove_single_char, threshold=2)</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p5.png" /></p>
<div id="application-to-the-example-string" class="section level3">
<h3>4.6.1 <strong>Application</strong> to the Example String</h3>
<p>I will continue at this point with the edited example string ‘clean_text_lemmatized_v_a’ from the last blog, which we already loaded at the beginning of this post.</p>
<pre class="r"><code>clean_text_lemmatized_v_a</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p6.png" /></p>
<pre class="r"><code>clean_text_wo_single_char = remove_single_char_func(clean_text_lemmatized_v_a)
clean_text_wo_single_char</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p7.png" /></p>
</div>
<div id="application-to-the-dataframe" class="section level3">
<h3>4.6.2 <strong>Application</strong> to the DataFrame</h3>
<pre class="r"><code>df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p8.png" /></p>
<div id="with-character-length-1-default-settings" class="section level4">
<h4>4.6.2.1 With Character Length = 1 (default settings)</h4>
<pre class="r"><code>df[&#39;Reviews_cleaned_wo_single_char&#39;] = df[&#39;Reviews_lemmatized&#39;].apply(remove_single_char_func)

df[&#39;Word_Count_cleaned_Reviews_wo_single_char&#39;] = df[&#39;Reviews_cleaned_wo_single_char&#39;].apply(word_count_func)

df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p9.png" /></p>
<pre class="r"><code>print(&#39;Average of lemmatized words counted: &#39; + str(df[&#39;Word_Count_lemmatized_Reviews&#39;].mean()))
print(&#39;Average of cleaned words wo single char counted: &#39; + str(df[&#39;Word_Count_cleaned_Reviews_wo_single_char&#39;].mean()))</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p10.png" /></p>
<p>Again, we see that some words have been removed. Let’s have a look and see what they are.</p>
<pre class="r"><code>df_subset = df[[&#39;Reviews_lemmatized&#39;, &#39;Word_Count_lemmatized_Reviews&#39;, 
                &#39;Reviews_cleaned_wo_single_char&#39;, &#39;Word_Count_cleaned_Reviews_wo_single_char&#39;]]

df_subset[&#39;Diff&#39;] = df_subset[&#39;Word_Count_lemmatized_Reviews&#39;] - \
                    df_subset[&#39;Word_Count_cleaned_Reviews_wo_single_char&#39;]


df_subset = df_subset[(df_subset[&quot;Diff&quot;] != 0)]
df_subset = df_subset.sort_values(by=&#39;Diff&#39;, ascending=False)
df_subset.head().T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p11.png" /></p>
<pre class="r"><code>df_subset[&#39;Reviews_lemmatized&#39;].iloc[0]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p12.png" /></p>
<pre class="r"><code>df_subset[&#39;Reviews_cleaned_wo_single_char&#39;].iloc[0]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p13.png" /></p>
<pre class="r"><code># Original text:

df[(df.index == 7479)][&#39;Reviews&#39;].iloc[0]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p14.png" /></p>
<p>Conclusion: By removing single characters you do not necessarily run the risk of losing valuable information from the text. Now, of course, the question arises whether you need information like millimeters (mm) or whether you also remove them with the remove_single_char function if you set the threshold to 2.</p>
<p>Let’s try it out.</p>
</div>
<div id="with-character-length-2" class="section level4">
<h4>4.6.2.2 With Character Length = 2</h4>
<p>Now let’s try it with a higher threshold (here 2) and see if valuable information would be lost or not.</p>
<pre class="r"><code>df[&quot;Reviews_cleaned_wo_char_length_2&quot;] = df.apply(lambda x: remove_single_char_func(x[&quot;Reviews_lemmatized&quot;], 
                                                            threshold=2), axis = 1)

df[&#39;Word_Count_cleaned_Reviews_wo_char_length_2&#39;] = df[&#39;Reviews_cleaned_wo_char_length_2&#39;].apply(word_count_func)

df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p15.png" /></p>
<pre class="r"><code>print(&#39;Average of lemmatized words counted: &#39; + str(df[&#39;Word_Count_lemmatized_Reviews&#39;].mean()))
print(&#39;Average of cleaned words wo single char counted: &#39; + str(df[&#39;Word_Count_cleaned_Reviews_wo_single_char&#39;].mean()))
print(&#39;Average of cleaned words wo char length 2 counted: &#39; + str(df[&#39;Word_Count_cleaned_Reviews_wo_char_length_2&#39;].mean()))</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p16.png" /></p>
<pre class="r"><code>df_subset = df[[&#39;Reviews_lemmatized&#39;, &#39;Word_Count_lemmatized_Reviews&#39;, 
                &#39;Reviews_cleaned_wo_char_length_2&#39;, &#39;Word_Count_cleaned_Reviews_wo_char_length_2&#39;]]

df_subset[&#39;Diff&#39;] = df_subset[&#39;Word_Count_lemmatized_Reviews&#39;] - \
                    df_subset[&#39;Word_Count_cleaned_Reviews_wo_char_length_2&#39;]


df_subset = df_subset[(df_subset[&quot;Diff&quot;] != 0)]
#df_subset = df_subset.sort_values(by=&#39;Diff&#39;, ascending=False)
df_subset.head().T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p17.png" /></p>
<pre class="r"><code>df_subset[&#39;Reviews_lemmatized&#39;].iloc[1]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p18.png" /></p>
<pre class="r"><code>df_subset[&#39;Reviews_cleaned_wo_char_length_2&#39;].iloc[1]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p19.png" /></p>
<pre class="r"><code># Original text:

df[(df.index == 3)][&#39;Reviews&#39;].iloc[0]</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p20.png" /></p>
<p>Conclusion: The average number of words could be reduced again with a threshold of 2, which would definitely help our later model training in terms of complexity and training speed. However, words like ‘go’ that might be profitable are also deleted. A possibility here would be to use another lemmatizer (for example the one in the norm_lemm_POS_tag function), where the verbs are not converted into their base form. So ‘went’ or ‘gone’ would not become ‘go’, which in turn would not be removed by the remove_single_char function with a threshold of 2.</p>
<p>In the following I will continue to work with the column ‘Reviews_cleaned_wo_single_char’, where we only removed single characters with a length of 1.</p>
</div>
</div>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>5 Conclusion</h1>
<p>In this post, I showed how to remove single characters from texts and spot check the generated results.</p>
<p>I save the edited DataFrame and Example String again for subsequent use.</p>
<pre class="r"><code>pk.dump(clean_text_wo_single_char, open(&#39;clean_text_wo_single_char.pkl&#39;, &#39;wb&#39;))

df.to_csv(&#39;Amazon_Unlocked_Mobile_small_Part_IV.csv&#39;, index = False)</code></pre>
<p>Next, I will continue with the topic of text exploration.</p>
</div>
