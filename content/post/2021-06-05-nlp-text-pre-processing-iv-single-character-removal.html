---
title: NLP - Text Pre-Processing IV (Single Character Removal)
author: Michael Fuchs
date: '2021-06-05'
slug: nlp-text-pre-processing-iv-single-character-removal
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-data">2 Import the Libraries and the Data</a></li>
<li><a href="#definition-of-required-functions">3 Definition of required Functions</a></li>
<li><a href="#text-pre-processing">4 Text Pre-Processing</a>
<ul>
<li><a href="#text-cleaning">4.1 (Text Cleaning)</a></li>
<li><a href="#tokenization">4.2 (Tokenization)</a></li>
<li><a href="#stop-words">4.3 (Stop Words)</a></li>
<li><a href="#digression-pos-ner">4.4 (Digression: POS &amp; NER)</a></li>
<li><a href="#normalization">4.5 (Normalization)</a></li>
<li><a href="#removing-single-characters">4.6 Removing Single Characters</a>
<ul>
<li><a href="#application-to-the-example-string">4.6.1 <strong>Application</strong> to the Example String</a></li>
<li><a href="#application-to-the-dataframe">4.6.2 <strong>Application</strong> to the DataFrame</a>
<ul>
<li><a href="#with-character-length-1-default-settings">4.6.2.1 With Character Length = 1 (default settings)</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Now we come to another sub-area regarding text pre-processing: The removal of individual characters.</p>
<p>For this publication the processed dataset <em>Amazon Unlocked Mobile</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used as well as the created Example String. You can download both files from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/NLP/Text%20Pre-Processing%20IV%20(Single%20Character%20Removal)">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>2 Import the Libraries and the Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

import pickle as pk

import warnings
warnings.filterwarnings(&quot;ignore&quot;)


from bs4 import BeautifulSoup
import unicodedata
import re

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize

from nltk.corpus import stopwords


from nltk.corpus import wordnet
from nltk import pos_tag
from nltk import ne_chunk

from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer

from nltk.probability import FreqDist
import matplotlib.pyplot as plt
from wordcloud import WordCloud</code></pre>
<pre class="r"><code>pd.set_option(&#39;display.max_colwidth&#39;, 30)</code></pre>
<pre class="r"><code>df = pd.read_csv(&#39;Amazon_Unlocked_Mobile_small_Part_III.csv&#39;)
df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p1.png" /></p>
<pre class="r"><code>df[&#39;Reviews_lemmatized&#39;] = df[&#39;Reviews_lemmatized&#39;].astype(str)</code></pre>
<pre class="r"><code>clean_text_lemmatized_v_a = pk.load(open(&quot;clean_text_lemmatized_v_a.pkl&quot;,&#39;rb&#39;))
clean_text_lemmatized_v_a</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p2.png" /></p>
</div>
<div id="definition-of-required-functions" class="section level1">
<h1>3 Definition of required Functions</h1>
<p>All functions are summarized here. I will show them again where they are used during this post if they are new and have not been explained yet.</p>
<pre class="r"><code>def word_count_func(text):
    &#39;&#39;&#39;
    Counts words within a string
    
    Args:
        text (str): String to which the function is to be applied, string
    
    Returns:
        Number of words within a string, integer
    &#39;&#39;&#39; 
    return len(text.split())</code></pre>
<pre class="r"><code>def remove_single_char_func(text, threshold=1):
    &#39;&#39;&#39;
    Removes single characters from string, if present
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Removes words whose length falls below the threshold (by default = 1)
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        String with removed words whose length was below the threshold (by default = 1)
    &#39;&#39;&#39; 
    threshold = threshold
    
    words = word_tokenize(text)
    text = &#39; &#39;.join([word for word in words if len(word) &gt; threshold])
    return text</code></pre>
</div>
<div id="text-pre-processing" class="section level1">
<h1>4 Text Pre-Processing</h1>
<div id="text-cleaning" class="section level2">
<h2>4.1 (Text Cleaning)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/22/nlp-text-pre-processing-i-text-cleaning/#text-cleaning">Text Cleaning</a></p>
</div>
<div id="tokenization" class="section level2">
<h2>4.2 (Tokenization)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#tokenization">Text Pre-Processing II-Tokenization</a></p>
</div>
<div id="stop-words" class="section level2">
<h2>4.3 (Stop Words)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#stop-words">Text Pre-Processing II-Stop Words</a></p>
</div>
<div id="digression-pos-ner" class="section level2">
<h2>4.4 (Digression: POS &amp; NER)</h2>
<p>I have already described this part in the previous post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#digression-pos-ner">Text Pre-Processing III-POS &amp; NER</a></p>
</div>
<div id="normalization" class="section level2">
<h2>4.5 (Normalization)</h2>
<p>I have already described this part in the previous post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#normalization">Text Pre-Processing III-Normalization</a></p>
</div>
<div id="removing-single-characters" class="section level2">
<h2>4.6 Removing Single Characters</h2>
<p>In some cases (as is the case with the Example String), single characters may still be present in a string (after using Stop Word Removal etc.).</p>
<p>Let’s look at the following example sentence where I am aware that some characters would no longer be there after our previous steps. This example is just to show how the function works.</p>
<pre class="r"><code>text_for_remove_single_char = \
&quot;This is an example string with numbers like 5 or 10 and single characters like a, b and c.&quot;
text_for_remove_single_char</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p3.png" /></p>
<pre class="r"><code>def remove_single_char_func(text, threshold=1):
    &#39;&#39;&#39;
    Removes single characters from string, if present
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Removes words whose length falls below the threshold (by default = 1)
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        String with removed words whose length was below the threshold (by default = 1)
    &#39;&#39;&#39; 
    threshold = threshold
    
    words = word_tokenize(text)
    text = &#39; &#39;.join([word for word in words if len(word) &gt; threshold])
    return text</code></pre>
<p>Now we apply the function to our example sentence (text_for_remove_single_char) with the default settings (threshold=1).</p>
<pre class="r"><code>remove_single_char_func(text_for_remove_single_char)</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p4.png" /></p>
<p>Depending on the case, the threshold can also be set high (for example, to 2 characters).</p>
<pre class="r"><code>remove_single_char_func(text_for_remove_single_char, threshold=2)</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p5.png" /></p>
<div id="application-to-the-example-string" class="section level3">
<h3>4.6.1 <strong>Application</strong> to the Example String</h3>
<p>I will continue at this point with the edited example string ‘clean_text_lemmatized_v_a’ from the last blog, which we already loaded at the beginning of this post.</p>
<pre class="r"><code>clean_text_lemmatized_v_a</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p6.png" /></p>
<pre class="r"><code>clean_text_wo_single_char = remove_single_char_func(clean_text_lemmatized_v_a)
clean_text_wo_single_char</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p7.png" /></p>
</div>
<div id="application-to-the-dataframe" class="section level3">
<h3>4.6.2 <strong>Application</strong> to the DataFrame</h3>
<pre class="r"><code>df.head(3).T</code></pre>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p8.png" /></p>
<div id="with-character-length-1-default-settings" class="section level4">
<h4>4.6.2.1 With Character Length = 1 (default settings)</h4>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p.png" /></p>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p.png" /></p>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p.png" /></p>
<p><img src="/post/2021-06-05-nlp-text-pre-processing-iv-single-character-removal_files/p126p.png" /></p>
</div>
</div>
</div>
</div>
