---
title: AutoML using PyCaret - Regression
author: Michael Fuchs
date: '2022-01-15'
slug: automl-using-pycaret-regression
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries-and-data">2 Loading the Libraries and Data</a></li>
<li><a href="#pycaret---regression">3 PyCaret - Regression</a>
<ul>
<li><a href="#setup">3.1 Setup</a></li>
<li><a href="#compare-models">3.2 Compare Models</a></li>
<li><a href="#model-evaluation">3.3 Model Evaluation</a></li>
<li><a href="#model-training">3.4 Model Training</a></li>
<li><a href="#model-optimization">3.5 Model Optimization</a>
<ul>
<li><a href="#tune-the-model">3.5.1 Tune the Model</a></li>
<li><a href="#ensemble_models">3.5.2 ensemble_models</a></li>
<li><a href="#blend_models">3.5.3 blend_models</a></li>
<li><a href="#stack_models">3.5.4 stack_models</a></li>
<li><a href="#performance-overview">3.5.5 Performance Overview</a></li>
</ul></li>
<li><a href="#model-evaluation-after-training">3.6 Model Evaluation after Training</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134s1.png" /></p>
<p>In my last post I introduced <a href="https://pycaret.gitbook.io/docs/">PyCaret</a> and showed how to solve <a href="https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/">classification problem</a> using this automated machine learning library.
As a complement to this post, I would like to introduce the possibilities of <strong>regressions</strong>.</p>
<p>For this post the dataset <em>House Sales in King County, USA</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">GitHub Repository</a>.</p>
</div>
<div id="loading-the-libraries-and-data" class="section level1">
<h1>2 Loading the Libraries and Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

import pycaret.regression  as pycr</code></pre>
<pre class="r"><code>house_df = pd.read_csv(&quot;house_prices.csv&quot;)
house_df = house_df.drop([&#39;zipcode&#39;, &#39;lat&#39;, &#39;long&#39;, &#39;date&#39;, &#39;id&#39;], axis=1)
house_df</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p1.png" /></p>
</div>
<div id="pycaret---regression" class="section level1">
<h1>3 PyCaret - Regression</h1>
<p>Many general options you have with PyCaret I already explained in my post about classifications.
<strong>In the following I would like to go into more detail about new and regression relevant functions.</strong></p>
<p>If you are not familiar with PyCaret yet, I advise you to read this post of mine first: <a href="https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/">AutoML using PyCaret - Classification</a></p>
<div id="setup" class="section level2">
<h2>3.1 Setup</h2>
<pre class="r"><code>summary_preprocess = pycr.setup(house_df, 
                                target = &#39;price&#39;,
                                numeric_features = [&#39;bedrooms&#39;,
                                                    &#39;waterfront&#39;,
                                                    &#39;view&#39;,
                                                    &#39;condition&#39;,
                                                    &#39;grade&#39;],
                                normalize = True,
                                feature_interaction = True,
                                feature_ratio = True,
                                group_features = [&#39;sqft_living&#39;, 
                                                  &#39;sqft_lot&#39;, 
                                                  &#39;sqft_above&#39;, 
                                                  &#39;sqft_basement&#39;, 
                                                  &#39;sqft_living15&#39;, 
                                                  &#39;sqft_lot15&#39;],
                                feature_selection = True,
                                remove_multicollinearity = True)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p2.png" /></p>
<p>First we can check if the data types of all variables were recognized correctly. If this is the case, as here, we can press Enter.</p>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p3.png" /></p>
<p>What is different in this initiation of the setup compared to the <a href="https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/#setup">classification post</a> is that I have included more pre-processing steps:</p>
<p><strong><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/data-preparation">Data Preparation</a></strong></p>
<p>This time the datatype of <em>some variables was not recognized correctly</em>. With the parameter <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/data-preparation#data-types">numeric_features=[]</a></em> the correct datatype can be assigned to these variables.</p>
<p><strong><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/scale-and-transform">Scaling</a></strong></p>
<p>Furthermore I scaled the data this time with the <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/scale-and-transform#normalize">normalize</a></em> parameter. If you want more information about this topic see here: <a href="https://michael-fuchs-python.netlify.app/2019/08/31/feature-scaling-with-scikit-learn/">Feature Scaling with Scikit-Learn</a></p>
<p><strong><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering">Feature Engineering</a></strong></p>
<p>Sometimes it is worthwhile to generate new features through arithmetic operations applied to existing variables. This is exactly what the <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering#feature-interaction">feature_interaction</a></em> and <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering#feature-interaction">feature_ratio</a></em> parameters do.</p>
<p>Here we would have two more options:</p>
<ul>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering#polynomial-features">Polynomial Features</a></li>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering#trigonometry-features">Trigonometry Features</a></li>
</ul>
<p>I would use these two methods if I determine that the relationship between the dependent and independent variables is not linear. Both would generate new features.</p>
<p>What I also did under the topic Feature Engineering is the grouping of features. This can and should be done if predictors are related in some way. Since we have different square footage data in our dataset, I want to group these features using the <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering#group-features">group_features</a></em> parameter.</p>
<p><strong><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection">Feature Selection</a></strong></p>
<p>Now that we have generated some new features by the parameters used before I would like to have it checked which of the predictors are profitable for the model training. For this I use the <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection#feature-selection">feature_selection</a></em>.</p>
<p>Furthermore, I would like to counteract multicollinearity. I can do this by using the <em><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection#remove-multicollinearity">remove_multicollinearity</a></em> parameter.</p>
<p><strong>Important information regarding the Order of Operations!</strong></p>
<p>It is important that we follow the order of operations.</p>
<ul>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/data-preparation">1 - Data Preparation</a></li>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/scale-and-transform">2 - Scale and Transform</a></li>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering">3 - Feature Engineering</a></li>
<li><a href="https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection">4 - Feature Selection</a></li>
</ul>
<p>In the first three steps additional features can be created whereas in the last step (feature selection) features are excluded because they violate model assumption or are not profitable for model training.</p>
<pre class="r"><code>x = pycr.get_config(&#39;X&#39;)
y = pycr.get_config(&#39;y&#39;)
trainX = pycr.get_config(&#39;X_train&#39;)
testX = pycr.get_config(&#39;X_test&#39;)
trainY = pycr.get_config(&#39;y_train&#39;)
testY = pycr.get_config(&#39;y_test&#39;)</code></pre>
<p>See here the number of predictors before and after pre-preocessing:</p>
<pre class="r"><code>print(&#39;Number of Predictors before pre-processig: &#39; + str(house_df.shape[1]-1))
print(&#39;Number of Predictors after pre-processig: &#39; + str(x.shape[1]))</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p4.png" /></p>
</div>
<div id="compare-models" class="section level2">
<h2>3.2 Compare Models</h2>
<pre class="r"><code>available_models = pycr.models()
available_models</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p5.png" /></p>
<pre class="r"><code>best_reg = pycr.compare_models()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p6.png" /></p>
<p>Let’s take a detailed look at the best model from the comparison:</p>
<pre class="r"><code>print(best_reg)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p7.png" /></p>
<p>All the possible games you can do with the compare_models() function have already been described here: <a href="https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/#compare-models">AutoML using PyCaret - Classification - Compare Models</a></p>
</div>
<div id="model-evaluation" class="section level2">
<h2>3.3 Model Evaluation</h2>
<pre class="r"><code>evaluation_best_clf = pycr.evaluate_model(best_reg)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p8.png" /></p>
<p>Here are a few more charts on the performance of our model:</p>
<pre class="r"><code>pycr.plot_model(best_reg, plot = &#39;learning&#39;)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p9.png" /></p>
<pre class="r"><code>pycr.plot_model(best_reg, plot = &#39;error&#39;)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p10.png" /></p>
<p>Here is an overview of possible graphics in PyCaret: <a href="https://pycaret.gitbook.io/docs/get-started/functions/analyze#regression">Examples by module - Regression</a></p>
<p><strong>Saving image files</strong></p>
<p>If you want to save the output graphics in PyCaret, you have to set the safe parameter to True. The syntax would look like this:</p>
<pre class="r"><code>pycr.plot_model(best_reg, plot = &#39;error&#39;,
                save = True)</code></pre>
</div>
<div id="model-training" class="section level2">
<h2>3.4 Model Training</h2>
<pre class="r"><code>print(best_reg)</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p11.png" /></p>
<pre class="r"><code># Train the RandomForestRegressor Model 
rf_reg = pycr.create_model(&#39;rf&#39;, fold = 5)

# Obtaining the performance overview
rf_reg_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p12.png" /></p>
</div>
<div id="model-optimization" class="section level2">
<h2>3.5 Model Optimization</h2>
<p>In the following I will try to improve the performance of our created algorithm with different methods. At the end of the chapter I will create an overview of the performance values. On their basis I will select afterwards the final model.</p>
<div id="tune-the-model" class="section level3">
<h3>3.5.1 Tune the Model</h3>
<pre class="r"><code># Tune the RandomForestRegressor Model 
rf_reg_tuned, rf_reg_tuner = pycr.tune_model(rf_reg,
                                             return_tuner=True)

# Obtaining the performance overview
rf_reg_tuned_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p13.png" /></p>
</div>
<div id="ensemble_models" class="section level3">
<h3>3.5.2 ensemble_models</h3>
<pre class="r"><code># Train the bagged Model 
rf_reg_bagged = pycr.ensemble_model(rf_reg, 
                                    method = &#39;Bagging&#39;, 
                                    fold = 5,
                                    n_estimators = 30)

# Obtaining the performance overview
rf_reg_bagged_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p14.png" /></p>
<pre class="r"><code># Train the boosted Model 
rf_reg_boosted = pycr.ensemble_model(rf_reg, 
                                     method = &#39;Boosting&#39;, 
                                     fold = 5,
                                     n_estimators = 30)

# Obtaining the performance overview
rf_reg_boosted_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p15.png" /></p>
</div>
<div id="blend_models" class="section level3">
<h3>3.5.3 blend_models</h3>
<p>Instead of selecting the models manually I will use the dynamic variant where the N best models are selected using the compare_models function and fed to the voting classifier.</p>
<pre class="r"><code># Training of N best models
voting_reg_dynamic = pycr.blend_models(pycr.compare_models(n_select = 3))

# Obtaining the performance overview
voting_reg_dynamic_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p16.png" /></p>
<pre class="r"><code>voting_reg_dynamic.estimators_</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p17.png" /></p>
</div>
<div id="stack_models" class="section level3">
<h3>3.5.4 stack_models</h3>
<pre class="r"><code># Training of N best models
stacked_reg_dynamic = pycr.stack_models(pycr.compare_models(n_select = 3))

# Obtaining the performance overview
stacked_reg_dynamic_results = pycr.pull()</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p18.png" /></p>
<pre class="r"><code>stacked_reg_dynamic.estimators_</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p19.png" /></p>
</div>
<div id="performance-overview" class="section level3">
<h3>3.5.5 Performance Overview</h3>
<p>As announced at the beginning of this chapter, I conclude with an overview of the performance metrics that were achieved:</p>
<pre class="r"><code>rf_reg_results_df = rf_reg_results.loc[[&#39;Mean&#39;]]
rf_reg_tuned_results_df = rf_reg_tuned_results.loc[[&#39;Mean&#39;]]
rf_reg_bagged_results_df = rf_reg_bagged_results.loc[[&#39;Mean&#39;]]
rf_reg_boosted_results_df = rf_reg_boosted_results.loc[[&#39;Mean&#39;]]
voting_reg_dynamic_results_df = voting_reg_dynamic_results.loc[[&#39;Mean&#39;]]
stacked_reg_dynamic_results_df = stacked_reg_dynamic_results.loc[[&#39;Mean&#39;]]


comparison_df = pd.concat([rf_reg_results_df,
                           rf_reg_tuned_results_df,
                           rf_reg_bagged_results_df,
                           rf_reg_boosted_results_df,
                           voting_reg_dynamic_results_df,
                           stacked_reg_dynamic_results_df]).reset_index()

comparison_df = comparison_df.drop(&#39;index&#39;, axis=1) 
comparison_df.insert(0, &quot;Model&quot;, [&#39;rf_reg&#39;, 
                                  &#39;rf_reg_tuned&#39;, 
                                  &#39;rf_reg_bagged&#39;,
                                  &#39;rf_reg_boosted&#39;,
                                  &#39;voting_reg_dynamic&#39;,
                                  &#39;stacked_reg_dynamic&#39;])

comparison_df.style.highlight_max(axis=0, 
                                  color = &#39;lightgreen&#39;, 
                                  subset=[&#39;R2&#39;]).highlight_min(axis=0, 
                                                               color = &#39;lightgreen&#39;, 
                                                               subset=[&#39;MAE&#39;,&#39;MSE&#39;,
                                                                       &#39;RMSE&#39;,&#39;RMSLE&#39;,&#39;MAPE&#39;])</code></pre>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p20.png" /></p>
</div>
</div>
<div id="model-evaluation-after-training" class="section level2">
<h2>3.6 Model Evaluation after Training</h2>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p.png" /></p>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p.png" /></p>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p.png" /></p>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p.png" /></p>
<p><img src="/post/2022-01-15-automl-using-pycaret-regression_files/p134p.png" /></p>
</div>
</div>
