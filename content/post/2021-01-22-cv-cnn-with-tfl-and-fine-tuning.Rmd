---
title: CV - CNN with TFL and Fine-Tuning
author: Michael Fuchs
date: '2021-01-22'
slug: cv-cnn-with-tfl-and-fine-tuning
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---



# 1 Introduction

In my post [Computer Vision - CNN with Transfer Learning](https://michael-fuchs-python.netlify.app/2021/01/17/computer-vision-cnn-with-transfer-learning/) I showed how to train a binary image classifier with the help of a pre-trained neural network. Now I would like to improve this model by means of Fine Tuning.

I will again use the pre-trained network [VGG19](https://keras.io/api/applications/vgg/#vgg19-function) from the [Keras applications](https://keras.io/api/applications/) provided.


For this publication I used the images from the *cats and dogs* dataset from the statistics platform ["Kaggle"](https://www.kaggle.com/c/dogs-vs-cats/data). You can download the used data from my ["GitHub Repository"](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network). 



# 2 Import the libraries

```{r, eval=F, echo=T}
from preprocessing_CNN import Train_Validation_Test_Split

import numpy as np
import pandas as pd

import os
import shutil

import pickle as pk

import cv2 
import matplotlib.pyplot as plt
%matplotlib inline 

from keras import layers
from keras import models
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model

from keras.applications import VGG19
```



# 3 Data pre-processing

How the data for a CNN model training must be prepared I have already explained in this post: [Computer Vision - Convolutional Neural Network](https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/)

The exact functionality of the code I have explained in this post: [Automate the Boring Stuff](https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/#train-validation-test-split)

Please download the two folders *cats* and *dogs* from my ["GitHub Repository"](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network) and navigate to the project's root directory in the terminal. The notebook must be started from the location where the two files are stored. 


## 3.1 Train-Validation-Test Split

For this please download the preprocessing_CNN.py file from my ["GitHub Repository"](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network) and place this file next to the folders *cats* and *dogs* and start your Jupyter notebook from here.


```{r, eval=F, echo=T}
c_train, d_train, c_val, d_val, c_test, d_test = Train_Validation_Test_Split('cats', 'dogs')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p1.png)


## 3.2 Obtaining the lists of randomly selected images


```{r, eval=F, echo=T}
list_cats_training = c_train
list_dogs_training = d_train

list_cats_validation = c_val
list_dogs_validation = d_val

list_cats_test = c_test
list_dogs_test = d_test
```


## 3.3 Determination of the directories


```{r, eval=F, echo=T}
root_directory = os.getcwd()

train_dir = os.path.join(root_directory, 'cats_and_dogs\\train')
validation_dir = os.path.join(root_directory, 'cats_and_dogs\\validation')
test_dir = os.path.join(root_directory, 'cats_and_dogs\\test')
```


## 3.4 Obtain the total number of training, validation and test images


```{r, eval=F, echo=T}
num_cats_img_train = len(list_cats_training)
num_dogs_img_train = len(list_dogs_training)

num_train_images_total = num_cats_img_train + num_dogs_img_train

print('Total training cat images: ' + str(num_cats_img_train))
print('Total training dog images: ' + str(num_dogs_img_train))
print()
print('Total training images: ' + str(num_train_images_total))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p2.png)


```{r, eval=F, echo=T}
num_cats_img_validation = len(list_cats_validation)
num_dogs_img_validation = len(list_dogs_validation)

num_validation_images_total = num_cats_img_validation + num_dogs_img_validation

print('Total validation cat images: ' + str(num_cats_img_validation))
print('Total validation dog images: ' + str(num_dogs_img_validation))
print()
print('Total validation images: ' + str(num_validation_images_total))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p3.png)


```{r, eval=F, echo=T}
num_cats_img_test = len(list_cats_test)
num_dogs_img_test = len(list_dogs_test)

num_test_images_total = num_cats_img_test + num_dogs_img_test

print('Total test cat images: ' + str(num_cats_img_test))
print('Total test dog images: ' + str(num_dogs_img_test))
print()
print('Total test images: ' + str(num_test_images_total))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p4.png)


# 4 Feature Extraction with Data Augmentation

## 4.1 Name Definitions


```{r, eval=F, echo=T}
checkpoint_no = 'ckpt_1_CNN_with_TFL_VGG19_FineTuning'
model_name = 'Cats_Dogs_CNN_TFL_VGG19_FineTuning_epoch_30'
```


## 4.2 Parameter Settings


```{r, eval=F, echo=T}
img_height = 150
img_width = 150
input_shape = (img_height, img_width, 3)

n_batch_size = 32

n_steps_per_epoch = int(num_train_images_total / n_batch_size)
n_validation_steps = int(num_validation_images_total / n_batch_size)
n_test_steps = int(num_test_images_total / n_batch_size)

n_epochs = 30

print('Input Shape: '+'('+str(img_height)+', '+str(img_width)+', ' + str(3)+')')
print('Batch Size: ' + str(n_batch_size))
print()
print('Steps per Epoch: ' + str(n_steps_per_epoch))
print()
print('Validation Steps: ' + str(n_validation_steps))
print('Test Steps: ' + str(n_test_steps))
print()
print('Number of Epochs: ' + str(n_epochs))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p5.png)


## 4.3 Instantiating the VGG19 convolutional base

```{r, eval=F, echo=T}
VGG19_base = VGG19(weights='imagenet',
                  include_top=False,
                  input_shape=input_shape)

conv_base = VGG19_base
```


```{r, eval=F, echo=T}
conv_base.summary()
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p6.png)


## 4.4 Freezing all layers up to a specific one

How is this post here different from [CNN with Transfer Learning](https://michael-fuchs-python.netlify.app/2021/01/17/computer-vision-cnn-with-transfer-learning/)?
Up to this point not at all!
But right here we can make a setting, which we have not made before. 
Until now we had all conv blocks always frozen (see [here](https://michael-fuchs-python.netlify.app/2021/01/17/computer-vision-cnn-with-transfer-learning/#layer-structure-1)). Now we set all parameters to trainable with conv_base.trainable = True. But of course (otherwise we wouldn't have to do any transfer learning) we want to keep most of the already learned features. So we have the possibility to freeze a part of the conv blocks or to leave a part unfrozen. 

With the following code we can freeze all layers up to 'block5_conv3'. Thus, in this example, only the weights of the last two conv layers (block5_conv3 and block5_conv4) are adjusted using our training data. 


```{r, eval=F, echo=T}
conv_base.trainable = True

set_trainable = False
for layer in conv_base.layers:
    if layer.name == 'block5_conv3':
        set_trainable = True
    if set_trainable:
        layer.trainable = True
    else:
        layer.trainable = False
```



## 4.5 Instantiating a densely connected classifier

### 4.5.1 Layer Structure

```{r, eval=F, echo=T}
model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
```

```{r, eval=F, echo=T}
model.summary()
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p7.png)


### 4.5.2 Configuring the model for training


```{r, eval=F, echo=T}
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
```


### 4.5.3 Using ImageDataGenerator


```{r, eval=F, echo=T}
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,)

validation_datagen = ImageDataGenerator(rescale=1./255)


train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode='binary')


validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode='binary')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p8.png)


## 4.6 Callbacks

```{r, eval=F, echo=T}
# Prepare a directory to store all the checkpoints.
checkpoint_dir = checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)
```


```{r, eval=F, echo=T}
keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir, 
                                   monitor='val_loss', save_best_only=True, mode='auto'),
                   EarlyStopping(monitor='val_loss', patience=5, mode='auto', 
                                 min_delta = 0, verbose=1)]
```


## 4.7 Fitting the model


```{r, eval=F, echo=T}
history = model.fit(
      train_generator,
      steps_per_epoch=n_steps_per_epoch,
      epochs=n_epochs,
      validation_data=validation_generator,
      validation_steps=n_validation_steps,
      callbacks=keras_callbacks)
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p9.png)


## 4.8 Obtaining the best model values


```{r, eval=F, echo=T}
hist_df = pd.DataFrame(history.history)
hist_df['epoch'] = hist_df.index + 1
cols = list(hist_df.columns)
cols = [cols[-1]] + cols[:-1]
hist_df = hist_df[cols]
hist_df.to_csv(checkpoint_no + '/' + 'history_df_' + model_name + '.csv')
hist_df.head()
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p10.png)


```{r, eval=F, echo=T}
values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]
values_of_best_model
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p11.png)


## 4.9 Obtaining class assignments


```{r, eval=F, echo=T}
class_assignment = train_generator.class_indices

df = pd.DataFrame([class_assignment], columns=class_assignment.keys())
df_stacked = df.stack()
df_temp = pd.DataFrame(df_stacked).reset_index().drop(['level_0'], axis=1)
df_temp.columns = ['Category', 'Allocated Number']
df_temp.to_csv(checkpoint_no + '/' + 'class_assignment_df_' + model_name + '.csv')

print('Class assignment:', str(class_assignment))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p12.png)



## 4.10 Validation

```{r, eval=F, echo=T}
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p13.png)



## 4.11 Load best model

```{r, eval=F, echo=T}
# Loading the automatically saved model
model_reloaded = load_model(checkpoint_no)

# Saving the best model in the correct path and format
root_directory = os.getcwd()
checkpoint_dir = os.path.join(root_directory, checkpoint_no)
model_name_temp = os.path.join(checkpoint_dir, model_name + '.h5')
model_reloaded.save(model_name_temp)

# Deletion of the automatically created folders/.pb file under Model Checkpoint File.
folder_name_temp1 = os.path.join(checkpoint_dir, 'assets')
folder_name_temp2 = os.path.join(checkpoint_dir, 'variables')
file_name_temp = os.path.join(checkpoint_dir, 'saved_model.pb')

shutil.move(file_name_temp, folder_name_temp1)
shutil.rmtree(folder_name_temp1, ignore_errors=True)
shutil.rmtree(folder_name_temp2, ignore_errors=True)
```

```{r, eval=F, echo=T}
best_model = load_model(model_name_temp)
```


## 4.12 Model Testing


```{r, eval=F, echo=T}
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode='binary')

test_loss, test_acc = best_model.evaluate(test_generator, steps=n_test_steps)
print()
print('Test Accuracy:', test_acc)
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p14.png)


```{r, eval=F, echo=T}
pk.dump(img_height, open(checkpoint_dir+ '\\' +'img_height.pkl', 'wb'))
pk.dump(img_width, open(checkpoint_dir+ '\\' +'img_width.pkl', 'wb'))
```


## 4.13 Test Out of the Box Pictures


```{r, eval=F, echo=T}
# Determine Checkpoint Dir
checkpoint_dir = 'ckpt_1_CNN_with_TFL_VGG19_FineTuning'

# Load best model
best_model = load_model(checkpoint_dir + '/' + 'Cats_Dogs_CNN_TFL_VGG19_FineTuning_epoch_30.h5')

# Load the categories
df = pd.read_csv(checkpoint_dir + '/' + 'class_assignment_df_Cats_Dogs_CNN_TFL_VGG19_FineTuning_epoch_30.csv')
df = df.sort_values(by='Allocated Number', ascending=True)
CATEGORIES = df['Category'].to_list()


# Load the used image height and width
img_height_reload = pk.load(open(checkpoint_dir + '/' + 'img_height.pkl','rb'))
img_width_reload = pk.load(open(checkpoint_dir + '/' + 'img_width.pkl','rb'))


print('Model Summary :' + str(best_model.summary()))
print()
print()
print('CATEGORIES : ' + str(CATEGORIES))
print()
print('Used image height: ' + str(img_height_reload))
print('Used image width: ' + str(img_width_reload))
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p15.png)


```{r, eval=F, echo=T}
img_pred = cv2.imread('out of the box pic/test_cat_pic_1.jpg')

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = cv2.resize(img_pred,(img_height_reload,img_width_reload))
img_pred = np.reshape(img_pred,[1,img_height_reload,img_width_reload,3])

classes = (best_model.predict(img_pred) > 0.5).astype("int32")

print()
print('------------------------------------')
print('Predicted Class: ' + CATEGORIES[int(classes[0])])
print('------------------------------------')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p16.png)


```{r, eval=F, echo=T}
img_pred = cv2.imread('out of the box pic/test_cat_pic_2.jpg')

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = cv2.resize(img_pred,(img_height_reload,img_width_reload))
img_pred = np.reshape(img_pred,[1,img_height_reload,img_width_reload,3])

classes = (best_model.predict(img_pred) > 0.5).astype("int32")

print()
print('------------------------------------')
print('Predicted Class: ' + CATEGORIES[int(classes[0])])
print('------------------------------------')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p17.png)


```{r, eval=F, echo=T}
img_pred = cv2.imread('out of the box pic/test_dog_pic_1.jpg')

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = cv2.resize(img_pred,(img_height_reload,img_width_reload))
img_pred = np.reshape(img_pred,[1,img_height_reload,img_width_reload,3])

classes = (best_model.predict(img_pred) > 0.5).astype("int32")

print()
print('------------------------------------')
print('Predicted Class: ' + CATEGORIES[int(classes[0])])
print('------------------------------------')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p18.png)


```{r, eval=F, echo=T}
img_pred = cv2.imread('out of the box pic/test_dog_pic_2.jpg')

print(plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)))

img_pred = cv2.resize(img_pred,(img_height_reload,img_width_reload))
img_pred = np.reshape(img_pred,[1,img_height_reload,img_width_reload,3])

classes = (best_model.predict(img_pred) > 0.5).astype("int32")

print()
print('------------------------------------')
print('Predicted Class: ' + CATEGORIES[int(classes[0])])
print('------------------------------------')
```

![](/post/2021-01-22-cv-cnn-with-tfl-and-fine-tuning_files/p108p19.png)


# 5 Conclusion

That's it. In this post I showed how you can use transfer learning and fine tuning to bring your model (especially if you have a small amount of training data) to a quite acceptable performance value. 



**References**

The content of the entire post was created using the following sources:

Chollet, F. (2018). Deep learning with Python (Vol. 361). New York: Manning.



