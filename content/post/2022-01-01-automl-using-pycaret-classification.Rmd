---
title: AutoML using PyCaret - Classification
author: Michael Fuchs
date: '2022-01-01'
slug: automl-using-pycaret-classification
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---


# 1 Introduction

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133s1.png)

Source: [PyCaret-GitHub](https://github.com/pycaret)


Data Scientists tend to make their tasks more and more effective and efficient. This also applies to the field of machine learning model training. 
There is a wide range of algorithms that can be used for regression and classification problems. 
[Machine Learning Pipelines]( https://michael-fuchs-python.netlify.app/2021/05/11/machine-learning-pipelines/) have helped to simplify and speed up the process of finding the best model. 

Now we come to the next stage: **Automated Machine Learning Libraries**

In my research, I came across [**PyCaret**](https://pycaret.org/) in this regard. 

[PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows.](https://pycaret.org/)

It can be used to work on the following problems:

+ [Classification](https://pycaret.gitbook.io/docs/get-started/quickstart#classification)
+ [Regression](https://pycaret.gitbook.io/docs/get-started/quickstart#regression)
+ [Clustering](https://pycaret.gitbook.io/docs/get-started/quickstart#clustering)
+ [Anomaly Detection](https://pycaret.gitbook.io/docs/get-started/quickstart#anomaly-detection)
+ [Natural Language Processing](https://pycaret.gitbook.io/docs/get-started/quickstart#natural-language-processing)
+ [Association Rules Mining](https://pycaret.gitbook.io/docs/get-started/quickstart#association-rules-mining)
+ [Time Series (beta)](https://pycaret.gitbook.io/docs/get-started/quickstart#time-series-beta)


When I read through the [GitBook]( https://pycaret.gitbook.io/docs/) and the [API Reference]( https://pycaret.readthedocs.io/en/latest/) PyCaret was very promising and I can say I was not disappointed. 

In the following I will show how to create a classification algorithm with PyCaret and what other possibilities you have with this AutoML library.


# 2 Loading the Libraries and Data


```{r, eval=F, echo=T}
import pandas as pd
import numpy as np

import pycaret.classification as pycc
```


```{r, eval=F, echo=T}
class Color:
   PURPLE = '\033[95m'
   CYAN = '\033[96m'
   DARKCYAN = '\033[36m'
   BLUE = '\033[94m'
   GREEN = '\033[92m'
   YELLOW = '\033[93m'
   RED = '\033[91m'
   BOLD = '\033[1m'
   UNDERLINE = '\033[4m'
   END = '\033[0m'
```

```{r, eval=F, echo=T}
bird_df = pd.read_csv('bird.csv').drop('id', axis=1)
bird_df.head()
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p1.png)


```{r, eval=F, echo=T}
bird_df.isnull().sum()
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p2.png)



# 3 PyCaret - Classification

## 3.1  Setup

As a first step, I initialize the training environment. At the same time, the transformation pipeline is created.
This setup function takes two parameters:

+ the dataset
+ the target variable


```{r, eval=F, echo=T}
summary_preprocess = pycc.setup(bird_df, target = 'type')
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p3.png)

First we can check if the data types of all variables were recognized correctly. If this is the case, as here, we can press Enter.


![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p4.png)

Now we get a detailed overview (only a part of it is shown here) of the initialized setup and the performed transformation steps of the pipeline. 

Default Transformations:

+ Missing Value Imputation
+ Perfect Collinearity Removal
+ One-Hot Encoding
+ Train-Test Split
 

All transformations can be set individually in the setup function. See here: [PyCaret Official - Preprocessing](https://pycaret.gitbook.io/docs/get-started/preprocessing)

These include:

+ [Data Preparation](https://pycaret.gitbook.io/docs/get-started/preprocessing/data-preparation)
    + Missing Values
    + Data Types
    + Encoding
+ [Scale and Transform](https://pycaret.gitbook.io/docs/get-started/preprocessing/scale-and-transform)
+ [Feature Engineering](https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-engineering)
+ [Feature Selection](https://pycaret.gitbook.io/docs/get-started/preprocessing/feature-selection) and 
+ [Other Parameters](https://pycaret.gitbook.io/docs/get-started/preprocessing/other-setup-parameters)


Use these preprocessing and transformation parameters in the setup as needed for your present data set. In my example I leave it at the default settings. 

Using the get_config function we can view the edited record. 

```{r, eval=F, echo=T}
x = pycc.get_config('X')
y = pycc.get_config('y')
trainX = pycc.get_config('X_train')
testX = pycc.get_config('X_test')
trainY = pycc.get_config('y_train')
testY = pycc.get_config('y_test')
```


```{r, eval=F, echo=T}
x
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p5.png)


```{r, eval=F, echo=T}
y
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p6.png)


Here we see how the target variable 'type' has been recoded to apply machine learning algorithms. This step can also be seen in the summary_preprocess in line 4 (index 3). 

If you want to get other values or information from the initiated setup here is a list of variables that can be retrieved using the get_config function: [Variables accessible by get_config function](https://pycaret.gitbook.io/docs/get-started/functions/others#get_config)



## 3.2  Compare Models

Now that all preprocessing steps are completed, we can check the performance of the classification algorithms available in PyCaret. 



```{r, eval=F, echo=T}
available_models = pycc.models()
available_models
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p7.png)

Now let's compare these models:



```{r, eval=F, echo=T}
best_clf = pycc.compare_models()
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p8.png)


Another nice thing about this view is that the best values of each metric are highlighted in yellow. The Extra Trees Classifier achieved the highest value for almost every metric, so all highlighted fields are listed under this algorithm.

Let's take a detailed look at the best model from the comparison:


```{r, eval=F, echo=T}
print(best_clf)
```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p9.png)


**Changing the sort order**

Of course, the highest Accuracy is not always the decisive metric, so sorting can also be done according to other evaluation metrics. Here, for example, the syntax to sort by AUC score:

`best_clf_AUC = pycc.compare_models(sort = 'AUC')`



### 3.2.1 Comparison of Specific Models


















```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)





























```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)






























```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)
































```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)




























```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)



































```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)


































```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)



































```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)































```{r, eval=F, echo=T}

```

![](/post/2022-01-01-automl-using-pycaret-classification_files/p133p.png)
















