---
title: Computer Vision - Convolutional Neural Network
author: Michael Fuchs
date: '2021-01-08'
slug: computer-vision-convolutional-neural-network
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries">2 Import the libraries</a></li>
<li><a href="#data-pre-processing">3 Data pre-processing</a>
<ul>
<li><a href="#train-validation-test-split">3.1 Train-Validation-Test Split</a></li>
<li><a href="#obtaining-the-lists-of-randomly-selected-images">3.2 Obtaining the lists of randomly selected images</a></li>
<li><a href="#determination-of-the-directories">3.3 Determination of the directories</a></li>
<li><a href="#obtain-the-total-number-of-training-validation-and-test-images">3.4 Obtain the total number of training, validation and test images</a></li>
</ul></li>
<li><a href="#descriptive-statistics">4 Descriptive Statistics</a></li>
<li><a href="#simple-cnn">5 Simple CNN</a>
<ul>
<li><a href="#name-definitions">5.1 Name Definitions</a></li>
<li><a href="#parameter-settings">5.2 Parameter Settings</a></li>
<li><a href="#instantiating-a-small-cnn">5.3 Instantiating a small CNN</a>
<ul>
<li><a href="#layer-structure">5.3.1 Layer Structure</a></li>
<li><a href="#configuring-the-model-for-training">5.3.2 Configuring the model for training</a></li>
<li><a href="#using-imagedatagenerator">5.3.3 Using ImageDataGenerator</a></li>
</ul></li>
<li><a href="#callbacks">5.4 Callbacks</a></li>
<li><a href="#fitting-the-model">5.5 Fitting the model</a></li>
<li><a href="#obtaining-the-best-model-values">5.6 Obtaining the best model values</a></li>
<li><a href="#obtaining-class-assignments">5.7 Obtaining class assignments</a></li>
<li><a href="#validation">5.8 Validation</a></li>
<li><a href="#load-best-model">5.9 Load best model</a></li>
<li><a href="#model-testing">5.10 Model Testing</a></li>
</ul></li>
<li><a href="#cnn-with-data-augmentation">6 CNN with Data Augmentation</a>
<ul>
<li><a href="#name-definitions-1">6.1 Name Definitions</a></li>
<li><a href="#parameter-settings-1">6.2 Parameter Settings</a></li>
<li><a href="#instantiating-a-cnn-with-data-augmentation">6.3 Instantiating a CNN with Data Augmentation</a>
<ul>
<li><a href="#layer-structure-1">6.3.1 Layer Structure</a></li>
<li><a href="#configuring-the-model-for-training-1">6.3.2 Configuring the model for training</a></li>
<li><a href="#using-imagedatagenerator-with-data-augmentation">6.3.3 Using ImageDataGenerator with data augmentation</a></li>
</ul></li>
<li><a href="#callbacks-1">6.4 Callbacks</a></li>
<li><a href="#fitting-the-model-1">6.5 Fitting the model</a></li>
<li><a href="#obtaining-the-best-model-values-1">6.6 Obtaining the best model values</a></li>
<li><a href="#obtaining-class-assignments-1">6.7 Obtaining class assignments</a></li>
<li><a href="#validation-1">6.8 Validation</a></li>
<li><a href="#load-best-model-1">6.9 Load best model</a></li>
<li><a href="#model-testing-1">6.10 Model Testing</a></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>So we got into <a href="https://tryolabs.com/resources/introductory-guide-computer-vision/">Computer Vision</a> and I described how to deal with image data in my last post <a href="https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/">Automate the Boring Stuff</a>.
Here I have also shown how to automatically split a dataset of images into a training, validation and test part.</p>
<p>I’ll barely cover that part in the post below and focus entirely on the topic at hand: How to classify the content of images using <strong>Convolutional Neural Networks</strong>.</p>
<p>What is a [Convolutional Neural(<a href="https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/" class="uri">https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/</a>) Network] (CNN)?</p>
<p>A CNN is is a deep learning neural network designed for processing structured arrays of data such as images.
Convolutional Neural Networks are widely used in computer vision and have become the state of the art for many visual applications such as image classification.
However, they can also be used for Recommender Systems, Natural Language Processing or Time Series Forecasting.</p>
<p>CNNs are very good at picking up on patterns in the input image, such as lines, gradients, circles or even eyes and faces. It is this property that makes CNNs so powerful for Computer Vision.
A CNN is a <a href="https://deepai.org/machine-learning-glossary-and-terms/feed-forward-neural-network">feed-forward neural network</a>. The power of a CNN comes from a special kind of layer called the <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">convolutional layer</a>.
CNNs contain many convolutional layers stacked on top of each other, each one capable of recognizing more sophisticated shapes.</p>
<p align="center">
<img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2020/05/Cats-Dogs-Classification-deep-learning.gif?raw=true" alt="readme crisp dm"/>
</p>
<p>Source: <a href="https://data-flair.training/">DataFlair</a></p>
<p>In this publication I will show how to classify image data using a CNN.
For this I used the images from the <em>cats and dogs</em> dataset from the statistics platform <a href="https://www.kaggle.com/c/dogs-vs-cats/data">“Kaggle”</a>. You can download the used data from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries" class="section level1">
<h1>2 Import the libraries</h1>
<pre class="r"><code>from preprocessing_CNN import Train_Validation_Test_Split

import numpy as np
import pandas as pd

import os
import shutil

import cv2 
import matplotlib.pyplot as plt
%matplotlib inline 

from keras import layers
from keras import models
from keras.callbacks import EarlyStopping, ModelCheckpoint

from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model</code></pre>
</div>
<div id="data-pre-processing" class="section level1">
<h1>3 Data pre-processing</h1>
<p>To get started with the training of a CNN, we first have to divide the data set into a training, validation and test part and determine some directories and metrics, so that we have less work later and can run through all processes fully automatically.</p>
<p>Please download the two folders <em>cats</em> and <em>dogs</em> from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a> and navigate to the project’s root directory in the terminal. The notebook must be started from the location where the two files are stored.</p>
<div id="train-validation-test-split" class="section level2">
<h2>3.1 Train-Validation-Test Split</h2>
<p>In my post <a href="https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/#train-validation-test-split">Automate the Boring Stuff</a> I showed how to do such a split with image data automatically. I used exactly this syntax and packed it into a .py file to keep this notebook clear. You can also download this .py file from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a>.</p>
<p>Place this file (preprocessing_CNN.py) next to the folders <em>cats</em> and <em>dogs</em> and start your Jupyter notebook from here.</p>
<p>Your folder structure should then look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p1.png" /></p>
<p>The function stored in the preprocessing_CNN.py file (Train_Validation_Test_Split) can be used as follows:</p>
<pre class="r"><code>c_train, d_train, c_val, d_val, c_test, d_test = Train_Validation_Test_Split(&#39;cats&#39;, &#39;dogs&#39;)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p0.png" /></p>
<p>You only need to specify the two names of the folders in which the original image data is located or the entire path to the respective folders if you have stored the files somewhere else.</p>
<p>I have chosen the percentage distribution as follows:</p>
<ul>
<li>Trainings Part: 60%</li>
<li>Validation Part: 20%</li>
<li>Testing Part: 20%</li>
</ul>
<p>Using the executed function, folders and subfolders are automatically created for the areas of training, validation and testing, and the image data is randomly divided according to the specified proportions.</p>
<p>As you can read in the function itself it returns 6 values:</p>
<ul>
<li>list_cats_training (int): List of randomly selected images for the training part of the first category</li>
<li>list_dogs_training (int): List of randomly selected images for the training part of the second category</li>
<li>list_cats_validation (int): List of randomly selected images for the validation part of the first category</li>
<li>list_dogs_validation (int): List of randomly selected images for the validation part of the second category</li>
<li>list_cats_test (int): List of randomly selected images for the test part of the first category</li>
<li>list_dogs_test (int): List of randomly selected images for the test part of the second category</li>
</ul>
<p>You don’t have to have these metrics output, but I use them later to determine some parameter settings of the neural network. You save as much as you can with smart programming.</p>
</div>
<div id="obtaining-the-lists-of-randomly-selected-images" class="section level2">
<h2>3.2 Obtaining the lists of randomly selected images</h2>
<p>To make the naming of the output of the function more meaningful I rename it accordingly</p>
<pre class="r"><code>list_cats_training = c_train
list_dogs_training = d_train

list_cats_validation = c_val
list_dogs_validation = d_val

list_cats_test = c_test
list_dogs_test = d_test</code></pre>
</div>
<div id="determination-of-the-directories" class="section level2">
<h2>3.3 Determination of the directories</h2>
<p>Here I specify the path where the neural network can later find the data.</p>
<pre class="r"><code>root_directory = os.getcwd()

train_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train&#39;)
validation_dir = os.path.join(root_directory, &#39;cats_and_dogs\\validation&#39;)
test_dir = os.path.join(root_directory, &#39;cats_and_dogs\\test&#39;)</code></pre>
</div>
<div id="obtain-the-total-number-of-training-validation-and-test-images" class="section level2">
<h2>3.4 Obtain the total number of training, validation and test images</h2>
<p>Here I’m not interested in reissuing the folder sizes but much more in getting the total number of images for the respective areas.</p>
<pre class="r"><code>num_cats_img_train = len(list_cats_training)
num_dogs_img_train = len(list_dogs_training)

num_train_images_total = num_cats_img_train + num_dogs_img_train

print(&#39;Total training cat images: &#39; + str(num_cats_img_train))
print(&#39;Total training dog images: &#39; + str(num_dogs_img_train))
print()
print(&#39;Total training images: &#39; + str(num_train_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p2.png" /></p>
<pre class="r"><code>num_cats_img_validation = len(list_cats_validation)
num_dogs_img_validation = len(list_dogs_validation)

num_validation_images_total = num_cats_img_validation + num_dogs_img_validation

print(&#39;Total validation cat images: &#39; + str(num_cats_img_validation))
print(&#39;Total validation dog images: &#39; + str(num_dogs_img_validation))
print()
print(&#39;Total validation images: &#39; + str(num_validation_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p3.png" /></p>
<pre class="r"><code>num_cats_img_test = len(list_cats_test)
num_dogs_img_test = len(list_dogs_test)

num_test_images_total = num_cats_img_test + num_dogs_img_test

print(&#39;Total test cat images: &#39; + str(num_cats_img_test))
print(&#39;Total test dog images: &#39; + str(num_dogs_img_test))
print()
print(&#39;Total test images: &#39; + str(num_test_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p4.png" /></p>
<p>The folder structure should now look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p5.png" /></p>
</div>
</div>
<div id="descriptive-statistics" class="section level1">
<h1>4 Descriptive Statistics</h1>
<p>Here are a few more descriptive statistics on the images we have available to us:</p>
<pre class="r"><code>root_directory = os.getcwd()
train_files_cats_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train\\cats&#39;)

height, width = [], []

fnames = [&#39;cat{}.jpg&#39;.format(i) for i in list_cats_training]
for fname in fnames:
    img_name = os.path.join(train_files_cats_dir, fname)
    img = cv2.imread(img_name)
    height.append(img.shape[0])
    width.append(img.shape[1])

plt.scatter(height,width, s=1)
plt.xlabel(&#39;Height&#39;, fontsize=16)
plt.ylabel(&#39;Width&#39;, fontsize=16)
plt.title(&#39;Scatter Plot of Height and Width of cat train images&#39;)
plt.show()  </code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p6.png" /></p>
<pre class="r"><code>plt.hist(height,bins = 50, alpha=0.5)
plt.hist(width,bins = 50,alpha=0.5)
plt.axis([0,600,0,4000])
plt.xlabel(&#39;Height/Width&#39;, fontsize=16)
plt.ylabel(&#39;Num of Images&#39;, fontsize=16)
plt.title(&#39;Variation of image sizes within dataset&#39;)
plt.show()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p7.png" /></p>
<pre class="r"><code>root_directory = os.getcwd()
train_files_dogs_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train\\dogs&#39;)

height, width = [], []

fnames = [&#39;dog{}.jpg&#39;.format(i) for i in list_dogs_training]
for fname in fnames:
    img_name = os.path.join(train_files_dogs_dir, fname)
    img = cv2.imread(img_name)
    height.append(img.shape[0])
    width.append(img.shape[1])

plt.scatter(height,width, s=1)
plt.xlabel(&#39;Height&#39;, fontsize=16)
plt.ylabel(&#39;Width&#39;, fontsize=16)
plt.title(&#39;Scatter Plot of Height and Width of dog train images&#39;)
plt.show() </code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p8.png" /></p>
<pre class="r"><code>plt.hist(height,bins = 50, alpha=0.5)
plt.hist(width,bins = 50,alpha=0.5)
plt.axis([0,600,0,4000])
plt.xlabel(&#39;Height/Width&#39;, fontsize=16)
plt.ylabel(&#39;Num of Images&#39;, fontsize=16)
plt.title(&#39;Variation of image sizes within dataset&#39;)
plt.show()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p9.png" /></p>
</div>
<div id="simple-cnn" class="section level1">
<h1>5 Simple CNN</h1>
<div id="name-definitions" class="section level2">
<h2>5.1 Name Definitions</h2>
<p>I always want to save the created models right away. For this purpose, I specify the name of the folder in which the future model is to be saved and the name that the model itself is to receive.</p>
<pre class="r"><code>checkpoint_no = &#39;ckpt_1_simple_CNN&#39;
model_name = &#39;Cats_Dogs_CNN_4_Conv_F32_64_128_128_epoch_30&#39;</code></pre>
</div>
<div id="parameter-settings" class="section level2">
<h2>5.2 Parameter Settings</h2>
<p>First, I determine the height and width of the images as they are to be read into the model.
This then results in the input_shape. The 3 stands for the image depth. Since we are dealing with colored images, we have a depth of 3 for red, green and blue (RGB).</p>
<p><strong>batch_size</strong></p>
<p>Batch Size determines the number of samples in each mini-batch. Its maximum is the number of all samples, which makes the gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but the iterations are slower. Its minimum is 1, resulting in a stochastic gradient descent: Fast, but the direction of the gradient step is based on one example only, the loss can jump around. Batch Size allows setting between the two extremes: exact gradient direction and fast iteration. Also, the maximum value for Batch Size may be limited if your model and dataset do not fit in the available (GPU) memory.</p>
<p><strong>steps_per_epoch</strong></p>
<p>Steps per Epoch is the number of batch iterations before a training epoch is considered complete. If you have a fixed-size training dataset, you can ignore it, but it can be useful if you have a huge dataset or if you generate random data extensions on the fly, i.e. if your training dataset has a (generated) infinite size. If you have the time to go through your entire training dataset, I recommend skipping this parameter.</p>
<p><strong>validation_steps</strong> and <strong>test_steps</strong></p>
<p>These two parameter are similar to Steps per Epoch but on the validation and test data set instead on the training data. If you have the time to go through your whole validation and test data set I recommend to skip this parameter as well.</p>
<p><strong>n_epochs</strong></p>
<p>Number of epochs how often a complete run should be performed.
One epoch is when an entire dataset is passed forward and backward through the neural network only once.</p>
<p><code>We can divide a dataset of 2000 examples into Batch Size of 500 then it will take 4 Steps per Epoch to complete 1 epoch.</code></p>
<p>Here we see the reason why I have some metrics returned from the Train_Validation_Test_Split function. After I have set a batch size of 32, the total amount of 15,000 training images results in 468 steps per epoch, so that all images were seen once per epoch.</p>
<p>The same is true for validation and test steps.</p>
<pre class="r"><code>img_height = 150
img_width = 150
input_shape = (img_height, img_width, 3)

n_batch_size = 32

n_steps_per_epoch = int(num_train_images_total / n_batch_size)
n_validation_steps = int(num_validation_images_total / n_batch_size)
n_test_steps = int(num_test_images_total / n_batch_size)

n_epochs = 30

print(&#39;Input Shape: &#39;+&#39;(&#39;+str(img_height)+&#39;, &#39;+str(img_width)+&#39;, &#39; + str(3)+&#39;)&#39;)
print(&#39;Batch Size: &#39; + str(n_batch_size))
print()
print(&#39;Steps per Epoch: &#39; + str(n_steps_per_epoch))
print()
print(&#39;Validation Steps: &#39; + str(n_validation_steps))
print(&#39;Test Steps: &#39; + str(n_test_steps))
print()
print(&#39;Number of Epochs: &#39; + str(n_epochs))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p10.png" /></p>
<p>I will always need this information with the ImageDataGenerators as well. Therefore, it has become a best practice to define the parameters once based on the calculations of the metrics from the split function.</p>
</div>
<div id="instantiating-a-small-cnn" class="section level2">
<h2>5.3 Instantiating a small CNN</h2>
<div id="layer-structure" class="section level3">
<h3>5.3.1 Layer Structure</h3>
<pre class="r"><code>model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation=&#39;relu&#39;,input_shape=input_shape))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())

model.add(layers.Dense(512, activation=&#39;relu&#39;))
model.add(layers.Dense(1, activation=&#39;sigmoid&#39;))</code></pre>
<p>I set the last <strong>Dense Layer to 1</strong> and chose <strong>‘sigmoid’</strong> as the activation function, since this is a <strong>binary classification problem</strong>.</p>
<pre class="r"><code>model.summary()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p11.png" /></p>
<p>If you want to know how the total number of parameters is calculated, see this <a href="https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d">post</a>.</p>
</div>
<div id="configuring-the-model-for-training" class="section level3">
<h3>5.3.2 Configuring the model for training</h3>
<pre class="r"><code>model.compile(loss=&#39;binary_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])</code></pre>
</div>
<div id="using-imagedatagenerator" class="section level3">
<h3>5.3.3 Using ImageDataGenerator</h3>
<pre class="r"><code>train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)


train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p12.png" /></p>
</div>
</div>
<div id="callbacks" class="section level2">
<h2>5.4 Callbacks</h2>
<p>The Keras library offers the option of <a href="https://keras.io/api/callbacks/">callbacks</a>. Personally, I pretty much always use two of them:</p>
<ul>
<li><a href="https://keras.io/api/callbacks/model_checkpoint/">ModelCheckpoint</a></li>
<li><a href="https://keras.io/api/callbacks/early_stopping/">EarlyStopping</a></li>
</ul>
<p><strong>ModelCheckpoint</strong> gives me the possibility to automatically save models measured by a defined metric (here validation loss) if this metric has improved after an epoch.</p>
<p><strong>EarlyStopping</strong> protects me from unnecessary further training of the model if a particular metric does not continue to improve over a number of n epochs. In such a case, the model training would be automatically aborted.</p>
<p>But there are other useful callbacks like <a href="https://keras.io/api/callbacks/reduce_lr_on_plateau/">ReduceLROnPlateau</a>. Here, the learning rate would automatically reduce if a metric stopped improving.</p>
<p>In the following I first used only ModelCheckpoint but in the model training with Data Augmentation under chapter 6 I also included EarlyStopping.</p>
<pre class="r"><code># Prepare a directory to store all the checkpoints.
checkpoint_dir = &#39;./&#39;+ checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)</code></pre>
<pre class="r"><code>keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + &#39;/&#39; + model_name, 
                                   monitor=&#39;val_loss&#39;, save_best_only=True, mode=&#39;auto&#39;)]</code></pre>
</div>
<div id="fitting-the-model" class="section level2">
<h2>5.5 Fitting the model</h2>
<p>After we have already determined the parameters, we now benefit from the fact that we no longer have to make any manual entries.</p>
<pre class="r"><code>history = model.fit(
      train_generator,
      steps_per_epoch=n_steps_per_epoch,
      epochs=n_epochs,
      validation_data=validation_generator,
      validation_steps=n_validation_steps,
      callbacks=keras_callbacks)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p13.png" /></p>
<p>After model training, your folder structure should look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p14.png" /></p>
<p>Here we see that our callback (ModelCheckpoint) has automatically created a folder ‘ckpt_1_simple_CNN’ (the name I gave in chapter 5.1) with a subfolder containing the automatically saved model.</p>
</div>
<div id="obtaining-the-best-model-values" class="section level2">
<h2>5.6 Obtaining the best model values</h2>
<p>By using the callback ModelCheckpoint the model was saved which had the lowest validaton loss.
But what exactly were the values of this model?
With the following code I have the possibility to display the values per epoch.
And with this dataframe I also have the possibility to display the values for the model that was automatically saved.</p>
<pre class="r"><code>hist_df = pd.DataFrame(history.history)
hist_df[&#39;epoch&#39;] = hist_df.index + 1
cols = list(hist_df.columns)
cols = [cols[-1]] + cols[:-1]
hist_df = hist_df[cols]
hist_df.to_csv(checkpoint_no + &#39;/&#39; + &#39;history_df_&#39; + model_name + &#39;.csv&#39;)
hist_df.head()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p15.png" /></p>
<pre class="r"><code>values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]
values_of_best_model</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p16.png" /></p>
<p>Since I will possibly train several models in several notebooks at the same time, it is advisable at this point to save the dataframe shown above as a .csv file in order to be able to refer to it again at a later time, for example to compare the model performance of the best models.</p>
<p>I have now saved the history values in my ModelCheckpoint folder.
This folder now looks like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p17.png" /></p>
</div>
<div id="obtaining-class-assignments" class="section level2">
<h2>5.7 Obtaining class assignments</h2>
<p>In addition to the metric values achieved per epoch during model training, it is also advisable to have the assigned class distribution output and to save this information as a .csv file so that you can refer to it again later.</p>
<pre class="r"><code>class_assignment = train_generator.class_indices

df = pd.DataFrame([class_assignment], columns=class_assignment.keys())
df_stacked = df.stack()
df_temp = pd.DataFrame(df_stacked).reset_index().drop([&#39;level_0&#39;], axis=1)
df_temp.columns = [&#39;Category&#39;, &#39;Allocated Number&#39;]
df_temp.to_csv(checkpoint_no + &#39;/&#39; + &#39;class_assignment_df_&#39; + model_name + &#39;.csv&#39;)

print(&#39;Class assignment:&#39;, str(class_assignment))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p18.png" /></p>
<p>Both files (the history values and the class assignments) are now stored in my ModelCheckpoint folder.
This folder now looks like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p19.png" /></p>
</div>
<div id="validation" class="section level2">
<h2>5.8 Validation</h2>
<p>In the following I will generate two graphs showing the training and validation accuracy on the one hand and the training and validation loss on the other hand.</p>
<pre class="r"><code>acc = history.history[&#39;accuracy&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, &#39;bo&#39;, label=&#39;Training acc&#39;)
plt.plot(epochs, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;)
plt.title(&#39;Training and validation accuracy&#39;)
plt.legend()

plt.figure()

plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.legend()

plt.show()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p20.png" /></p>
<p>The graphs clearly show that we have a problem with <a href="https://towardsdatascience.com/overfitting-vs-underfitting-a-conceptual-explanation-d94ee20ca7f9">overfitting</a>.</p>
</div>
<div id="load-best-model" class="section level2">
<h2>5.9 Load best model</h2>
<p>As you can see from the current folder structure shown above, the automatically created subfolders inside the ModelCheckpoint folder are not that great. The best model was saved as a .pb file and did not get a proper naming.</p>
<p>I want my final model to be saved with apt naming under the created ModelCheckpoint folder.
Since I am aiming for this tidy approach I will load the .pb model below, save it as an .h5 file and delete the unnecessary folders.</p>
<p>Our ModelCheckpoint folder should then look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p21.png" /></p>
<p>The overall folder structure should look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p22.png" /></p>
<p>As a final step we load the saved .h5 model.</p>
<pre class="r"><code>best_model = load_model(model_name_temp)</code></pre>
</div>
<div id="model-testing" class="section level2">
<h2>5.10 Model Testing</h2>
<p>With the .h5 model reloaded, let’s now check the performance of the CNN using the test data.</p>
<pre class="r"><code>test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)

test_loss, test_acc = best_model.evaluate(test_generator, steps=n_test_steps)
print()
print(&#39;Test Accuracy:&#39;, test_acc)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p23.png" /></p>
<p>As expected, the performance is not that good yet. Therefore, we perform another model training.</p>
</div>
</div>
<div id="cnn-with-data-augmentation" class="section level1">
<h1>6 CNN with Data Augmentation</h1>
<p><a href="https://www.analyticsvidhya.com/blog/2020/08/image-augmentation-on-the-fly-using-keras-imagedatagenerator/">Data Augmentation</a> is a nice way to prevent overfitting, especially in computer vision. Here the amount of training is increased by rotating, stretching and other modification processes of the images.</p>
<p>Most steps and settings remain the same. Therefore, I will only discuss noteworthy changes in the following.</p>
<div id="name-definitions-1" class="section level2">
<h2>6.1 Name Definitions</h2>
<pre class="r"><code>checkpoint_no = &#39;ckpt_2_CNN_with_augm&#39;
model_name = &#39;Cats_Dogs_CNN_4_Conv_F32_64_128_128_epoch_60_es&#39;</code></pre>
</div>
<div id="parameter-settings-1" class="section level2">
<h2>6.2 Parameter Settings</h2>
<pre class="r"><code>img_height = 150
img_width = 150
input_shape = (img_height, img_width, 3)

n_batch_size = 64

n_steps_per_epoch = int(num_train_images_total / n_batch_size)
n_validation_steps = int(num_validation_images_total / n_batch_size)
n_test_steps = int(num_test_images_total / n_batch_size)

n_epochs = 60

print(&#39;Input Shape: &#39;+&#39;(&#39;+str(img_height)+&#39;, &#39;+str(img_width)+&#39;, &#39; + str(3)+&#39;)&#39;)
print(&#39;Batch Size: &#39; + str(n_batch_size))
print()
print(&#39;Steps per Epoch: &#39; + str(n_steps_per_epoch))
print()
print(&#39;Validation Steps: &#39; + str(n_validation_steps))
print(&#39;Test Steps: &#39; + str(n_test_steps))
print()
print(&#39;Number of Epochs: &#39; + str(n_epochs))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p24.png" /></p>
</div>
<div id="instantiating-a-cnn-with-data-augmentation" class="section level2">
<h2>6.3 Instantiating a CNN with Data Augmentation</h2>
<div id="layer-structure-1" class="section level3">
<h3>6.3.1 Layer Structure</h3>
<p>I have added an additional dropout layer here, which should also counteract overfittig.</p>
<pre class="r"><code>model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation=&#39;relu&#39;,input_shape=input_shape))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())

model.add(layers.Dropout(0.5))

model.add(layers.Dense(512, activation=&#39;relu&#39;))
model.add(layers.Dense(1, activation=&#39;sigmoid&#39;))</code></pre>
<pre class="r"><code>model.summary()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p25.png" /></p>
</div>
<div id="configuring-the-model-for-training-1" class="section level3">
<h3>6.3.2 Configuring the model for training</h3>
<pre class="r"><code>model.compile(loss=&#39;binary_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])</code></pre>
</div>
<div id="using-imagedatagenerator-with-data-augmentation" class="section level3">
<h3>6.3.3 Using ImageDataGenerator with data augmentation</h3>
<pre class="r"><code>train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,)

validation_datagen = ImageDataGenerator(rescale=1./255)



train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(img_height, img_width),
        batch_size=n_batch_size,
        class_mode=&#39;binary&#39;)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p26.png" /></p>
</div>
</div>
<div id="callbacks-1" class="section level2">
<h2>6.4 Callbacks</h2>
<p>As previously announced, I use not only the ModelCheckpoint callback here but also the EarlyStopping.</p>
<pre class="r"><code># Prepare a directory to store all the checkpoints.
checkpoint_dir = &#39;./&#39;+ checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)</code></pre>
<pre class="r"><code>keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + &#39;/&#39; + model_name, 
                                   monitor=&#39;val_loss&#39;, save_best_only=True, mode=&#39;auto&#39;),
                   EarlyStopping(monitor=&#39;val_loss&#39;, patience=5, mode=&#39;auto&#39;, 
                                 min_delta = 0, verbose=1)]</code></pre>
</div>
<div id="fitting-the-model-1" class="section level2">
<h2>6.5 Fitting the model</h2>
<pre class="r"><code>history = model.fit(
      train_generator,
      steps_per_epoch=n_steps_per_epoch,
      epochs=n_epochs,
      validation_data=validation_generator,
      validation_steps=n_validation_steps,
      callbacks=keras_callbacks)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p27.png" /></p>
</div>
<div id="obtaining-the-best-model-values-1" class="section level2">
<h2>6.6 Obtaining the best model values</h2>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
<div id="obtaining-class-assignments-1" class="section level2">
<h2>6.7 Obtaining class assignments</h2>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
<div id="validation-1" class="section level2">
<h2>6.8 Validation</h2>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
<div id="load-best-model-1" class="section level2">
<h2>6.9 Load best model</h2>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
<div id="model-testing-1" class="section level2">
<h2>6.10 Model Testing</h2>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
</div>
