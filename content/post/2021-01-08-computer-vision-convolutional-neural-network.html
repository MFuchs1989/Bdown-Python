---
title: Computer Vision - Convolutional Neural Network
author: Michael Fuchs
date: '2021-01-08'
slug: computer-vision-convolutional-neural-network
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries">2 Import the libraries</a></li>
<li><a href="#data-pre-processing">3 Data pre-processing</a>
<ul>
<li><a href="#train-validation-test-split">3.1 Train-Validation-Test Split</a></li>
<li><a href="#obtaining-the-lists-of-randomly-selected-images">3.2 Obtaining the lists of randomly selected images</a></li>
<li><a href="#determination-of-the-directories">3.3 Determination of the directories</a></li>
<li><a href="#obtain-the-total-number-of-training-validation-and-test-images">3.4 Obtain the total number of training, validation and test images</a></li>
</ul></li>
<li><a href="#descriptive-statistics">4 Descriptive Statistics</a></li>
<li><a href="#simple-cnn">5 Simple CNN</a>
<ul>
<li><a href="#name-definitions">5.1 Name Definitions</a></li>
<li><a href="#parameter-settings">5.2 Parameter Settings</a></li>
<li><a href="#instantiating-a-small-cnn">5.3 Instantiating a small CNN</a>
<ul>
<li><a href="#layer-structure">5.3.1 Layer Structure</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>So we got into <a href="https://tryolabs.com/resources/introductory-guide-computer-vision/">Computer Vision</a> and I described how to deal with image data in my last post <a href="https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/">Automate the Boring Stuff</a>.
Here I have also shown how to automatically split a dataset of images into a training, validation and test part.</p>
<p>I’ll barely cover that part in the post below and focus entirely on the topic at hand: How to classify the content of images using <strong>Convolutional Neural Networks</strong>.</p>
<p>What is a [Convolutional Neural(<a href="https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/" class="uri">https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/</a>) Network] (CNN)?</p>
<p>A CNN is is a deep learning neural network designed for processing structured arrays of data such as images.
Convolutional Neural Networks are widely used in computer vision and have become the state of the art for many visual applications such as image classification.
However, they can also be used for Recommender Systems, Natural Language Processing or Time Series Forecasting.</p>
<p>CNNs are very good at picking up on patterns in the input image, such as lines, gradients, circles or even eyes and faces. It is this property that makes CNNs so powerful for Computer Vision.
A CNN is a <a href="https://deepai.org/machine-learning-glossary-and-terms/feed-forward-neural-network">feed-forward neural network</a>. The power of a CNN comes from a special kind of layer called the <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">convolutional layer</a>.
CNNs contain many convolutional layers stacked on top of each other, each one capable of recognizing more sophisticated shapes.</p>
<p align="center">
<img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2020/05/Cats-Dogs-Classification-deep-learning.gif?raw=true" alt="readme crisp dm"/>
</p>
<p>In this publication I will show how to classify image data using a CNN.
For this I used the images from the <em>cats and dogs</em> dataset from the statistics platform <a href="https://www.kaggle.com/c/dogs-vs-cats/data">“Kaggle”</a>. You can download the used data from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries" class="section level1">
<h1>2 Import the libraries</h1>
<pre class="r"><code>from preprocessing_CNN import Train_Validation_Test_Split

import numpy as np
import pandas as pd

import os
import shutil

import cv2 
import matplotlib.pyplot as plt
%matplotlib inline 

from keras import layers
from keras import models
from keras.callbacks import EarlyStopping, ModelCheckpoint

from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model</code></pre>
</div>
<div id="data-pre-processing" class="section level1">
<h1>3 Data pre-processing</h1>
<p>To get started with the training of a CNN, we first have to divide the data set into a training, validation and test part and determine some directories and metrics, so that we have less work later and can run through all processes fully automatically.</p>
<p>Please download the two folders <em>cats</em> and <em>dogs</em> from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a> and navigate to the project’s root directory in the terminal. The notebook must be started from the location where the two files are stored.</p>
<div id="train-validation-test-split" class="section level2">
<h2>3.1 Train-Validation-Test Split</h2>
<p>In my post <a href="https://michael-fuchs-python.netlify.app/2021/01/01/computer-vision-automate-the-boring-stuff/#train-validation-test-split">Automate the Boring Stuff</a> I showed how to do such a split with image data automatically. I used exactly this syntax and packed it into a .py file to keep this notebook clear. You can also download this .py file from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/Computer%20Vision/Convolutional%20Neural%20Network">“GitHub Repository”</a>.</p>
<p>Place this file (preprocessing_CNN.py) next to the folders <em>cats</em> and <em>dogs</em> and start your Jupyter notebook from here.</p>
<p>Your folder structure should then look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p1.png" /></p>
<p>The function stored in the preprocessing_CNN.py file (Train_Validation_Test_Split) can be used as follows:</p>
<pre class="r"><code>c_train, d_train, c_val, d_val, c_test, d_test = Train_Validation_Test_Split(&#39;cats&#39;, &#39;dogs&#39;)</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p0.png" /></p>
<p>You only need to specify the two names of the folders in which the original image data is located or the entire path to the respective folders if you have stored the files somewhere else.</p>
<p>I have chosen the percentage distribution as follows:</p>
<ul>
<li>Trainings Part: 60%</li>
<li>Validation Part: 20%</li>
<li>Testing Part: 20%</li>
</ul>
<p>Using the executed function, folders and subfolders are automatically created for the areas of training, validation and testing, and the image data is randomly divided according to the specified proportions.</p>
<p>As you can read in the function itself it returns 6 values:</p>
<ul>
<li>list_cats_training (int): List of randomly selected images for the training part of the first category</li>
<li>list_dogs_training (int): List of randomly selected images for the training part of the second category</li>
<li>list_cats_validation (int): List of randomly selected images for the validation part of the first category</li>
<li>list_dogs_validation (int): List of randomly selected images for the validation part of the second category</li>
<li>list_cats_test (int): List of randomly selected images for the test part of the first category</li>
<li>list_dogs_test (int): List of randomly selected images for the test part of the second category</li>
</ul>
<p>You don’t have to have these metrics output, but I use them later to determine some parameter settings of the neural network. You save as much as you can with smart programming.</p>
</div>
<div id="obtaining-the-lists-of-randomly-selected-images" class="section level2">
<h2>3.2 Obtaining the lists of randomly selected images</h2>
<p>To make the naming of the output of the function more meaningful I rename it accordingly</p>
<pre class="r"><code>list_cats_training = c_train
list_dogs_training = d_train

list_cats_validation = c_val
list_dogs_validation = d_val

list_cats_test = c_test
list_dogs_test = d_test</code></pre>
</div>
<div id="determination-of-the-directories" class="section level2">
<h2>3.3 Determination of the directories</h2>
<p>Here I specify the path where the neural network can later find the data.</p>
<pre class="r"><code>root_directory = os.getcwd()

train_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train&#39;)
validation_dir = os.path.join(root_directory, &#39;cats_and_dogs\\validation&#39;)
test_dir = os.path.join(root_directory, &#39;cats_and_dogs\\test&#39;)</code></pre>
</div>
<div id="obtain-the-total-number-of-training-validation-and-test-images" class="section level2">
<h2>3.4 Obtain the total number of training, validation and test images</h2>
<p>Here I’m not interested in reissuing the folder sizes but much more in getting the total number of images for the respective areas.</p>
<pre class="r"><code>num_cats_img_train = len(list_cats_training)
num_dogs_img_train = len(list_dogs_training)

num_train_images_total = num_cats_img_train + num_dogs_img_train

print(&#39;Total training cat images: &#39; + str(num_cats_img_train))
print(&#39;Total training dog images: &#39; + str(num_dogs_img_train))
print()
print(&#39;Total training images: &#39; + str(num_train_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p2.png" /></p>
<pre class="r"><code>num_cats_img_validation = len(list_cats_validation)
num_dogs_img_validation = len(list_dogs_validation)

num_validation_images_total = num_cats_img_validation + num_dogs_img_validation

print(&#39;Total validation cat images: &#39; + str(num_cats_img_validation))
print(&#39;Total validation dog images: &#39; + str(num_dogs_img_validation))
print()
print(&#39;Total validation images: &#39; + str(num_validation_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p3.png" /></p>
<pre class="r"><code>num_cats_img_test = len(list_cats_test)
num_dogs_img_test = len(list_dogs_test)

num_test_images_total = num_cats_img_test + num_dogs_img_test

print(&#39;Total test cat images: &#39; + str(num_cats_img_test))
print(&#39;Total test dog images: &#39; + str(num_dogs_img_test))
print()
print(&#39;Total test images: &#39; + str(num_test_images_total))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p4.png" /></p>
<p>The folder structure should now look like this:</p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p5.png" /></p>
</div>
</div>
<div id="descriptive-statistics" class="section level1">
<h1>4 Descriptive Statistics</h1>
<p>Here are a few more descriptive statistics on the images we have available to us:</p>
<pre class="r"><code>root_directory = os.getcwd()
train_files_cats_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train\\cats&#39;)

height, width = [], []

fnames = [&#39;cat{}.jpg&#39;.format(i) for i in list_cats_training]
for fname in fnames:
    img_name = os.path.join(train_files_cats_dir, fname)
    img = cv2.imread(img_name)
    height.append(img.shape[0])
    width.append(img.shape[1])

plt.scatter(height,width, s=1)
plt.xlabel(&#39;Height&#39;, fontsize=16)
plt.ylabel(&#39;Width&#39;, fontsize=16)
plt.title(&#39;Scatter Plot of Height and Width of cat train images&#39;)
plt.show()  </code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p6.png" /></p>
<pre class="r"><code>plt.hist(height,bins = 50, alpha=0.5)
plt.hist(width,bins = 50,alpha=0.5)
plt.axis([0,600,0,4000])
plt.xlabel(&#39;Height/Width&#39;, fontsize=16)
plt.ylabel(&#39;Num of Images&#39;, fontsize=16)
plt.title(&#39;Variation of image sizes within dataset&#39;)
plt.show()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p7.png" /></p>
<pre class="r"><code>root_directory = os.getcwd()
train_files_dogs_dir = os.path.join(root_directory, &#39;cats_and_dogs\\train\\dogs&#39;)

height, width = [], []

fnames = [&#39;dog{}.jpg&#39;.format(i) for i in list_dogs_training]
for fname in fnames:
    img_name = os.path.join(train_files_dogs_dir, fname)
    img = cv2.imread(img_name)
    height.append(img.shape[0])
    width.append(img.shape[1])

plt.scatter(height,width, s=1)
plt.xlabel(&#39;Height&#39;, fontsize=16)
plt.ylabel(&#39;Width&#39;, fontsize=16)
plt.title(&#39;Scatter Plot of Height and Width of dog train images&#39;)
plt.show() </code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p8.png" /></p>
<pre class="r"><code>plt.hist(height,bins = 50, alpha=0.5)
plt.hist(width,bins = 50,alpha=0.5)
plt.axis([0,600,0,4000])
plt.xlabel(&#39;Height/Width&#39;, fontsize=16)
plt.ylabel(&#39;Num of Images&#39;, fontsize=16)
plt.title(&#39;Variation of image sizes within dataset&#39;)
plt.show()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p9.png" /></p>
</div>
<div id="simple-cnn" class="section level1">
<h1>5 Simple CNN</h1>
<div id="name-definitions" class="section level2">
<h2>5.1 Name Definitions</h2>
<p>I always want to save the created models right away. For this purpose, I specify the name of the folder in which the future model is to be saved and the name that the model itself is to receive.</p>
<pre class="r"><code>checkpoint_no = &#39;ckpt_1_simple_CNN&#39;
model_name = &#39;Cats_Dogs_CNN_4_Conv_F32_64_128_128_epoch_30&#39;</code></pre>
</div>
<div id="parameter-settings" class="section level2">
<h2>5.2 Parameter Settings</h2>
<p>First, I determine the height and width of the images as they are to be read into the model.
This then results in the input_shape. The 3 stands for the image depth. Since we are dealing with colored images, we have a depth of 3 for red, green and blue (RGB).</p>
<p><strong>batch_size</strong></p>
<p>Batch Size determines the number of samples in each mini-batch. Its maximum is the number of all samples, which makes the gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but the iterations are slower. Its minimum is 1, resulting in a stochastic gradient descent: Fast, but the direction of the gradient step is based on one example only, the loss can jump around. Batch Size allows setting between the two extremes: exact gradient direction and fast iteration. Also, the maximum value for Batch Size may be limited if your model and dataset do not fit in the available (GPU) memory.</p>
<p><strong>steps_per_epoch</strong></p>
<p>Steps per Epoch is the number of batch iterations before a training epoch is considered complete. If you have a fixed-size training dataset, you can ignore it, but it can be useful if you have a huge dataset or if you generate random data extensions on the fly, i.e. if your training dataset has a (generated) infinite size. If you have the time to go through your entire training dataset, I recommend skipping this parameter.</p>
<p><strong>validation_steps</strong> and <strong>test_steps</strong></p>
<p>These two parameter are similar to Steps per Epoch but on the validation and test data set instead on the training data. If you have the time to go through your whole validation and test data set I recommend to skip this parameter as well.</p>
<p><strong>n_epochs</strong></p>
<p>Number of epochs how often a complete run should be performed.
One epoch is when an entire dataset is passed forward and backward through the neural network only once.</p>
<p><code>We can divide a dataset of 2000 examples into Batch Size of 500 then it will take 4 Steps per Epoch to complete 1 epoch.</code></p>
<p>Here we see the reason why I have some metrics returned from the Train_Validation_Test_Split function. After I have set a batch size of 32, the total amount of 15,000 training images results in 468 steps per epoch, so that all images were seen once per epoch.</p>
<p>The same is true for validation and test steps.</p>
<pre class="r"><code>img_height = 150
img_width = 150
input_shape = (img_height, img_width, 3)

n_batch_size = 32

n_steps_per_epoch = int(num_train_images_total / n_batch_size)
n_validation_steps = int(num_validation_images_total / n_batch_size)
n_test_steps = int(num_test_images_total / n_batch_size)

n_epochs = 30

print(&#39;Input Shape: &#39;+&#39;(&#39;+str(img_height)+&#39;, &#39;+str(img_width)+&#39;, &#39; + str(3)+&#39;)&#39;)
print(&#39;Batch Size: &#39; + str(n_batch_size))
print()
print(&#39;Steps per Epoch: &#39; + str(n_steps_per_epoch))
print()
print(&#39;Validation Steps: &#39; + str(n_validation_steps))
print(&#39;Test Steps: &#39; + str(n_test_steps))
print()
print(&#39;Number of Epochs: &#39; + str(n_epochs))</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p10.png" /></p>
<p>I will always need this information with the ImageDataGenerators as well. Therefore, it has become a best practice to define the parameters once based on the calculations of the metrics from the split function.</p>
</div>
<div id="instantiating-a-small-cnn" class="section level2">
<h2>5.3 Instantiating a small CNN</h2>
<div id="layer-structure" class="section level3">
<h3>5.3.1 Layer Structure</h3>
<pre class="r"><code>model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation=&#39;relu&#39;,input_shape=input_shape))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())

model.add(layers.Dense(512, activation=&#39;relu&#39;))
model.add(layers.Dense(1, activation=&#39;sigmoid&#39;))</code></pre>
<p>I set the last <strong>Dense Layer to 1</strong> and chose <strong>‘sigmoid’</strong> as the activation function, since this is a <strong>binary classification problem</strong>.</p>
<pre class="r"><code>model.summary()</code></pre>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p11.png" /></p>
<p>Wie die parameter sich berechnen:</p>
<p><a href="https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d" class="uri">https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d</a></p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
<p><img src="/post/2021-01-08-computer-vision-convolutional-neural-network_files/p104p.png" /></p>
</div>
</div>
</div>
