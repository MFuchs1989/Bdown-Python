---
title: NLP - Text Pre-Processing V (Text Exploration)
author: Michael Fuchs
date: '2021-06-10'
slug: nlp-text-pre-processing-v-text-exploration
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-data">2 Import the Libraries and the Data</a></li>
<li><a href="#definition-of-required-functions">3 Definition of required Functions</a></li>
<li><a href="#text-pre-processing">4 Text Pre-Processing</a>
<ul>
<li><a href="#text-cleaning">4.1 (Text Cleaning)</a></li>
<li><a href="#tokenization">4.2 (Tokenization)</a></li>
<li><a href="#stop-words">4.3 (Stop Words)</a></li>
<li><a href="#digression-pos-ner">4.4 (Digression: POS &amp; NER)</a></li>
<li><a href="#normalization">4.5 (Normalization)</a></li>
<li><a href="#removing-single-characters">4.6 (Removing Single Characters)</a></li>
<li><a href="#text-exploration">4.7 Text Exploration</a>
<ul>
<li><a href="#descriptive-statistics">4.7.1 Descriptive Statistics</a>
<ul>
<li><a href="#most-common-words">4.7.1.1 Most common Words</a></li>
<li><a href="#least-common-words">4.7.1.2 Least common Words</a></li>
</ul></li>
<li><a href="#text-visualization">4.7.2 Text Visualization</a>
<ul>
<li><a href="#via-bar-charts">4.7.2.1 via Bar Charts</a></li>
<li><a href="#via-word-clouds">4.7.2.2 via Word Clouds</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Now that we have completed some pre-processing steps, I always like to start text exploration and visualization at this point.</p>
<p>For this publication the processed dataset <em>Amazon Unlocked Mobile</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used as well as the created Example String. You can download both files from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/NLP/Text%20Pre-Processing%20V%20(Text%20Exploration)">“GitHub Repository”</a>.</p>
</div>
<div id="import-the-libraries-and-the-data" class="section level1">
<h1>2 Import the Libraries and the Data</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

import pickle as pk

import warnings
warnings.filterwarnings(&quot;ignore&quot;)


from bs4 import BeautifulSoup
import unicodedata
import re

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize

from nltk.corpus import stopwords


from nltk.corpus import wordnet
from nltk import pos_tag
from nltk import ne_chunk

from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer

from nltk.probability import FreqDist
import matplotlib.pyplot as plt
from wordcloud import WordCloud</code></pre>
<pre class="r"><code>pd.set_option(&#39;display.max_colwidth&#39;, 30)</code></pre>
<pre class="r"><code>df = pd.read_csv(&#39;Amazon_Unlocked_Mobile_small_Part_IV.csv&#39;)
df.head(3).T</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p1.png" /></p>
<pre class="r"><code>df[&#39;Reviews_cleaned_wo_single_char&#39;] = df[&#39;Reviews_cleaned_wo_single_char&#39;].astype(str)</code></pre>
<pre class="r"><code>clean_text_wo_single_char = pk.load(open(&quot;clean_text_wo_single_char.pkl&quot;,&#39;rb&#39;))
clean_text_wo_single_char</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p2.png" /></p>
</div>
<div id="definition-of-required-functions" class="section level1">
<h1>3 Definition of required Functions</h1>
<p>All functions are summarized here. I will show them again where they are used during this post if they are new and have not been explained yet.</p>
<pre class="r"><code>def token_and_unique_word_count_func(text):
    &#39;&#39;&#39;
    Outputs the number of words and unique words
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to count unique words
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Prints:
        Number of existing tokens and number of unique words
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    print(&#39;Number of tokens: &#39; + str(len(words))) 
    print(&#39;Number of unique words: &#39; + str(len(fdist)))</code></pre>
<pre class="r"><code>def most_common_word_func(text, n_words=25):
    &#39;&#39;&#39;
    Returns a DataFrame with the most commonly used words from a text with their frequencies
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to determine the word frequency
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        A DataFrame with the most commonly occurring words (by default = 25) with their frequencies
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    n_words = n_words
    
    df_fdist = pd.DataFrame({&#39;Word&#39;: fdist.keys(),
                             &#39;Frequency&#39;: fdist.values()})
    df_fdist = df_fdist.sort_values(by=&#39;Frequency&#39;, ascending=False).head(n_words)
    
    return df_fdist</code></pre>
<pre class="r"><code>def least_common_word_func(text, n_words=25):
    &#39;&#39;&#39;
    Returns a DataFrame with the least commonly used words from a text with their frequencies
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to determine the word frequency
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        A DataFrame with the least commonly occurring words (by default = 25) with their frequencies
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    n_words = n_words
    
    df_fdist = pd.DataFrame({&#39;Word&#39;: fdist.keys(),
                             &#39;Frequency&#39;: fdist.values()})
    df_fdist = df_fdist.sort_values(by=&#39;Frequency&#39;, ascending=False).tail(n_words)
    
    return df_fdist</code></pre>
</div>
<div id="text-pre-processing" class="section level1">
<h1>4 Text Pre-Processing</h1>
<div id="text-cleaning" class="section level2">
<h2>4.1 (Text Cleaning)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/22/nlp-text-pre-processing-i-text-cleaning/#text-cleaning">Text Cleaning</a></p>
</div>
<div id="tokenization" class="section level2">
<h2>4.2 (Tokenization)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#tokenization">Text Pre-Processing II-Tokenization</a></p>
</div>
<div id="stop-words" class="section level2">
<h2>4.3 (Stop Words)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/#stop-words">Text Pre-Processing II-Stop Words</a></p>
</div>
<div id="digression-pos-ner" class="section level2">
<h2>4.4 (Digression: POS &amp; NER)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#digression-pos-ner">Text Pre-Processing III-POS &amp; NER</a></p>
</div>
<div id="normalization" class="section level2">
<h2>4.5 (Normalization)</h2>
<p>I have already described this part in an earlier post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/05/31/nlp-text-pre-processing-iii-pos-ner-and-normalization/#normalization">Text Pre-Processing III-Normalization</a></p>
</div>
<div id="removing-single-characters" class="section level2">
<h2>4.6 (Removing Single Characters)</h2>
<p>I have already described this part in the previous post. See here: <a href="https://michael-fuchs-python.netlify.app/2021/06/05/nlp-text-pre-processing-iv-single-character-removal/#removing-single-characters">Text Pre-Processing IV-Removing Single Characters</a></p>
</div>
<div id="text-exploration" class="section level2">
<h2>4.7 Text Exploration</h2>
<div id="descriptive-statistics" class="section level3">
<h3>4.7.1 Descriptive Statistics</h3>
<p>For better readability, I have added punctuation to the following example sentence. At this point in the text preprocessing, these would no longer be present, nor would stop words or other words with little or no information content.</p>
<p>But that doesn’t matter. You can use this analysis in different places, you just have to keep in mind how clean your text already is and whether punctuation marks or similar are counted.</p>
<pre class="r"><code>text_for_exploration = \
&quot;To begin to toboggan first buy a toboggan, but do not buy too big a toboggan. \
Too big a toboggan is too big a toboggan to buy to begin to toboggan.&quot;
text_for_exploration</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p3.png" /></p>
<pre class="r"><code>def token_and_unique_word_count_func(text):
    &#39;&#39;&#39;
    Outputs the number of words and unique words
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to count unique words
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Prints:
        Number of existing tokens and number of unique words
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    print(&#39;Number of tokens: &#39; + str(len(words))) 
    print(&#39;Number of unique words: &#39; + str(len(fdist)))</code></pre>
<pre class="r"><code>token_and_unique_word_count_func(text_for_exploration)</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p4.png" /></p>
<div id="most-common-words" class="section level4">
<h4>4.7.1.1 Most common Words</h4>
<pre class="r"><code>def most_common_word_func(text, n_words=25):
    &#39;&#39;&#39;
    Returns a DataFrame with the most commonly used words from a text with their frequencies
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to determine the word frequency
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        A DataFrame with the most commonly occurring words (by default = 25) with their frequencies
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    n_words = n_words
    
    df_fdist = pd.DataFrame({&#39;Word&#39;: fdist.keys(),
                             &#39;Frequency&#39;: fdist.values()})
    df_fdist = df_fdist.sort_values(by=&#39;Frequency&#39;, ascending=False).head(n_words)
    
    return df_fdist</code></pre>
<pre class="r"><code>most_common_word_func(text_for_exploration)</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p5.png" /></p>
<pre class="r"><code>df_most_common_words_10 = most_common_word_func(text_for_exploration, n_words=10)
df_most_common_words_10</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p6.png" /></p>
</div>
<div id="least-common-words" class="section level4">
<h4>4.7.1.2 Least common Words</h4>
<pre class="r"><code>def least_common_word_func(text, n_words=25):
    &#39;&#39;&#39;
    Returns a DataFrame with the least commonly used words from a text with their frequencies
    
    Step 1: Use word_tokenize() to get tokens from string
    Step 2: Uses the FreqDist function to determine the word frequency
    
    Args:
        text (str): String to which the functions are to be applied, string
    
    Returns:
        A DataFrame with the least commonly occurring words (by default = 25) with their frequencies
    &#39;&#39;&#39; 
    words = word_tokenize(text)
    fdist = FreqDist(words) 
    
    n_words = n_words
    
    df_fdist = pd.DataFrame({&#39;Word&#39;: fdist.keys(),
                             &#39;Frequency&#39;: fdist.values()})
    df_fdist = df_fdist.sort_values(by=&#39;Frequency&#39;, ascending=False).tail(n_words)
    
    return df_fdist</code></pre>
<pre class="r"><code>least_common_word_func(text_for_exploration, 3)</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p7.png" /></p>
</div>
</div>
<div id="text-visualization" class="section level3">
<h3>4.7.2 Text Visualization</h3>
<p>Note: I apply the visualization only once to the most common words for now.</p>
<div id="via-bar-charts" class="section level4">
<h4>4.7.2.1 via Bar Charts</h4>
<pre class="r"><code>plt.figure(figsize=(11,7))
plt.bar(df_most_common_words_10[&#39;Word&#39;], 
        df_most_common_words_10[&#39;Frequency&#39;])

plt.xlabel(&#39;Most common Words&#39;)
plt.ylabel(&quot;Frequency&quot;)
plt.title(&quot;Frequency distribution of the 10 most common words&quot;)

plt.show()</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p8.png" /></p>
</div>
<div id="via-word-clouds" class="section level4">
<h4>4.7.2.2 via Word Clouds</h4>
<p>With the WordCloud function, you can also have the most frequently occurring words displayed visually. The advantage is that by default all stop words or irrelevant characters are removed from the display.
The parameters that can still be set can be read <a href="https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html">here</a>.</p>
<pre class="r"><code>wordcloud = WordCloud(width = 800, height = 800,
                background_color =&#39;white&#39;,
                min_font_size = 10).generate(text_for_exploration)

plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;)
plt.axis(&quot;off&quot;)
  
plt.show()</code></pre>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p9.png" /></p>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p.png" /></p>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p.png" /></p>
<p><img src="/post/2021-06-10-nlp-text-pre-processing-v-text-exploration_files/p127p.png" /></p>
</div>
</div>
</div>
</div>
