---
title: NN – Artificial Neural Network for Multi-Class Classfication
author: Michael Fuchs
date: '2021-02-23'
slug: nn-artificial-neural-network-for-multi-class-classfication
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#loading-the-libraries">2 Loading the libraries</a></li>
<li><a href="#loading-the-data">3 Loading the data</a></li>
<li><a href="#data-pre-processing">4 Data pre-processing</a>
<ul>
<li><a href="#determination-of-the-predictors-and-the-criterion">4.1 Determination of the predictors and the criterion</a></li>
<li><a href="#encoding">4.2 Encoding</a></li>
<li><a href="#train-validation-test-split">4.3 Train-Validation-Test Split</a></li>
<li><a href="#check-if-all-classes-are-included-in-every-split-part">4.4 Check if all classes are included in every split part</a></li>
</ul></li>
<li><a href="#ann-for-multi-class-classfication">5 ANN for Multi-Class Classfication</a>
<ul>
<li><a href="#name-definitions">5.1 Name Definitions</a></li>
<li><a href="#parameter-settings">5.2 Parameter Settings</a></li>
<li><a href="#layer-structure">5.3 Layer Structure</a></li>
<li><a href="#configuring-the-model-for-training">5.4 Configuring the model for training</a></li>
<li><a href="#callbacks">5.5 Callbacks</a></li>
<li><a href="#fitting-the-model">5.6 Fitting the model</a></li>
<li><a href="#obtaining-the-best-model-values">5.7 Obtaining the best model values</a></li>
<li><a href="#obtaining-class-assignments">5.8 Obtaining class assignments</a></li>
<li><a href="#validation">5.9 Validation</a></li>
<li><a href="#load-best-model">5.10 Load best model</a></li>
<li><a href="#model-testing">5.11 Model Testing</a></li>
<li><a href="#predictions">5.12 Predictions</a></li>
</ul></li>
<li><a href="#prevent-overfitting">6 Prevent Overfitting</a></li>
<li><a href="#conclusion">7 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>In my last post, I showed how to do <a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/">binary classification</a> using the Keras deep learning library. Now I would like to show how to make multi-class classifications.</p>
<p>For this publication the dataset <em>bird</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets">“GitHub Repository”</a>.</p>
</div>
<div id="loading-the-libraries" class="section level1">
<h1>2 Loading the libraries</h1>
<pre class="r"><code>import pandas as pd
import numpy as np
import os
import shutil
import pickle as pk
import matplotlib.pyplot as plt

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

from keras import models
from keras import layers
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import load_model</code></pre>
</div>
<div id="loading-the-data" class="section level1">
<h1>3 Loading the data</h1>
<pre class="r"><code>df = pd.read_csv(&#39;bird.csv&#39;).dropna()

print()
print(&#39;Shape of dataframe:&#39;)
print(str(df.shape))
print()
print(&#39;Head of dataframe:&#39;)
df.head()</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p1.png" /></p>
<p>Description of predictors:</p>
<ul>
<li>Length and Diameter of Humerus</li>
<li>Length and Diameter of Ulna</li>
<li>Length and Diameter of Femur</li>
<li>Length and Diameter of Tibiotarsus</li>
<li>Length and Diameter of Tarsometatarsus</li>
</ul>
<pre class="r"><code>df[&#39;type&#39;].value_counts()</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p2.png" /></p>
<p>Description of the target variable:</p>
<ul>
<li>SW: Swimming Birds</li>
<li>W: Wading Birds</li>
<li>T: Terrestrial Birds</li>
<li>R: Raptors</li>
<li>P: Scansorial Birds</li>
<li>SO: Singing Birds</li>
</ul>
</div>
<div id="data-pre-processing" class="section level1">
<h1>4 Data pre-processing</h1>
<div id="determination-of-the-predictors-and-the-criterion" class="section level2">
<h2>4.1 Determination of the predictors and the criterion</h2>
<pre class="r"><code>x = df.drop(&#39;type&#39;, axis=1)
y = df[&#39;type&#39;]</code></pre>
</div>
<div id="encoding" class="section level2">
<h2>4.2 Encoding</h2>
<p>Last time (<a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#encoding">Artificial Neural Network for binary Classification</a>) we used <a href="https://michael-fuchs-python.netlify.app/2019/06/16/types-of-encoder/#label-encoding">LabelEncoder</a> for this. Since we now want to do a multi-class classification we need <a href="https://michael-fuchs-python.netlify.app/2019/06/16/types-of-encoder/#one-hot-encoder">One-Hot Encoding</a>.</p>
<pre class="r"><code>encoder = OneHotEncoder()

encoded_Y = encoder.fit(y.values.reshape(-1,1))
encoded_Y = encoded_Y.transform(y.values.reshape(-1,1)).toarray()

encoded_Y</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p3.png" /></p>
</div>
<div id="train-validation-test-split" class="section level2">
<h2>4.3 Train-Validation-Test Split</h2>
<p>In the following, I will randomly assign 70% of the data to the training part and 15% each to the validation and test part.</p>
<pre class="r"><code>train_ratio = 0.70
validation_ratio = 0.15
test_ratio = 0.15

# Generate TrainX and TrainY
trainX, testX, trainY, testY = train_test_split(x, encoded_Y, test_size= 1 - train_ratio)
# Genearate ValX, TestX, ValY and TestY
valX, testX, valY, testY = train_test_split(testX, testY, test_size=test_ratio/(test_ratio + validation_ratio))</code></pre>
<pre class="r"><code>print(trainX.shape)
print(valX.shape)
print(testX.shape)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p4.png" /></p>
</div>
<div id="check-if-all-classes-are-included-in-every-split-part" class="section level2">
<h2>4.4 Check if all classes are included in every split part</h2>
<p>Since this is a very small dataset with 413 observations and the least represented class contains only 23 observations, I advise at this point to check whether all classes are included in the variables created by the train validation test split.</p>
<pre class="r"><code>re_transformed_array_trainY = encoder.inverse_transform(trainY)

unique_elements, counts_elements = np.unique(re_transformed_array_trainY, return_counts=True)
unique_elements_and_counts_trainY = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)
unique_elements_and_counts_trainY.columns = [&#39;unique_elements&#39;, &#39;count&#39;]

unique_elements_and_counts_trainY</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p5.png" /></p>
<pre class="r"><code>re_transformed_array_valY = encoder.inverse_transform(valY)

unique_elements, counts_elements = np.unique(re_transformed_array_valY, return_counts=True)
unique_elements_and_counts_valY = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)
unique_elements_and_counts_valY.columns = [&#39;unique_elements&#39;, &#39;count&#39;]

unique_elements_and_counts_valY</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p6.png" /></p>
<pre class="r"><code>re_transformed_array_testY = encoder.inverse_transform(testY)

unique_elements, counts_elements = np.unique(re_transformed_array_testY, return_counts=True)
unique_elements_and_counts_testY = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)
unique_elements_and_counts_testY.columns = [&#39;unique_elements&#39;, &#39;count&#39;]

unique_elements_and_counts_testY</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p7.png" /></p>
<p>Of course, you can also use a for-loop:</p>
<pre class="r"><code>y_part = [trainY, valY, testY]

for y_part in y_part:
    re_transformed_array = encoder.inverse_transform(y_part)
    
    unique_elements, counts_elements = np.unique(re_transformed_array, return_counts=True)
    unique_elements_and_counts = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)
    unique_elements_and_counts.columns = [&#39;unique_elements&#39;, &#39;count&#39;]
    print(&#39;---------------&#39;)
    print(unique_elements_and_counts)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p8.png" /></p>
<p>To check if all categories are contained in all three variables (trainY, valY and testY) I first store the unique elements in lists and can then compare them with a logical query.</p>
<pre class="r"><code>list_trainY = unique_elements_and_counts_trainY[&#39;unique_elements&#39;].to_list()
list_valY = unique_elements_and_counts_valY[&#39;unique_elements&#39;].to_list()
list_testY = unique_elements_and_counts_testY[&#39;unique_elements&#39;].to_list()

print(list_trainY)
print(list_valY)
print(list_testY)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p9.png" /></p>
<pre class="r"><code>check_val =  all(item in list_valY for item in list_trainY)
 
if check_val is True:
    print(&#39;OK !&#39;)
    print(&quot;The list_valY contains all elements of the list_trainY.&quot;)    
else :
    print()
    print(&#39;No !&#39;)
    print(&quot;List_valY doesn&#39;t have all elements of the list_trainY.&quot;)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p10.png" /></p>
<pre class="r"><code>check_test =  all(item in list_testY for item in list_trainY)
 
if check_test is True:
    print(&#39;OK !&#39;)
    print(&quot;The list_testY contains all elements of the list_trainY.&quot;)    
else :
    print()
    print(&#39;No !&#39;)
    print(&quot;List_testY doesn&#39;t have all elements of the list_trainY.&quot;)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p11.png" /></p>
</div>
</div>
<div id="ann-for-multi-class-classfication" class="section level1">
<h1>5 ANN for Multi-Class Classfication</h1>
<div id="name-definitions" class="section level2">
<h2>5.1 Name Definitions</h2>
<pre class="r"><code>checkpoint_no = &#39;ckpt_1_ANN&#39;
model_name = &#39;Bird_ANN_2FC_F32_32_epoch_15&#39;</code></pre>
</div>
<div id="parameter-settings" class="section level2">
<h2>5.2 Parameter Settings</h2>
<pre class="r"><code>input_shape = trainX.shape[1]

n_batch_size = 20

n_steps_per_epoch = int(trainX.shape[0] / n_batch_size)
n_validation_steps = int(valX.shape[0] / n_batch_size)
n_test_steps = int(testX.shape[0] / n_batch_size)

n_epochs = 25

num_classes = trainY.shape[1]

print(&#39;Input Shape: &#39; + str(input_shape))
print(&#39;Batch Size: &#39; + str(n_batch_size))
print()
print(&#39;Steps per Epoch: &#39; + str(n_steps_per_epoch))
print()
print(&#39;Validation Steps: &#39; + str(n_validation_steps))
print(&#39;Test Steps: &#39; + str(n_test_steps))
print()
print(&#39;Number of Epochs: &#39; + str(n_epochs))
print()
print(&#39;Number of Classes: &#39; + str(num_classes))</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p12.png" /></p>
</div>
<div id="layer-structure" class="section level2">
<h2>5.3 Layer Structure</h2>
<p>Here I use the activation function ‘softmax’ in contrast to the <a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#layer-structure">binary classification</a>.</p>
<pre class="r"><code>model = models.Sequential()
model.add(layers.Dense(64, activation=&#39;relu&#39;, input_shape=(input_shape,)))
model.add(layers.Dense(64, activation=&#39;relu&#39;))
model.add(layers.Dense(num_classes, activation=&#39;softmax&#39;))</code></pre>
<pre class="r"><code>model.summary()</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p13.png" /></p>
</div>
<div id="configuring-the-model-for-training" class="section level2">
<h2>5.4 Configuring the model for training</h2>
<p>Again, the neural network for multi-class classification differs from that for <a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#configuring-the-model-for-training">binary classification</a>. Here the loss function ‘categorical_crossentropy’ is used.</p>
<pre class="r"><code>model.compile(loss=&#39;categorical_crossentropy&#39;,
              optimizer=&#39;adam&#39;,
              metrics=[&#39;accuracy&#39;])</code></pre>
</div>
<div id="callbacks" class="section level2">
<h2>5.5 Callbacks</h2>
<p>If you want to know more about callbacks you can read about it here at <a href="https://keras.io/api/callbacks/">Keras</a> or also in my post about <a href="https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/#callbacks">Convolutional Neural Networks</a>.</p>
<pre class="r"><code># Prepare a directory to store all the checkpoints.
checkpoint_dir = &#39;./&#39;+ checkpoint_no
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)</code></pre>
<pre class="r"><code>keras_callbacks = [ModelCheckpoint(filepath = checkpoint_dir + &#39;/&#39; + model_name, 
                                   monitor=&#39;val_loss&#39;, save_best_only=True, mode=&#39;auto&#39;)]</code></pre>
</div>
<div id="fitting-the-model" class="section level2">
<h2>5.6 Fitting the model</h2>
<pre class="r"><code>history = model.fit(trainX,
                    trainY,
                    steps_per_epoch=n_steps_per_epoch,
                    epochs=n_epochs,
                    batch_size=n_batch_size,
                    validation_data=(valX, valY),
                    validation_steps=n_validation_steps,
                    callbacks=[keras_callbacks])</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p14.png" /></p>
</div>
<div id="obtaining-the-best-model-values" class="section level2">
<h2>5.7 Obtaining the best model values</h2>
<pre class="r"><code>hist_df = pd.DataFrame(history.history)
hist_df[&#39;epoch&#39;] = hist_df.index + 1
cols = list(hist_df.columns)
cols = [cols[-1]] + cols[:-1]
hist_df = hist_df[cols]
hist_df.to_csv(checkpoint_no + &#39;/&#39; + &#39;history_df_&#39; + model_name + &#39;.csv&#39;)
hist_df.head()</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p15.png" /></p>
<pre class="r"><code>values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]
values_of_best_model</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p16.png" /></p>
</div>
<div id="obtaining-class-assignments" class="section level2">
<h2>5.8 Obtaining class assignments</h2>
<p>Similar to the <a href="https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/#obtaining-class-assignments-1">neural networks for computer vision</a>, I also save the class assignments for later reuse.</p>
<pre class="r"><code>class_assignment = dict(zip(y, encoded_Y))

df_temp = pd.DataFrame([class_assignment], columns=class_assignment.keys())
df_temp = df_temp.stack()
df_temp = pd.DataFrame(df_temp).reset_index().drop([&#39;level_0&#39;], axis=1)
df_temp.columns = [&#39;Category&#39;, &#39;Allocated Number&#39;]

df_temp.to_csv(checkpoint_no + &#39;/&#39; + &#39;class_assignment_df_&#39; + model_name + &#39;.csv&#39;)

print(&#39;Class assignment:&#39;)
class_assignment</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p17.png" /></p>
<p>The encoder used is also saved.</p>
<pre class="r"><code>pk.dump(encoder, open(checkpoint_no + &#39;/&#39; + &#39;encoder.pkl&#39;, &#39;wb&#39;))</code></pre>
</div>
<div id="validation" class="section level2">
<h2>5.9 Validation</h2>
<pre class="r"><code>acc = history.history[&#39;accuracy&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, &#39;bo&#39;, label=&#39;Training acc&#39;)
plt.plot(epochs, val_acc, &#39;b&#39;, label=&#39;Validation acc&#39;)
plt.title(&#39;Training and validation accuracy&#39;)
plt.legend()

plt.figure()

plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.legend()

plt.show()</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p18.png" /></p>
</div>
<div id="load-best-model" class="section level2">
<h2>5.10 Load best model</h2>
<p>Again, reference to the <a href="https://michael-fuchs-python.netlify.app/2021/01/08/computer-vision-convolutional-neural-network/#load-best-model">Computer Vision posts</a> where I explained why and how I cleaned up the Model Checkpoint folders.</p>
<pre class="r"><code># Loading the automatically saved model
model_reloaded = load_model(checkpoint_no + &#39;/&#39; + model_name)

# Saving the best model in the correct path and format
root_directory = os.getcwd()
checkpoint_dir = os.path.join(root_directory, checkpoint_no)
model_name_temp = os.path.join(checkpoint_dir, model_name + &#39;.h5&#39;)
model_reloaded.save(model_name_temp)

# Deletion of the automatically created folder under Model Checkpoint File.
folder_name_temp = os.path.join(checkpoint_dir, model_name)
shutil.rmtree(folder_name_temp, ignore_errors=True)</code></pre>
<pre class="r"><code>best_model = load_model(model_name_temp)</code></pre>
<p>The overall folder structure should look like this:</p>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113s1.png" /></p>
</div>
<div id="model-testing" class="section level2">
<h2>5.11 Model Testing</h2>
<pre class="r"><code>test_loss, test_acc = best_model.evaluate(testX,
                                          testY,
                                          steps=n_test_steps)
print()
print(&#39;Test Accuracy:&#39;, test_acc)</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p19.png" /></p>
</div>
<div id="predictions" class="section level2">
<h2>5.12 Predictions</h2>
<p>Now it’s time for some predictions.
Here I printed the first 5 results.</p>
<pre class="r"><code>y_pred = model.predict(testX)
y_pred[:5]</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p20.png" /></p>
<p>Now we need the previously saved encoder to recode the data.</p>
<pre class="r"><code>encoder_reload = pk.load(open(checkpoint_dir + &#39;\\&#39; + &#39;encoder.pkl&#39;,&#39;rb&#39;))</code></pre>
<pre class="r"><code>re_transformed_y_pred = encoder_reload.inverse_transform(y_pred)
re_transformed_y_pred[:5]</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p21.png" /></p>
<p>Now we can see which bird species was predicted.
If you want the result to be even more beautiful, you can add the predicted values to the testX part:</p>
<pre class="r"><code>testX[&#39;re_transformed_y_pred&#39;] = re_transformed_y_pred
testX</code></pre>
<p><img src="/post/2021-02-23-nn-artificial-neural-network-for-multi-class-classfication_files/p113p22.png" /></p>
</div>
</div>
<div id="prevent-overfitting" class="section level1">
<h1>6 Prevent Overfitting</h1>
<p>At this point I would like to remind you of the topic of overfitting. In my last post (<a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#prevent-overfitting">Artificial Neural Network for binary Classification</a>) I explained in more detail what can be done against overfitting. Here again a list with the corresponding links:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#reduce-the-networks-size">Reduce the network’s size</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#adding-weight-regularization">Adding weight regularization</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2021/02/16/nn-artificial-neural-network-for-binary-classification/#adding-dropout">Adding dropout</a></li>
</ul>
</div>
<div id="conclusion" class="section level1">
<h1>7 Conclusion</h1>
<p>Again, as a reminder which metrics should be stored additionally when using neural networks in real life:</p>
<ul>
<li>Mean values of the individual predictors in order to be able to compensate for missing values later on.</li>
<li>Further encoders for predictors, if categorical features are converted.</li>
<li>Scaler, if these are used.</li>
<li>If variables would have been excluded, a list with the final features should have been stored.</li>
</ul>
<p>For what reason I give these recommendations can be well read in my <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/">Data Science Post</a>. Here I have also created <a href="https://michael-fuchs-python.netlify.app/2020/08/21/the-data-science-process-crisp-dm/#data-science-best-practice-guidlines-for-ml-model-development">best practice guidelines</a> on how to proceed with model training.</p>
<p>I would like to add one limitation at this point. You may have noticed it already, but the dataset was heavily imbalanced. How to deal with such problems I have explained here: <a href="https://michael-fuchs-python.netlify.app/2020/01/16/dealing-with-imbalanced-classes/">Dealing with imbalanced classes</a></p>
<p><strong>References</strong></p>
<p>The content of the entire post was created using the following sources:</p>
<p>Chollet, F. (2018). Deep learning with Python (Vol. 361). New York: Manning.</p>
</div>
