---
title: ETL - Pipeline with join2
author: Michael Fuchs
date: '2020-11-26'
slug: etl-pipeline-with-join2
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#setup">2 Setup</a></li>
<li><a href="#etl-pipeline-with-join2">3 ETL Pipeline with join2</a>
<ul>
<li><a href="#extract">3.1 Extract</a></li>
<li><a href="#transform">3.2 Transform</a>
<ul>
<li><a href="#joining">3.2.1 Joining</a></li>
<li><a href="#pre-process-countries_metadata-for-joining">3.2.2 pre-process countries_metadata for joining</a></li>
<li><a href="#cleaning">3.2.3 Cleaning</a></li>
<li><a href="#add-further-calculations">3.2.4 Add further calculations</a></li>
</ul></li>
<li><a href="#load">3.3 Load</a></li>
</ul></li>
<li><a href="#create-etl_pipeline.py">4 Create etl_pipeline.py</a></li>
<li><a href="#test-etl_pipeline.py">5 Test etl_pipeline.py</a>
<ul>
<li><a href="#from-jupyter-notebook">5.1 from jupyter notebook</a></li>
<li><a href="#from-command-line">5.2 from command line</a></li>
</ul></li>
<li><a href="#conclusion">6 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Let us come to another variant of ETL. The <a href="https://michael-fuchs-python.netlify.app/2020/11/25/etl-pipeline-with-join/">“last time”</a> I prepared two data sets and then merged them.
Now I will again load two records, edit one of them to make a join possible, merge the records and edit them further.
Finally I want to save the final dataset.</p>
<p><strong>Overview of the ETL steps:</strong></p>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89s1.png" /></p>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89s2.png" /></p>
<p>At the end I will test the created ETL. I will show this from another jupyter notebook and a fully automatic call from the command line.</p>
<p>For this post I use two specially created sample data sets. A copy of them is stored in my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/ETL/Pipeline%20with%20join2">“GitHub Repo”</a>.</p>
</div>
<div id="setup" class="section level1">
<h1>2 Setup</h1>
<p>There is not much to add to the setup. In the two previous posts I have already explained it in detail.</p>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p1.png" /></p>
</div>
<div id="etl-pipeline-with-join2" class="section level1">
<h1>3 ETL Pipeline with join2</h1>
<pre class="r"><code>import pandas as pd</code></pre>
<div id="extract" class="section level2">
<h2>3.1 Extract</h2>
<pre class="r"><code>countries = pd.read_csv(&#39;../data/input/Countries.csv&#39;)
countries</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p2.png" /></p>
<pre class="r"><code>countries_metadata = pd.read_csv(&#39;../data/input/Countries_metadata.csv&#39;)
countries_metadata</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p3.png" /></p>
</div>
<div id="transform" class="section level2">
<h2>3.2 Transform</h2>
<div id="joining" class="section level3">
<h3>3.2.1 Joining</h3>
<pre class="r"><code>df = pd.merge(countries, countries_metadata, left_on=&#39;Countries&#39;, right_on=&#39;country_names&#39;, how=&#39;left&#39;)
df</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p4.png" /></p>
<p>As we can see, the problem here is that we do not have a uniform name for the countries.</p>
</div>
<div id="pre-process-countries_metadata-for-joining" class="section level3">
<h3>3.2.2 pre-process countries_metadata for joining</h3>
<pre class="r"><code>countries_metadata.country_names = countries_metadata.country_names.map(lambda x: x.split(&#39;.&#39;)[1])
countries_metadata</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p5.png" /></p>
<pre class="r"><code>df = pd.merge(countries, countries_metadata, left_on=&#39;Countries&#39;, right_on=&#39;country_names&#39;, how=&#39;left&#39;)
df</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p6.png" /></p>
</div>
<div id="cleaning" class="section level3">
<h3>3.2.3 Cleaning</h3>
<pre class="r"><code>df = df.drop([&#39;country_names&#39;], axis=1)
df</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p7.png" /></p>
</div>
<div id="add-further-calculations" class="section level3">
<h3>3.2.4 Add further calculations</h3>
<pre class="r"><code>df[&#39;pop_density&#39;] = df[&#39;Population&#39;]/df[&#39;Land_Area&#39;]
df.head()</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p8.png" /></p>
<pre class="r"><code>df[&#39;Population&#39;] = df[&#39;Population&#39;]/1000
df[&#39;Land_Area&#39;] = df[&#39;Land_Area&#39;]/1000

df.head()</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p9.png" /></p>
<pre class="r"><code>df = df.rename(columns={&#39;Population&#39;:&#39;Population_per_k&#39;, &#39;Land_Area&#39;:&#39;Land_Area_per_k&#39;})
df</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p10.png" /></p>
</div>
</div>
<div id="load" class="section level2">
<h2>3.3 Load</h2>
<pre class="r"><code>df.to_csv(&#39;../data/output/new_df.csv&#39;)</code></pre>
</div>
</div>
<div id="create-etl_pipeline.py" class="section level1">
<h1>4 Create etl_pipeline.py</h1>
<pre class="r"><code>import pandas as pd
import numpy as np
import os


class DataPreprocessor:
    def __init__(self, path_folder = &quot;path/to/data&quot;):

        self.path_folder = path_folder
        
        # Path to input
        self.path_input_folder = &quot;{}/input/&quot;.format(path_folder)
        self.path_input_countries = self.path_input_folder + &#39;Countries.csv&#39;
        self.path_input_countries_metadata = self.path_input_folder + &#39;Countries_metadata.csv&#39;

        # Path on which output tables are saved
        self.path_output_folder = &quot;{}/output/&quot;.format(path_folder)
        self.path_output_countries = self.path_output_folder + &#39;Countries.csv&#39;
        self.path_output_countries_metadata = self.path_output_folder + &#39;Countries_metadata.csv&#39;
        self.path_output_new_df = self.path_output_folder + &#39;new_df.csv&#39;

        # create dictionaries for read dtypes
        self.read_dtypes_countries = {&#39;Countries&#39;:&#39;category&#39;}
        self.read_dtypes_countries_metadata = {&#39;country_names&#39;:&#39;category&#39;}

        # create folders for output if not existent yet
        if not os.path.exists(self.path_output_folder):
            os.makedirs(self.path_output_folder) 

    def read_data_from_raw_input(self):

        print(&quot;Start:\tRead in countries Dataset&quot;)
        self.countries = pd.read_csv(self.path_input_countries, dtype=self.read_dtypes_countries)
        print(&quot;Finish:\tRead in countries Dataset&quot;)

        print(&quot;Start:\tRead in countries_metadata Dataset&quot;)       
        self.countries_metadata = pd.read_csv(self.path_input_countries_metadata, dtype=self.read_dtypes_countries_metadata)
        print(&quot;Finish:\tRead in countries_metadata Dataset&quot;)

    def preprocess_data(self, save_preprocess_countries=False, save_preprocess_countries_metadata=False, save_preprocess_new_df=True):

        print(&quot;Start:\tPreprocessing countries_metadata Dataset&quot;)
        self.preprocess_countries_metadata()
        print(&quot;Finish:\tPreprocessing countries_metadata Dataset&quot;)

        self.new_df = pd.merge(self.countries, self.countries_metadata, left_on=&#39;Countries&#39;, right_on=&#39;country_names&#39;, how=&#39;left&#39;)

        self.preprocess_new_df()

#        print(&quot;Start:\tPreprocessing countries Dataset&quot;)
#        self.preprocess_countries()
#        print(&quot;Finish:\tPreprocessing countries Dataset&quot;)

        if save_preprocess_countries:
            print(&quot;Start:\tSave countries Dataset to disc&quot;)
            self.countries.to_csv(self.path_output_countries, index=False)
            print(&quot;Finish:\tSave countries Dataset to disc&quot;)

        if save_preprocess_countries_metadata:
            print(&quot;Start:\tSave countries_metadata Dataset to disc&quot;)
            self.countries_metadata.to_csv(self.path_output_countries_metadata, index=False)
            print(&quot;Finish:\tSave countries_metadata Dataset to disc&quot;)

        if save_preprocess_new_df:
            print(&quot;Start:\tSave new_df Dataset to disc&quot;)
            self.new_df.to_csv(self.path_output_new_df, index=False)
            print(&quot;Finish:\tSave new_df Dataset to disc&quot;)

        return self.countries, self.countries_metadata, self.new_df

    def preprocess_countries_metadata(self):
        
        self.countries_metadata.country_names = self.countries_metadata.country_names.map(lambda x: x.split(&#39;.&#39;)[1])
        self.new_df[&#39;pop_density&#39;] = self.new_df[&#39;Population&#39;]/self.new_df[&#39;Land_Area&#39;]
        self.new_df[&#39;Population&#39;] = self.new_df[&#39;Population&#39;]/1000
        self.new_df[&#39;Land_Area&#39;] = self.new_df[&#39;Land_Area&#39;]/1000
        self.new_df = self.new_df.rename(columns={&#39;Population&#39;: &#39;Population_per_k&#39;, &#39;Land_Area&#39;: &#39;Land_Area_per_k&#39;})

    def preprocess_new_df(self):
        
        self.new_df = self.new_df.drop([&#39;country_names&#39;], axis=1)

        
    def read_preprocessed_tables(self):
        
        print(&quot;Start:\tRead in modified Dataset&quot;)
        self.new_df = pd.read_csv(self.path_output_new_df, dtype=self.read_dtypes_new_df)
        print(&quot;Finish:\tRead in modified Dataset&quot;)

        return self.new_df
             

def main():

    datapreprocesssor = DataPreprocessor()
    datapreprocesssor.read_data_from_raw_input()
    datapreprocesssor.preprocess_data()
    print(&#39;ETL has been successfully completed !!&#39;)

#if __name__ == &#39;__main__&#39;:
#    main()</code></pre>
<p>We have commented out the main from the ETL pipeline here. Of course you have to remove it in the .py file.</p>
<p>We have removed the part self.preprocess_countries(), because it is not used here. We continue to work with the new_df after the join. The option to save the loaded file countries.csv, in this case, as we have loaded it, remains, because you might want to have all relevant records in the output folder.</p>
<p>Unfortunately the view is not optimal. Therefore I recommend to copy the syntax into a .py file.
I prefer <a href="https://code.visualstudio.com/">“Visual Studio Code”</a> from Microsoft.
But I also put the file in my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets/ETL/Pipeline%20with%20join2">“GitHub Repo”</a> from where you can get it.</p>
</div>
<div id="test-etl_pipeline.py" class="section level1">
<h1>5 Test etl_pipeline.py</h1>
<p>Now we want to test our created ETL.</p>
<div id="from-jupyter-notebook" class="section level2">
<h2>5.1 from jupyter notebook</h2>
<p>First I want to test the ETL from a notebook. For this we create and start a <strong>new</strong> notebook in the notebooks-folder with the name ‘Test ETL Pipeline with join2.ipynb’.</p>
<pre class="r"><code>import sys

# Specifies the file path where the first .py file is located.
sys.path.insert(1, &#39;../data&#39;)
import etl_pipeline</code></pre>
<pre class="r"><code>datapreprocessor = etl_pipeline.DataPreprocessor()
datapreprocessor.read_data_from_raw_input()</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p11.png" /></p>
<pre class="r"><code>new_df = datapreprocessor.preprocess_data(save_preprocess_new_df=True)</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p12.png" /></p>
<pre class="r"><code>new_df = datapreprocessor.read_preprocessed_tables()</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p13.png" /></p>
<pre class="r"><code>new_df</code></pre>
<p><img src="/post/2020-11-26-etl-pipeline-with-join2_files/p89p14.png" /></p>
</div>
<div id="from-command-line" class="section level2">
<h2>5.2 from command line</h2>
<p>Because we have defined a main in the .py file we are able to call and execute the ETL from the command line.
It does not matter which command line this is exactly. You can use Anaconda Power Shell, Git Bash, the Windwos Comman Line or anything else.</p>
<p>Type only the following commands in your command prompt:</p>
<pre class="r"><code>cd &quot;path/to/your/data/folder&quot;
python etl_pipeline.py</code></pre>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>6 Conclusion</h1>
<p>In this kind of ETL I showed how to load and edit one or more data sets, then merge them, edit them further and finally save them.</p>
</div>
