---
title: Roadmap for Classification Tasks
author: Michael Fuchs
date: '2020-02-19'
slug: roadmap-for-classification-tasks
categories:
  - R
tags:
  - R Markdown
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#roadmap-for-classification-tasks">2 Roadmap for Classification Tasks</a>
<ul>
<li><a href="#data-pre-processing">2.1 Data pre-processing</a></li>
<li><a href="#feature-selection-methods">2.2 Feature Selection Methods</a></li>
<li><a href="#classification-algorithms">2.3 Classification Algorithms</a></li>
</ul></li>
<li><a href="#conclusion">3 Conclusion</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>Another big chapter from the supervised machine learning area comes to an end. In the past 4 months I wrote in detail about the functionality and use of the most common classification algorithms within data science.</p>
<p>Analogous to my post <a href="https://michael-fuchs-python.netlify.com/2019/10/14/roadmap-for-regression-analysis/">“Roadmap for Regression Analysis”</a>, I will give again an overview of the handling of classification tasks.</p>
</div>
<div id="roadmap-for-classification-tasks" class="section level1">
<h1>2 Roadmap for Classification Tasks</h1>
<div id="data-pre-processing" class="section level2">
<h2>2.1 Data pre-processing</h2>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p1.png" /></p>
<p>Here are the links to the individual topics:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/20/dealing-with-outliers/">Dealing with outliers</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/03/18/dealing-with-missing-values/">Handling Missing Values</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/06/16/types-of-encoder/">Feature Encoding</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/31/feature-scaling-with-scikit-learn/">Feature Scaling</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/16/dealing-with-imbalanced-classes/">Dealing with imbalanced classes</a></li>
</ul>
</div>
<div id="feature-selection-methods" class="section level2">
<h2>2.2 Feature Selection Methods</h2>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p2.png" /></p>
<p>Here are the links to the individual topics:</p>
<p>Filter methods:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/07/28/dealing-with-highly-correlated-features/">Dealing with highly correlated features</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/09/dealing-with-constant-and-duplicate-features/">Dealing with constant features</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/09/dealing-with-constant-and-duplicate-features/">Dealing with duplicate features</a></li>
</ul>
<p>Wrapper methods:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">SelectKBest</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Step Forward Feature Selection</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Backward Elimination</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Recursive Feature Elimination (RFE)</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Exhaustive Feature Selection</a></li>
</ul>
</div>
<div id="classification-algorithms" class="section level2">
<h2>2.3 Classification Algorithms</h2>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p3.png" /></p>
<p>Here are the links to the individual topics:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/10/31/introduction-to-logistic-regression/">Logistic Regression</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/08/introduction-to-support-vector-machines/">Support Vector Machines</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/14/introduction-to-perceptron-algorithm/">Perceptron</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/11/introduction-to-sgd-classifier/">SGD Classifier</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/13/ovo-and-ovr-classifier/">OvO and OvR Classifier</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/15/multinomial-logistic-regression/">Softmax Regression</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/30/introduction-to-decision-trees/">Decision Trees</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/12/15/introduction-to-naive-bayes-classifier/">Naive Bayes Classifier</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/12/27/introduction-to-knn-classifier/">K Nearest Neighbor Classifier</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/03/07/ensemble-modeling-bagging/">Bagging</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/03/26/ensemble-modeling-boosting/">Boosting</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/04/01/ensemble-modeling-xgboost/#xgboost-for-classification">XGBoost</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/04/24/ensemble-modeling-stacking/">Stacking</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/04/29/stacking-with-scikit-learn/">Stacking with scikit-learn</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/05/05/ensemble-modeling-voting//">Voting</a></li>
</ul>
<p><strong>Notes on the special classifiers:</strong></p>
<p>As described in the <a href="https://michael-fuchs-python.netlify.com/2019/11/11/introduction-to-sgd-classifier/">SGD Classifier</a> post, this is not a classifier. It’s a linear classifier optimized by the Stochastic Gradient Descent.</p>
<p>With the <a href="https://michael-fuchs-python.netlify.com/2019/11/13/ovo-and-ovr-classifier/">One-vs-One and One-vs-Rest</a> method it is possible to make binary classifiers multiple.</p>
<p><strong>Notes on ensemble methods:</strong></p>
<p>Depending on the underlying problem with the predictions I choose the following ensemble method:</p>
<ul>
<li>Bagging: Decrease Variance</li>
<li>Boosting: Decrease Bias</li>
<li>Stacking: Improve Predictions</li>
</ul>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>3 Conclusion</h1>
<p>The methods and algorithms shown in the overviews are described in detail in the respective publications with regard to theory and practical application. Just click on the respective link.</p>
</div>
