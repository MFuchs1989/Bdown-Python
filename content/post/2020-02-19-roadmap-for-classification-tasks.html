---
title: Roadmap for Classification Tasks
author: Michael Fuchs
date: '2020-02-19'
slug: roadmap-for-classification-tasks
categories:
  - R
tags:
  - R Markdown
---



<p>#Table of Content</p>
<ul>
<li>1 Introduction</li>
<li>2 Roadmap for Classification Tasks</li>
<li>2.1 Data pre-processing</li>
<li>2.2 Feature Selection Methods</li>
<li>2.3 Classification Algorithms</li>
<li>3 Conclusion</li>
</ul>
<p>#1 Introduction</p>
<p>Another big chapter from the supervised machine learning area comes to an end. In the past 4 months I wrote in detail about the functionality and use of the most common classification algorithms within data science.</p>
<p>Analogous to my post <a href="https://michael-fuchs-python.netlify.com/2019/10/14/roadmap-for-regression-analysis/">“Roadmap for Regression Analysis”</a>, I will give again an overview of the handling of classification tasks.</p>
<p>#2 Roadmap for Classification Tasks</p>
<p>#2.1 Data pre-processing</p>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p1.png" /></p>
<p>Here are the links to the individual topics:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/03/18/dealing-with-missing-values/">Handling Missing Values</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/20/dealing-with-outliers/">Dealing with outliers</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/06/16/types-of-encoder/">Feature Encoding</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/31/feature-scaling-with-scikit-learn/">Feature Scaling</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/16/dealing-with-imbalanced-classes/">Dealing with imbalanced classes</a></li>
</ul>
<p>#2.2 Feature Selection Methods</p>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p2.png" /></p>
<p>Here are the links to the individual topics:</p>
<p>Filter methods:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/07/28/dealing-with-highly-correlated-features/">Dealing with highly correlated features</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/09/dealing-with-constant-and-duplicate-features/">Dealing with constant features</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/08/09/dealing-with-constant-and-duplicate-features/">Dealing with duplicate features</a></li>
</ul>
<p>Wrapper methods:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">SelectKBest</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Step Forward Feature Selection</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Backward Elimination</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Recursive Feature Elimination (RFE)</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2020/01/31/feature-selection-methods-for-classification-tasks/">Exhaustive Feature Selection</a></li>
</ul>
<p>#2.3 Classification Algorithms</p>
<p><img src="/post/2020-02-19-roadmap-for-classification-tasks_files/p40p3.png" /></p>
<p>Here are the links to the individual topics:</p>
<ul>
<li><a href="https://michael-fuchs-python.netlify.com/2019/10/31/introduction-to-logistic-regression/">Logistic Regression</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/08/introduction-to-support-vector-machines/">Support Vector Machines</a></li>
<li><h2 id="perceptron"><a href="https://michael-fuchs-python.netlify.com/2019/11/14/introduction-to-perceptron-algorithm/">Perceptron</a></h2></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/11/introduction-to-sgd-classifier/">SGD Classifier</a></li>
<li><h2 id="ovo-and-ovr-classifier"><a href="https://michael-fuchs-python.netlify.com/2019/11/13/ovo-and-ovr-classifier/">OvO and OvR Classifier</a></h2></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/15/multinomial-logistic-regression/">Softmax Regression</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/11/30/introduction-to-decision-trees/">Decision Trees</a></li>
<li><a href="https://michael-fuchs-python.netlify.com/2019/12/15/introduction-to-naive-bayes-classifier/">Naive Bayes Classifier</a></li>
<li><h2 id="k-nearest-neighbor-classifier"><a href="https://michael-fuchs-python.netlify.com/2019/12/27/introduction-to-knn-classifier/">K Nearest Neighbor Classifier</a></h2></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/03/07/ensemble-modeling-bagging/">Bagging</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/03/26/ensemble-modeling-boosting/">Boosting</a></li>
<li><a href="https://michael-fuchs-python.netlify.app/2020/04/24/ensemble-modeling-stacking/">Stacking</a></li>
</ul>
<p><strong>Notes on the special classifiers:</strong></p>
<p>As described in the <a href="https://michael-fuchs-python.netlify.com/2019/11/11/introduction-to-sgd-classifier/">SGD Classifier</a> post, this is not a classifier. It’s a linear classifier optimized by the Stochastic Gradient Descent.</p>
<p>With the <a href="https://michael-fuchs-python.netlify.com/2019/11/13/ovo-and-ovr-classifier/">One-vs-One and One-vs-Rest</a> method it is possible to make binary classifiers multiple.</p>
<p>#3 Conclusion</p>
<p>The methods and algorithms shown in the overviews are described in detail in the respective publications with regard to theory and practical application. Just click on the respective link.</p>
