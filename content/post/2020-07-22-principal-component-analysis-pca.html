---
title: Principal Component Analysis (PCA)
author: Michael Fuchs
date: '2020-07-22'
slug: principal-component-analysis-pca
categories:
  - R
tags:
  - R Markdown
---



<div id="table-of-content" class="section level1">
<h1>Table of Content</h1>
<ul>
<li>1 Introduction</li>
<li>2 Loading the libraries</li>
<li>3 Introducing</li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>After the various methods of cluster analysis <a href="&#39;https://michael-fuchs-python.netlify.app/2020/07/14/roadmap-for-cluster-analysis/&#39;">‘Cluster Analysis’</a> have been presented in various publications, we now come to the second category in the area of unsupervised machine learning: Dimensionality Reduction</p>
<p>The areas of application of dimensionality reduction are widely spread within machine learning.
Here are some applications of Dimensionality Reduction:</p>
<ul>
<li>Pre-processing / Feature engineering</li>
<li>Noise reduction</li>
<li>Generating plausible artificial datasets</li>
<li>Financial modelling / risk analysis</li>
</ul>
<p>For this post the datasets <em>Auto-mpg</em> and <em>MNIST</em> from the statistic platform <a href="https://www.kaggle.com">“Kaggle”</a> were used. A copy of the records is available at <a href="https://drive.google.com/open?id=1C9SVQS7t_DBOwhgL_dq-joz8R5SssPVs" class="uri">https://drive.google.com/open?id=1C9SVQS7t_DBOwhgL_dq-joz8R5SssPVs</a> and <a href="https://drive.google.com/open?id=1Bfquk0uKnh6B3Yjh2N87qh0QcmLokrVk" class="uri">https://drive.google.com/open?id=1Bfquk0uKnh6B3Yjh2N87qh0QcmLokrVk</a>.</p>
</div>
<div id="loading-the-libraries" class="section level1">
<h1>2 Loading the libraries</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

from sklearn.decomposition import PCA</code></pre>
</div>
<div id="introducing" class="section level1">
<h1>3 Introducing</h1>
<p>PCA is a commonly used and very effective dimensionality reduction technique, which often forms a pre-processing stage for a number of machine learning models and techniques.</p>
<p>In a nutshell:
PCA reduces the sparsity in the dataset by separating the data into a series of components where each component represents a source of information within the data.</p>
<p>As its name suggests, the first principal component produced in PCA, comprises the majority of information or variance within the data. With each subsequent component, less information, but more subtlety, is contributed to the compressed data.</p>
<p>This post is intended to serve as an introduction to PCA in general.
In two further publications, the two main uses of the PCA:</p>
<ul>
<li>PCA for visualization</li>
<li>PCA for speed up machine learning algorithms</li>
</ul>
<p>are to be presented separately in detail.</p>
<p><img src="/post/2020-07-22-principal-component-analysis-pca_files/p55p.png" /></p>
<p><img src="/post/2020-07-22-principal-component-analysis-pca_files/p55p.png" /></p>
<p><img src="/post/2020-07-22-principal-component-analysis-pca_files/p55p.png" /></p>
</div>
