---
title: Data Wrangling
author: Michael Fuchs
date: '2019-03-03'
slug: data-wrangling
categories:
  - R
tags:
  - R Markdown
---


#Table of Content

+ 1 Introduction
+ 2 Loading the libraries and the data
+ 3 Overview of the data
+ 4 Get some statistics
+ 5 Select data
+ 5.1  Easy selection
+ 5.2 Conditional selection
+ 5.3 Set option
+ 6 Filter
+ 6.1 Normal filter
+ 6.2 Filter with a defined list
+ 7 Panda's query
+ 8 Group by
+ 8.1 with size
+ 8.2 with count
+ 8.2.1 Count Non - Zero Observations
+ 8.3 with sum
+ 8.4 with nunique
+ 8.5 with mean
+ 8.6 with agg.



#1 Introduction


Never stop learning !

The entry into the field of data science with ["R / R-Studio"](https://michael-fuchs.netlify.com/) was a smart matter. Now it's time and for each Data Scientist advisable to learn another scripting language.

Let's start with Python!


For this post the dataset *flight* from the statistic platform ["Kaggle"](https://www.kaggle.com) was used. A copy of the record is available at <https://drive.google.com/open?id=1w3c818UAJW4VVqwYmgDIsn-b8WqcZQzL>.


#2 Loading the libraries and the data



```{r, eval=F, echo=T}
import pandas as pd
```


```{r, eval=F, echo=T}
flight = pd.read_csv("path/to/file/flight.csv")
```



#3 Overview of the data

With the following commands it is possible to get a quick overview of his available data. 

```{r, eval=F, echo=T}
flight.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p1.png)

```{r, eval=F, echo=T}
flight.tail()
```

![](/post/2019-03-03-data-wrangling_files/p1p2.png)


```{r, eval=F, echo=T}
flight.shape
```

![](/post/2019-03-03-data-wrangling_files/p1p3.png)

```{r, eval=F, echo=T}
flight.columns
```

![](/post/2019-03-03-data-wrangling_files/p1p4.png)

```{r, eval=F, echo=T}
flight['Origin_Airport'].value_counts().head().T
```

![](/post/2019-03-03-data-wrangling_files/p1p5.png)

```{r, eval=F, echo=T}
flight.dtypes.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p6.png)

#4 Get some statistics


```{r, eval=F, echo=T}
flight.describe()
```

![](/post/2019-03-03-data-wrangling_files/p1p7.png)

```{r, eval=F, echo=T}
flight['Dep_Delay'].agg(['mean', 'median', 'std', 'min', 'max']).reset_index()
```

![](/post/2019-03-03-data-wrangling_files/p1p8.png)

```{r, eval=F, echo=T}
flight[['Origin_Airport', 'Departure_Time', 'Dep_Delay', 'Carrier_Delay']].groupby('Origin_Airport').mean().head()
```

![](/post/2019-03-03-data-wrangling_files/p1p9.png)


#5 Select data

#5.1  Easy selection

```{r, eval=F, echo=T}
flight[['Year']].head()
```

![](/post/2019-03-03-data-wrangling_files/p1p10.png)

```{r, eval=F, echo=T}
flight[['Year', 'WeatherDelay']].head()
```

![](/post/2019-03-03-data-wrangling_files/p1p11.png)


```{r, eval=F, echo=T}
flight[1:4]
```

![](/post/2019-03-03-data-wrangling_files/p1p12.png)


```{r, eval=F, echo=T}
flight.loc[1:4, ['Year', 'WeatherDelay', 'Flight_Date']]
```

![](/post/2019-03-03-data-wrangling_files/p1p13.png)

```{r, eval=F, echo=T}
flight.iloc[:,1:5].head()     #iloc = index
```

![](/post/2019-03-03-data-wrangling_files/p1p14.png)

```{r, eval=F, echo=T}
flight.iloc[1:4,[1,3,5]]
```

![](/post/2019-03-03-data-wrangling_files/p1p15.png)

#5.2 Conditional selection

Var.1 (here I see how many cases are affected)
```{r, eval=F, echo=T}
flight[(flight["Distance"] >= 3000)].shape[0]        
```

![](/post/2019-03-03-data-wrangling_files/p1p16.png)

Var.2 (here I see how many cases are affected)
```{r, eval=F, echo=T}
flight[flight.Distance >= 3000].shape[0]           
```

![](/post/2019-03-03-data-wrangling_files/p1p17.png)

Var. 1
```{r, eval=F, echo=T}
flight[(flight["Distance"] >= 3000) & (flight["DayOfWeek"] == 1) & (flight["Flight_Date"] == '11/07/2016')]    
```

![](/post/2019-03-03-data-wrangling_files/p1p18.png)

Var.2
```{r, eval=F, echo=T}
flight[(flight.Distance >= 3000) & (flight.DayOfWeek == 1) & (flight.Flight_Date == '11/07/2016')]    
```

![](/post/2019-03-03-data-wrangling_files/p1p19.png)


```{r, eval=F, echo=T}
flight[(flight.Origin_Airport == 'ATL') | (flight.Origin_Airport == 'BOS')]['Origin_Airport'].value_counts()
```

![](/post/2019-03-03-data-wrangling_files/p1p20.png)


```{r, eval=F, echo=T}
# slow method:
# flight[(flight.Origin_Airport == 'ATL') | (flight.Origin_Airport == 'BOS') | (flight.Origin_Airport == 'JFK')]

# fast method:
filter_list = ['ATL', 'BOS', 'JFK']
flight[flight.Origin_Airport.isin(filter_list)]['Origin_Airport'].value_counts()
```

![](/post/2019-03-03-data-wrangling_files/p1p21.png)


#5.3 Set option

With the set option function one can determine, how many lines and columns should be issued.

```{r, eval=F, echo=T}
flight.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p22.png)

```{r, eval=F, echo=T}
pd.set_option('display.max_rows', 2)
pd.set_option('display.max_columns', 2)
flight.head(200)
```

![](/post/2019-03-03-data-wrangling_files/p1p23.png)

#6 Filter

#6.1 Normal filter

Select columns containing 'Delay'
```{r, eval=F, echo=T}
flight.filter(like='Delay', axis=1).head()
```

![](/post/2019-03-03-data-wrangling_files/p1p.png)


#6.2 Filter with a defined list

Here we creat a list (top 4 airports with max. delay)
```{r, eval=F, echo=T}
df = (                              
    flight
    [['Origin_Airport', 'Dep_Delay']]
    .groupby(['Origin_Airport'])
    .sum()
    .sort_values(by='Dep_Delay', ascending=False)
    .reset_index()
    .head(4)
)

df
```

![](/post/2019-03-03-data-wrangling_files/p1p24.png)


Here we define and apply the defined list
```{r, eval=F, echo=T}
mylist = df['Origin_Airport'].tolist()
mylist
```

![](/post/2019-03-03-data-wrangling_files/p1p25.png)



```{r, eval=F, echo=T}
df = flight[(flight['Origin_Airport'].isin(mylist)) & (flight['DayOfWeek']>5)]       
df = df[['Origin_Airport', 'Distance']]
df = df.groupby(['Origin_Airport']).agg(['mean', 'median', 'std', 'min', 'max'])
df
```

![](/post/2019-03-03-data-wrangling_files/p1p26.png)

Now we have the sum of distance for the top 4 airports with max. delay


For a better view:
```{r, eval=F, echo=T}
df.columns = df.columns.droplevel()
df = df.reset_index()
df
```

![](/post/2019-03-03-data-wrangling_files/p1p27.png)


#7 Panda's query

Here are some expressions from the pandas *query function*


```{r, eval=F, echo=T}
flight.query("DayOfWeek > 4").head()
```

![](/post/2019-03-03-data-wrangling_files/p1p28.png)


```{r, eval=F, echo=T}
flight.query("DayOfWeek > 4  & Origin_Airport == 'BOS'").head()
```

![](/post/2019-03-03-data-wrangling_files/p1p29.png)


```{r, eval=F, echo=T}
df = flight.set_index(['DayOfWeek'])
df.query("index < Day").head()             
#Alternative: df.query("DayOfWeek < Day").head()
```

![](/post/2019-03-03-data-wrangling_files/p1p30.png)


```{r, eval=F, echo=T}
df.query("index < Day & index > 5").head()            
#Alternative: df.query("DayOfWeek < Day & DayOfWeek > 5").head()  
```

![](/post/2019-03-03-data-wrangling_files/p1p31.png)


```{r, eval=F, echo=T}
df = flight.set_index(['DayOfWeek', 'Origin_Airport'])
df.query('DayOfWeek == "6" &  Origin_Airport == "JFK"').head()
```

![](/post/2019-03-03-data-wrangling_files/p1p32.png)


```{r, eval=F, echo=T}
df[['Scheduled_Arrival', 'Arrival_Time', 'Arrival_Delay']].query("Scheduled_Arrival < Arrival_Time").head() 
```

![](/post/2019-03-03-data-wrangling_files/p1p33.png)


```{r, eval=F, echo=T}
df.query("Origin_Airport in ['JFK', 'DFW'] & Day in [1, 2, 4]").head()
```

![](/post/2019-03-03-data-wrangling_files/p1p34.png)


#8 Group by

```{r, eval=F, echo=T}
flight.groupby('Origin_Airport').size().head()
```

![](/post/2019-03-03-data-wrangling_files/p1p35.png)


```{r, eval=F, echo=T}
flight.groupby(['Origin_Airport','DayOfWeek']).size().head(17).T
```

![](/post/2019-03-03-data-wrangling_files/p1p36.png)


```{r, eval=F, echo=T}
flight.groupby(['Origin_Airport']).get_group('BOS').head()               
#add. Filter on 'BOS'
```

![](/post/2019-03-03-data-wrangling_files/p1p37.png)





##8.1 with size

```{r, eval=F, echo=T}
df = pd.DataFrame({"Person":
                   ["John", "Myla", "Lewis", "John", "Myla"],
                   "Age": [24., np.nan, 21., 33, 26],
                   "Single": [False, True, True, True, False]})
df 
```

![](/post/2019-03-03-data-wrangling_files/p1p38.png)


```{r, eval=F, echo=T}
df[['Single', 'Age']].groupby(['Single']).size()       
#the size function counts columns (including NAs !!) 
```

![](/post/2019-03-03-data-wrangling_files/p1p39.png)

##8.2 with count

```{r, eval=F, echo=T}
df[['Single', 'Age']].groupby(['Single']).count()     
#the count function counts columns (excluding NAs !!)
```

![](/post/2019-03-03-data-wrangling_files/p1p40.png)


###8.2.1 Count Non - Zero Observations

**Vertical count**

```{r, eval=F, echo=T}
df = pd.DataFrame({"Person":
                   ["Männlich", "Weiblich", "Männlich", "Männlich", "Weiblich", "Männlich", "Weiblich",                     "Männlich", "Weiblich", "Männlich", "Weiblich", "Männlich", "Weiblich"],
                    "Verspätung in Min.": [0, 0, 4., 0, 5, 1, 0, 0, 11, 5, 4, 0, 9]})
df.head(6)
```

![](/post/2019-03-03-data-wrangling_files/p1p41.png)

```{r, eval=F, echo=T}
df['Verspätet?'] = np.where(df['Verspätung in Min.'] > 0, 1, 0)
df[['Person', 'Verspätet?']].groupby(['Person']).sum()
```

![](/post/2019-03-03-data-wrangling_files/p1p42.png)



**Horizontal count**

```{r, eval=F, echo=T}
df = pd.DataFrame({"Person":
                   ["Person 1", "Person 2", "Person 3"],
                   "MZP1": 
                   [0, 2, 4],
                   "MZP2": 
                   [0, 3, 6],
                   "MZP3": 
                   [1, 7, 0]})
df.head() 
```

![](/post/2019-03-03-data-wrangling_files/p1p43.png)


```{r, eval=F, echo=T}
df2 = df[['MZP1', 'MZP2', 'MZP3']]
df2['Zwischensumme'] = df.astype(bool).sum(axis=1)
df2['Verspätungen'] = df2.Zwischensumme - 1
df2
```

![](/post/2019-03-03-data-wrangling_files/p1p44.png)

*astype(bool).sum(axis=1)* also counts the index (and categorical variables if any). Therefore *select* and *"Zwischensmme - 1"*



```{r, eval=F, echo=T}
df['Anzahl Verspätungen'] = df2.Verspätungen
df = df[['Person', 'Anzahl Verspätungen']].sort_values(by='Anzahl Verspätungen', ascending=False)
df
```

![](/post/2019-03-03-data-wrangling_files/p1p45.png)


##8.3 with sum

```{r, eval=F, echo=T}
df[['Single', 'Age']].groupby(['Single']).sum().reset_index() 
```

![](/post/2019-03-03-data-wrangling_files/p1p46.png)


##8.4 with nunique

```{r, eval=F, echo=T}
df.groupby(['Single']).nunique()       
#nunique counts characteristics within the respective sorting (without NAs)
```

![](/post/2019-03-03-data-wrangling_files/p1p47.png)


##8.5 with mean

```{r, eval=F, echo=T}
df[['Single', 'Age']].groupby(['Single']).mean().reset_index() 
```

![](/post/2019-03-03-data-wrangling_files/p1p48.png)


##8.6 with agg.

```{r, eval=F, echo=T}
df[['Single', 'Age']].groupby(['Single']).agg(['mean', 'median', 'std', 'min', 'max']).reset_index()
```

![](/post/2019-03-03-data-wrangling_files/p1p49.png)

```{r, eval=F, echo=T}
df_rank = flight.groupby('Origin_Airport')      #another way

df_descriptive = df_rank['Dep_Delay'].agg(['mean', 'median', 'std', 'min', 'max']).reset_index()


# Renaming Pandas Dataframe Columns
df_descriptive = df_descriptive.rename(columns={'Origin_Airport':'Origin Airport', 'mean':'Mean',                      'median':'Median', 'std':'Standard Deviation', 'min':'Minimum', 'max': 'Maximum'})

df_descriptive.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p50.png)













```{r, eval=F, echo=T}
hier zum tippen 
```

![](/post/2019-03-03-data-wrangling_files/p1p.png)



















