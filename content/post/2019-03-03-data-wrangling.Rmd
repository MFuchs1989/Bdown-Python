---
title: Data Wrangling
author: Michael Fuchs
date: '2019-03-03'
slug: data-wrangling
categories:
  - R
tags:
  - R Markdown
  
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

# 1 Introduction


Never stop learning !

The entry into the field of data science with ["R / R-Studio"](https://michael-fuchs.netlify.com/) was a smart matter. Now it's time and for each Data Scientist advisable to learn another scripting language.

Let's start with Python!


For this post the dataset *flight* from the statistic platform ["Kaggle"](https://www.kaggle.com) was used. You can download it from my [GitHub Repository](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets).



# 2 Loading the libraries and the data


```{r, eval=F, echo=T}
import pandas as pd
import numpy as np
```

```{r, eval=F, echo=T}
flight = pd.read_csv("flight.csv")
```


# 3 Overview of the data

With the following commands it is possible to get a quick overview of his available data. 


```{r, eval=F, echo=T}
flight.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p1.png)

```{r, eval=F, echo=T}
flight.tail()
```

![](/post/2019-03-03-data-wrangling_files/p1p2.png)

```{r, eval=F, echo=T}
flight.shape
```

![](/post/2019-03-03-data-wrangling_files/p1p3.png)

```{r, eval=F, echo=T}
flight.columns
```

![](/post/2019-03-03-data-wrangling_files/p1p4.png)


```{r, eval=F, echo=T}
flight['Origin_Airport'].value_counts().head().T
```

![](/post/2019-03-03-data-wrangling_files/p1p5.png)


```{r, eval=F, echo=T}
flight.dtypes.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p6.png)

We can also output the unique values of a column.

```{r, eval=F, echo=T}
#List unique values in the flight['Origin_Airport'] column
flight.Origin_Airport.unique()
```

![](/post/2019-03-03-data-wrangling_files/p1p7.png)

Now let's take a look at the unique values of several columns. For this purpose, I will select 4 categorical columns from the data set as an example:


```{r, eval=F, echo=T}
flight_subset = flight[['UniqueCarrier','Tai_lNum','Origin_Airport','Origin_City_Name']]
flight_subset
```

![](/post/2019-03-03-data-wrangling_files/p1p8.png)

Now I can use a for loop to display the number of contained labels:

```{r, eval=F, echo=T}
for feature in flight_subset.columns[:]:
    print(feature, ':', len(flight_subset[feature].unique()), 'labels')
```

![](/post/2019-03-03-data-wrangling_files/p1p9.png)

# 4 Get some statistics

```{r, eval=F, echo=T}
flight.describe()
```

![](/post/2019-03-03-data-wrangling_files/p1p10.png)



```{r, eval=F, echo=T}
flight['Dep_Delay'].agg(['mean', 'median', 'std', 'min', 'max']).reset_index()
```

![](/post/2019-03-03-data-wrangling_files/p1p11.png)


```{r, eval=F, echo=T}
flight[['Origin_Airport', 'Departure_Time', 'Dep_Delay', 'Carrier_Delay']].groupby('Origin_Airport').mean().head()
```

![](/post/2019-03-03-data-wrangling_files/p1p12.png)


# 5 Select data

## 5.1  Easy Selection


```{r, eval=F, echo=T}
flight[['Year']].head()
```

![](/post/2019-03-03-data-wrangling_files/p1p13.png)



```{r, eval=F, echo=T}
flight[['Year', 'WeatherDelay']].head()
```

![](/post/2019-03-03-data-wrangling_files/p1p14.png)



```{r, eval=F, echo=T}
# Select specific rows
flight[1:4]
```

![](/post/2019-03-03-data-wrangling_files/p1p15.png)


```{r, eval=F, echo=T}
# Select specific rows & columns
flight.loc[1:4, ['Year', 'WeatherDelay', 'Flight_Date']]
```

![](/post/2019-03-03-data-wrangling_files/p1p16.png)



```{r, eval=F, echo=T}
# Select all columns from Col_X to Col_Y
flight.loc[:,'Year':'DayOfWeek'].head()
```

![](/post/2019-03-03-data-wrangling_files/p1p17.png)


```{r, eval=F, echo=T}
# Select all columns from Col_X to Col_Y and Col_Z
flight.loc[:,'Year':'DayOfWeek'].join(flight.loc[:,'Tai_lNum']).head()
```

![](/post/2019-03-03-data-wrangling_files/p1p18.png)


```{r, eval=F, echo=T}
# Select all columns from Col_X to Col_Y and from Col_Z to Col_*
flight.loc[:,'Year':'DayOfWeek'].join(flight.loc[:,'Tai_lNum':'Origin_Airport']).head()
```

![](/post/2019-03-03-data-wrangling_files/p1p19.png)


## 5.2 Conditional Selection


```{r, eval=F, echo=T}
flight[(flight["Distance"] >= 3000) & (flight["DayOfWeek"] == 1) & (flight["Flight_Date"] == '11/07/2016')]
```

![](/post/2019-03-03-data-wrangling_files/p1p20.png)



```{r, eval=F, echo=T}
flight[(flight.Origin_Airport == 'ATL') | (flight.Origin_Airport == 'BOS')]['Origin_Airport']
```

![](/post/2019-03-03-data-wrangling_files/p1p21.png)



```{r, eval=F, echo=T}
# If you want to see how many cases are affected use Shape[0]

flight[(flight["Distance"] >= 3000)].shape[0] 
```

![](/post/2019-03-03-data-wrangling_files/p1p22.png)


## 5.3 Set option

With the set option function one can determine, how many lines and columns should be issued.


```{r, eval=F, echo=T}
flight.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p23.png)



```{r, eval=F, echo=T}
pd.set_option('display.max_rows', 2)
pd.set_option('display.max_columns', 2)
flight.head(200)
```

![](/post/2019-03-03-data-wrangling_files/p1p24.png)


```{r, eval=F, echo=T}
# Don't forget to reset the set options if they are no longer required.

pd.reset_option('all')
```



# 6 Dropping Values 

## 6.1 Dropping Columns



```{r, eval=F, echo=T}
df = pd.DataFrame({'Name': ['Anton', 'Moni', np.NaN, 'Renate', 'Justus'],
                   'Age': [32,22,62,np.NaN,18],
                   'Salary': [np.NaN, np.NaN,4500,2500,3800],
                   'Job': ['Student', np.NaN, 'Manager', 'Teacher', 'Student']})
df
```

![](/post/2019-03-03-data-wrangling_files/p1p25.png)


```{r, eval=F, echo=T}
reduced_df = df.drop(['Job'], axis=1)
reduced_df.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p26.png)



```{r, eval=F, echo=T}
reduced_df2 = df.drop(['Salary', 'Job'], axis=1)
reduced_df2.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p27.png)



```{r, eval=F, echo=T}
# You can also use a list to excluede columns
col_to_exclude = ['Salary', 'Job']

reduced_df_with_list = df.drop(col_to_exclude, axis=1)
reduced_df_with_list.head()
```

![](/post/2019-03-03-data-wrangling_files/p1p28.png)


## 6.2 Dropping NaN Values


```{r, eval=F, echo=T}
df
```

![](/post/2019-03-03-data-wrangling_files/p1p29.png)

```{r, eval=F, echo=T}
#Dropping all NaN values from column 'Name'
df.dropna(subset=['Name'])
```

![](/post/2019-03-03-data-wrangling_files/p1p30.png)


```{r, eval=F, echo=T}
#Dropping all NaN values from the columns 'Salary' and 'Job' if there is min. 1
df.dropna(subset=['Salary', 'Job'])
```

![](/post/2019-03-03-data-wrangling_files/p1p31.png)


## 6.3 NaN Values vs. Null Values

NaN values and zero values are not the same thing. 
This becomes clear from the examples below, so that you do not mistakenly follow a false assumption. 




```{r, eval=F, echo=T}
df_NaN_vs_Null = pd.DataFrame({'AIRLINE': ['AS', 'LH', 'KE'],
                               'VALUE': [1, 0, np.NAN]})
df_NaN_vs_Null
```

![](/post/2019-03-03-data-wrangling_files/p1p32.png)

```{r, eval=F, echo=T}
# The isna() function does its job well
df_NaN_vs_Null[df_NaN_vs_Null['VALUE'].isna()]
```

![](/post/2019-03-03-data-wrangling_files/p1p33.png)


```{r, eval=F, echo=T}
# The isnull() function also looks for NaN values not for NULL values!
df_NaN_vs_Null[df_NaN_vs_Null['VALUE'].isnull()]
```

![](/post/2019-03-03-data-wrangling_files/p1p34.png)


```{r, eval=F, echo=T}
# For Null values you have to select the respective column like this:
df_NaN_vs_Null[(df_NaN_vs_Null["VALUE"] == 0)]
```

![](/post/2019-03-03-data-wrangling_files/p1p35.png)


```{r, eval=F, echo=T}
# If you are looking for both (NaN and Null Values) use this method:
df_NaN_vs_Null[(df_NaN_vs_Null["VALUE"] == 0) | (df_NaN_vs_Null["VALUE"].isnull())]
```

![](/post/2019-03-03-data-wrangling_files/p1p36.png)


# 7 Filtering Values

Let's use this dummy dataset:


```{r, eval=F, echo=T}
df = pd.DataFrame({'Name': ['Maria', 'Marc', 'Julia', 'Mike', 'Sarah', 
                            'Sven', 'Mel', 'Alex', 'John', 'Marlene'],
                   'Favorite_Fruit': ['Banana', 'Apple', 'Melon', 'Peach', 'Grape', 
                                      'Melon', 'Orange', 'Banana', 'Melon', 'Apple']})
df
```

![](/post/2019-03-03-data-wrangling_files/p1p37.png)


## 7.1 Filter with Lists

```{r, eval=F, echo=T}
value_list = ["Apple", "Melon"]

boolean_value_list = df['Favorite_Fruit'].isin(value_list)
filtered_df = df[boolean_value_list]
filtered_df
```

![](/post/2019-03-03-data-wrangling_files/p1p38.png)


## 7.2 Exclude certain values


```{r, eval=F, echo=T}
value_list = ["Apple", "Melon"]

inverse_boolean_value_list = ~df.Favorite_Fruit.isin(value_list)
inverse_filtered_df = df[inverse_boolean_value_list]
inverse_filtered_df
```

![](/post/2019-03-03-data-wrangling_files/p1p39.png)



# 8 Working with Lists

## 8.1 Creation of Lists

```{r, eval=F, echo=T}
df
```

![](/post/2019-03-03-data-wrangling_files/p1p40.png)















```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)















```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)














```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)












```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)












```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)














```{r, eval=F, echo=T}

```

![](/post/2019-03-03-data-wrangling_files/p1p.png)




