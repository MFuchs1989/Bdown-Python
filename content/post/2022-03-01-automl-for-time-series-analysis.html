---
title: AutoML for Time Series Analysis
author: Michael Fuchs
date: '2022-03-01'
slug: automl-for-time-series-analysis
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">1 Introduction</a></li>
<li><a href="#import-the-libraries-and-the-functions">2 Import the Libraries and the Functions</a></li>
<li><a href="#import-the-data">3 Import the Data</a></li>
<li><a href="#autots">4 AutoTS</a>
<ul>
<li><a href="#compare-models">4.1 Compare Models</a></li>
<li><a href="#train-a-single-model">4.2 Train a single Model</a></li>
<li><a href="#compare-models-with-external-variables">4.3 Compare Models with external variables</a></li>
</ul></li>
<li><a href="#merlion">5 Merlion</a>
<ul>
<li><a href="#prepare-the-data">5.1 Prepare the Data</a></li>
<li><a href="#default-forecaster-model">5.2 Default Forecaster Model</a></li>
<li><a href="#multiple-models-ensembles">5.3 Multiple Models &amp; Ensembles</a>
<ul>
<li><a href="#model-config-training">5.3.1 Model Config &amp; Training</a></li>
<li><a href="#model-evaluation">5.3.2 Model Evaluation</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>There are automated machine learning libraries not only for <a href="https://michael-fuchs-python.netlify.app/2022/01/01/automl-using-pycaret-classification/">classification</a> or <a href="https://michael-fuchs-python.netlify.app/2022/01/15/automl-using-pycaret-regression/">regression</a> but also for time series prediction.</p>
<p>This is the topic of this post.</p>
<p>In this post I will introduce two packages that I find quite useful to find out which algorithm fits for my time series:</p>
<ul>
<li><a href="https://github.com/winedarksea/AutoTS">AutoTS</a></li>
<li><a href="https://github.com/salesforce/Merlion">Merlion</a></li>
</ul>
<p>Where the latter has less to do with automated machine learning but is fast and easy to use in terms of multiple models and ensembles.</p>
</div>
<div id="import-the-libraries-and-the-functions" class="section level1">
<h1>2 Import the Libraries and the Functions</h1>
<pre class="r"><code>import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
from sklearn import metrics

from statsmodels.tsa.stattools import adfuller
import ast

import warnings
warnings.filterwarnings(&quot;ignore&quot;)


# Libraries for AutoTS
from autots import AutoTS
from autots import model_forecast


# Libraries for Merlion
from merlion.utils import TimeSeries
from merlion.models.defaults import DefaultForecasterConfig, DefaultForecaster

from merlion.models.forecast.arima import Arima, ArimaConfig
from merlion.models.forecast.prophet import Prophet, ProphetConfig
from merlion.models.forecast.smoother import MSES, MSESConfig

from merlion.transform.base import Identity
from merlion.transform.resample import TemporalResample

from merlion.evaluate.forecast import ForecastMetric
from merlion.models.ensemble.combine import Mean, ModelSelector
from merlion.models.ensemble.forecast import ForecasterEnsemble, ForecasterEnsembleConfig</code></pre>
<pre class="r"><code>def mean_absolute_percentage_error_func(y_true, y_pred):
    &#39;&#39;&#39;
    Calculate the mean absolute percentage error as a metric for evaluation
    
    Args:
        y_true (float64): Y values for the dependent variable (test part), numpy array of floats 
        y_pred (float64): Predicted values for the dependen variable (test parrt), numpy array of floats
    
    Returns:
        Mean absolute percentage error 
    &#39;&#39;&#39;    
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100</code></pre>
<pre class="r"><code>def timeseries_evaluation_metrics_func(y_true, y_pred):
    &#39;&#39;&#39;
    Calculate the following evaluation metrics:
        - MSE
        - MAE
        - RMSE
        - MAPE
        - R²
    
    Args:
        y_true (float64): Y values for the dependent variable (test part), numpy array of floats 
        y_pred (float64): Predicted values for the dependen variable (test parrt), numpy array of floats
    
    Returns:
        MSE, MAE, RMSE, MAPE and R² 
    &#39;&#39;&#39;    
    print(&#39;Evaluation metric results: &#39;)
    print(f&#39;MSE is : {metrics.mean_squared_error(y_true, y_pred)}&#39;)
    print(f&#39;MAE is : {metrics.mean_absolute_error(y_true, y_pred)}&#39;)
    print(f&#39;RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}&#39;)
    print(f&#39;MAPE is : {mean_absolute_percentage_error_func(y_true, y_pred)}&#39;)
    print(f&#39;R2 is : {metrics.r2_score(y_true, y_pred)}&#39;,end=&#39;\n\n&#39;)</code></pre>
<pre class="r"><code>def Augmented_Dickey_Fuller_Test_func(timeseries , column_name):
    &#39;&#39;&#39;
    Calculates statistical values whether the available data are stationary or not 
    
    Args:
        series (float64): Values of the column for which stationarity is to be checked, numpy array of floats 
        column_name (str): Name of the column for which stationarity is to be checked
    
    Returns:
        p-value that indicates whether the data are stationary or not
    &#39;&#39;&#39; 
    print (f&#39;Results of Dickey-Fuller Test for column: {column_name}&#39;)
    adfTest = adfuller(timeseries, autolag=&#39;AIC&#39;)
    dfResults = pd.Series(adfTest[0:4], index=[&#39;ADF Test Statistic&#39;,&#39;P-Value&#39;,&#39;# Lags Used&#39;,&#39;# Observations Used&#39;])
    for key, value in adfTest[4].items():
       dfResults[&#39;Critical Value (%s)&#39;%key] = value
    print (dfResults)
    if adfTest[1] &lt;= 0.05:
        print()
        print(&quot;Conclusion:&quot;)
        print(&quot;Reject the null hypothesis&quot;)
        print(&#39;\033[92m&#39; + &quot;Data is stationary&quot; + &#39;\033[0m&#39;)
    else:
        print()
        print(&quot;Conclusion:&quot;)
        print(&quot;Fail to reject the null hypothesis&quot;)
        print(&#39;\033[91m&#39; + &quot;Data is non-stationary&quot; + &#39;\033[0m&#39;)</code></pre>
<pre class="r"><code>def inverse_diff_func(actual_df, pred_df):
    &#39;&#39;&#39;
    Transforms the differentiated values back
    
    Args:
        actual dataframe (float64): Values of the columns, numpy array of floats 
        predicted dataframe (float64): Values of the columns, numpy array of floats 
    
    Returns:
        Dataframe with the predicted values
    &#39;&#39;&#39;
    df_temp = pred_df.copy()
    columns = actual_df.columns
    for col in columns: 
        df_temp[str(col)+&#39;_inv_diff&#39;] = actual_df[col].iloc[-1] + df_temp[str(col)].cumsum()
    return df_temp</code></pre>
</div>
<div id="import-the-data" class="section level1">
<h1>3 Import the Data</h1>
<p>For this post the dataset FB from the statistic platform <a href="https://www.kaggle.com/">Kaggle</a> was used. You can download it from my <a href="https://github.com/MFuchs1989/Datasets-and-Miscellaneous/blob/main/datasets/Time%20Series%20Analysis/FB.csv">GitHub Repository</a>.</p>
<pre class="r"><code>df = pd.read_csv(&#39;FB.csv&#39;)
df = df[[&#39;Date&#39;, &#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;]]
df.index = pd.to_datetime(df.Date)
df = df.drop(&#39;Date&#39;, axis=1)
df.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p1.png" /></p>
<pre class="r"><code>X = df[[&#39;Close&#39;]]

trainX = X.iloc[:-30]
testX = X.iloc[-30:]</code></pre>
</div>
<div id="autots" class="section level1">
<h1>4 AutoTS</h1>
<p>With AutoTS you have the possibility to test all kinds of ML algorithms that are suitable for analyzing and predicting time series.</p>
<p>Here is the corresponding <a href="https://github.com/winedarksea/AutoTS">GitHub repository</a></p>
<p>You can find the exact documentation here: <a href="https://winedarksea.github.io/AutoTS/build/html/source/intro.html#">AutoTS</a></p>
<div id="compare-models" class="section level2">
<h2>4.1 Compare Models</h2>
<pre class="r"><code>model = AutoTS(
    forecast_length=30,
    frequency=&#39;d&#39;, #for daily
    prediction_interval=0.9,
    model_list=&#39;all&#39;, 
    transformer_list=&#39;all&#39;,
    max_generations=7,
    num_validations=3,
    validation_method=&#39;similarity&#39;,
    n_jobs=-1)</code></pre>
<p>For the parameter model_list there are some settings that can be made:</p>
<ul>
<li>defined list of algorithms e.g. [‘GSL’, ‘LastValueNaive’ …]</li>
<li>‘superfast’</li>
<li>‘fast’</li>
<li>‘fast_parallel’</li>
<li>‘all’</li>
<li>‘default’</li>
<li>‘probabilistic’</li>
<li>‘multivariate’</li>
</ul>
<p>For a detailed description of the parameters, please read the <a href="https://winedarksea.github.io/AutoTS/build/html/source/autots.html">documentation</a>.</p>
<pre class="r"><code>model = model.fit(trainX)</code></pre>
<p>Let’s display the model parameters:</p>
<pre class="r"><code>best_model_Name = model.best_model_name
best_model_Parameters = model.best_model_params
best_model_TransformationParameters = model.best_model_transformation_params

print(&#39;Best model:&#39;)
print(best_model_Name)
print()
print(&#39;Model parameter of best model:&#39;)
print(best_model_Parameters)
print()
print(&#39;Transformation parameter of best model:&#39;)
print(best_model_TransformationParameters)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p2.png" /></p>
<p>Now it is time to do the prediction and validation:</p>
<pre class="r"><code>prediction = model.predict()
prediction</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p3.png" /></p>
<pre class="r"><code>prediction.plot(model.df_wide_numeric,
                series=model.df_wide_numeric.columns[0],
                start_date=&quot;2019-01-01&quot;)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p4.png" /></p>
<p>If you wonder why there are gaps in this chart, it is because the stock price is only documented from Monday to Friday. The weekend or holidays are not considered in the data set.</p>
<p>But that doesn’t matter, we can also display the chart again more nicely. But first let’s have a look at the validation metrics:</p>
<pre class="r"><code>forecasts_df = prediction.forecast
forecasts_up, forecasts_low = prediction.upper_forecast, prediction.lower_forecast</code></pre>
<pre class="r"><code>timeseries_evaluation_metrics_func(testX, forecasts_df)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p5.png" /></p>
<pre class="r"><code>plt.rcParams[&quot;figure.figsize&quot;] = [15,7]
plt.plot(trainX, label=&#39;Train &#39;)
plt.plot(testX, label=&#39;Test &#39;)
plt.plot(forecasts_df, label=&#39;Predicted &#39;)
plt.plot(forecasts_up, label=&#39;Confidence Interval Upper bound &#39;)
plt.plot(forecasts_low, label=&#39;Confidence Interval Lower bound &#39;)
plt.legend(loc=&#39;best&#39;)
plt.show()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p6.png" /></p>
<p>With the following command we get all calculated models including their parameters and achieved score:</p>
<pre class="r"><code>model_results = model.results()
model_results</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p7.png" /></p>
</div>
<div id="train-a-single-model" class="section level2">
<h2>4.2 Train a single Model</h2>
<p>Of course, you also have the possibility to train certain models specifically. Since FBProphet seems to be the best model for the data set at hand, I would like to use this algorithm specifically.</p>
<p>If you want to use another specific algorithm is here a list of models available in AutoTS: <a href="https://winedarksea.github.io/AutoTS/build/html/source/tutorial.html#models-1">Models in AutoTS</a></p>
<p>Here again the parameters that led to the best result for FBProphet:</p>
<pre class="r"><code>print(&#39;Best model:&#39;)
print(best_model_Name)
print()
print(&#39;Model parameter of best model:&#39;)
print(best_model_Parameters)
print()
print(&#39;Transformation parameter of best model:&#39;)
print(best_model_TransformationParameters)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p8.png" /></p>
<p>I could now enter the parameters as follows:</p>
<pre class="r"><code>FBProphet_model = model_forecast(
    model_name=&quot;FBProphet&quot;,
    model_param_dict={&#39;holiday&#39;: True, &#39;regression_type&#39;: None, &#39;growth&#39;: &#39;linear&#39;, 
                      &#39;n_changepoints&#39;: 25, &#39;changepoint_prior_scale&#39;: 30, 
                      &#39;seasonality_mode&#39;: &#39;additive&#39;, &#39;changepoint_range&#39;: 0.8, 
                      &#39;seasonality_prior_scale&#39;: 40, &#39;holidays_prior_scale&#39;: 10.0},
    model_transform_dict={
        &#39;fillna&#39;: &#39;ffill_mean_biased&#39;,
        &#39;transformations&#39;: {&#39;0&#39;: &#39;SeasonalDifference&#39;, 
                            &#39;1&#39;: &#39;Round&#39;},
        &#39;transformation_params&#39;: {&#39;0&#39;: {&#39;lag_1&#39;: 52, &#39;method&#39;: &#39;Median&#39;}, 
                                  &#39;1&#39;: {&#39;decimals&#39;: 1, &#39;on_transform&#39;: True, &#39;on_inverse&#39;: False}}},
    df_train=trainX,
    forecast_length=30)</code></pre>
<p>But after I am too lazy to transcribe everything I can also use the saved metrics from the best model of AutoTS. I just have to format them as a dictionary.</p>
<pre class="r"><code>best_model_Parameters_dic = ast.literal_eval(str(best_model_Parameters))
best_model_TransformationParameters_dic = ast.literal_eval(str(best_model_TransformationParameters))</code></pre>
<pre class="r"><code>LastValueNaive_model = model_forecast(
    model_name = best_model_Name,
    model_param_dict = best_model_Parameters_dic,
    model_transform_dict = best_model_TransformationParameters_dic,
    df_train = trainX,
    forecast_length=30)</code></pre>
<pre class="r"><code>forecasts_df_LastValueNaive_model = LastValueNaive_model.forecast
forecasts_df_LastValueNaive_model.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p9.png" /></p>
<pre class="r"><code>timeseries_evaluation_metrics_func(testX, forecasts_df_LastValueNaive_model)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p10.png" /></p>
<p>OK why is this result now again better than the one achieved before with FBProphet? This has to do with the fact that we had used cross vailidation (n=3) before.</p>
<p>Let’s display the results:</p>
<pre class="r"><code>plt.rcParams[&quot;figure.figsize&quot;] = [15,7]
plt.plot(trainX, label=&#39;Train &#39;)
plt.plot(testX, label=&#39;Test &#39;)
plt.plot(forecasts_df_LastValueNaive_model, label=&#39;Predicted &#39;)
plt.legend(loc=&#39;best&#39;)
plt.show()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p11.png" /></p>
<p>Looks better already.</p>
</div>
<div id="compare-models-with-external-variables" class="section level2">
<h2>4.3 Compare Models with external variables</h2>
<p>Now, the fact is that time series can be affected by other variables. We can also take this into account in our machine learning algorithms.</p>
<p>Let’s look at the following variables to finally predict ‘Close’:</p>
<pre class="r"><code>df.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p12.png" /></p>
<pre class="r"><code>trainX_multi = df.iloc[:-30]
testX_multi = df.iloc[-30:]</code></pre>
<p>We can have the values for all variables predicted with a higher weight for the target variable (‘Close’).</p>
<pre class="r"><code>model_ext_var = AutoTS(
    forecast_length=30,
    frequency=&#39;d&#39;,
    prediction_interval=0.9,
    model_list=&#39;all&#39;,
    transformer_list=&quot;all&quot;,
    max_generations=7,
    num_validations=3,
    models_to_validate=0.2,
    validation_method=&quot;similarity&quot;,
    n_jobs=-1)</code></pre>
<pre class="r"><code>weights_close = {&#39;Close&#39;: 20}

model_ext_var = model_ext_var.fit(trainX_multi,
                                  weights=weights_close)</code></pre>
<p>This time it is an ensemble that gives the best result:</p>
<pre class="r"><code>best_model_ext_var_Name = model_ext_var.best_model_name
best_model_ext_var_Parameters = model_ext_var.best_model_params
best_model_ext_var_TransformationParameters = model_ext_var.best_model_transformation_params

print(&#39;Best model:&#39;)
print(best_model_ext_var_Name)
print()
print(&#39;Model parameter of best model:&#39;)
print(best_model_ext_var_Parameters)
print()
print(&#39;Transformation parameter of best model:&#39;)
print(best_model_ext_var_TransformationParameters)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p13.png" /></p>
<p>Let’s do the validation:</p>
<pre class="r"><code>prediction_ext_var = model_ext_var.predict()
forecasts_df_ext_var = prediction_ext_var.forecast
forecasts_up_ext_var, forecasts_low_ext_var = prediction_ext_var.upper_forecast, prediction_ext_var.lower_forecast</code></pre>
<pre class="r"><code>for i in [&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39; ]:
    print(f&#39;Evaluation metric for {i}&#39;)
    timeseries_evaluation_metrics_func(testX_multi[str(i)] , forecasts_df_ext_var[str(i)])</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p14.png" /></p>
<pre class="r"><code>for i in [&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39; ]:
    
    plt.rcParams[&quot;figure.figsize&quot;] = [10,7]
    plt.plot(trainX_multi[str(i)], label=&#39;Train &#39;+str(i))
    plt.plot(testX_multi[str(i)], label=&#39;Test &#39;+str(i))
    plt.plot(forecasts_df_ext_var[str(i)], label=&#39;Predicted &#39;+str(i))
    plt.legend(loc=&#39;best&#39;)
    plt.show()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p15.png" /></p>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p16.png" /></p>
<p>As you can see, with AutoTS you can quickly and easily get a first insight into which algorithm fits best to the dataset at hand.</p>
</div>
</div>
<div id="merlion" class="section level1">
<h1>5 Merlion</h1>
<p>As mentioned at the beginning, I find <a href="https://github.com/salesforce/Merlion">Merlion</a> quite handy for specifically testing promising algorithms for their performance to see if they fit our time series.</p>
<div id="prepare-the-data" class="section level2">
<h2>5.1 Prepare the Data</h2>
<pre class="r"><code>df.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p17.png" /></p>
<pre class="r"><code>Augmented_Dickey_Fuller_Test_func(df[&#39;Close&#39; ],&#39;Close&#39;)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p18.png" /></p>
<pre class="r"><code>train_diff = trainX.diff()
train_diff.dropna(inplace = True)</code></pre>
<pre class="r"><code>Augmented_Dickey_Fuller_Test_func(train_diff[&#39;Close&#39; ],&#39;Close&#39;)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p19.png" /></p>
<p>This time we differentiate our time series:</p>
<pre class="r"><code>train_data = TimeSeries.from_pd(train_diff)
test_data = TimeSeries.from_pd(testX)</code></pre>
</div>
<div id="default-forecaster-model" class="section level2">
<h2>5.2 Default Forecaster Model</h2>
<pre class="r"><code>merlion_default_model = DefaultForecaster(DefaultForecasterConfig())
merlion_default_model.train(train_data=train_data)
forecast_default_model, test_err = merlion_default_model.forecast(time_stamps=test_data.time_stamps)</code></pre>
<p>Admittedly, the output of the forecast is not as easy to continue using as I would like. However, we can easily transform it into a usable format:</p>
<pre class="r"><code>forecast_default_model_df = pd.DataFrame(forecast_default_model).reset_index()
forecast_default_model_df.columns = [&#39;index&#39;, &#39;ts&#39;, &#39;Value&#39;]
forecast_default_model_df[&#39;Value&#39;] = forecast_default_model_df[&#39;Value&#39;].astype(str)
forecast_default_model_df[&#39;Value&#39;] = forecast_default_model_df[&#39;Value&#39;].str.replace(&#39;,&#39;, &#39;&#39;)
forecast_default_model_df[&#39;Value&#39;] = forecast_default_model_df[&#39;Value&#39;].str.replace(&#39;(&#39;, &#39;&#39;)
forecast_default_model_df[&#39;Value&#39;] = forecast_default_model_df[&#39;Value&#39;].str.replace(&#39;)&#39;, &#39;&#39;)
forecast_default_model_df[&#39;Value&#39;] = forecast_default_model_df[&#39;Value&#39;].astype(float)

# Assign correct index to dataframe
forecast_default_model_df = forecast_default_model_df.drop([&#39;ts&#39;,&#39;index&#39;], axis=1)
forecast_default_model_df.index = testX.index

# Rename the column accordingly
forecast_default_model_df.columns = [&#39;Close&#39;]


forecast_default_model_df.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p20.png" /></p>
<p>Now let’s do the inverse transformation so that the predicted values become useful.</p>
<pre class="r"><code>forecast_default_model_df = inverse_diff_func(trainX, forecast_default_model_df)
forecast_default_model_df.head()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p21.png" /></p>
<pre class="r"><code>timeseries_evaluation_metrics_func(testX, forecast_default_model_df[&#39;Close_inv_diff&#39;])</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p22.png" /></p>
<pre class="r"><code>plt.rcParams[&quot;figure.figsize&quot;] = [15,7]
plt.plot(trainX, label=&#39;Train &#39;)
plt.plot(testX, label=&#39;Test &#39;)
plt.plot(forecast_default_model_df[&#39;Close_inv_diff&#39;], label=&#39;Predicted &#39;)

plt.legend(loc=&#39;best&#39;)
plt.show()</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p23.png" /></p>
<p>Mhhh still not the best result. Let’s see if we can improve that again.</p>
</div>
<div id="multiple-models-ensembles" class="section level2">
<h2>5.3 Multiple Models &amp; Ensembles</h2>
<div id="model-config-training" class="section level3">
<h3>5.3.1 Model Config &amp; Training</h3>
<p>Now I am going to train multiple models as well as ensembles:</p>
<pre class="r"><code>merlion_arima_model_config = ArimaConfig(max_forecast_steps=100, order=(1, 1, 1),
                                         transform=TemporalResample(granularity=&quot;D&quot;))

merlion_arima_model  = Arima(merlion_arima_model_config)</code></pre>
<pre class="r"><code>merlion_prophet_model_config = ProphetConfig(max_forecast_steps=100, transform=Identity())

merlion_prophet_model  = Prophet(merlion_prophet_model_config)</code></pre>
<pre class="r"><code>merlion_mses_model_config = MSESConfig(max_forecast_steps=100, max_backstep=80,
                                       transform=TemporalResample(granularity=&quot;D&quot;))

merlion_mses_model  = MSES(merlion_mses_model_config)</code></pre>
<pre class="r"><code>merlion_ensemble_model_config = ForecasterEnsembleConfig(combiner=Mean(), 
                                                         models=[merlion_arima_model, 
                                                                 merlion_prophet_model, 
                                                                 merlion_mses_model])

merlion_ensemble_model  = ForecasterEnsemble(config=merlion_ensemble_model_config)</code></pre>
<pre class="r"><code>merlion_selector_model_config = ForecasterEnsembleConfig(combiner=ModelSelector(metric=ForecastMetric.sMAPE))

merlion_selector_model = ForecasterEnsemble(config=merlion_selector_model_config, 
                                            models=[merlion_arima_model, 
                                                    merlion_prophet_model, 
                                                    merlion_mses_model])</code></pre>
<pre class="r"><code>print(f&quot;Training {type(merlion_arima_model).__name__}:&quot;)
merlion_arima_model.train(train_data)

print(f&quot;\nTraining {type(merlion_prophet_model).__name__}:&quot;)
merlion_prophet_model.train(train_data=train_data)

print(f&quot;\nTraining {type(merlion_mses_model).__name__}:&quot;)
merlion_mses_model.train(train_data=train_data)

print(&quot;\nTraining ensemble model:&quot;)
merlion_ensemble_model.train(train_data=train_data)

print(&quot;\nTraining model selector:&quot;)
merlion_selector_model.train(train_data=train_data)

print()
print(&quot;Model training finished!!&quot;)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p24.png" /></p>
<pre class="r"><code>print(f&quot;Forecasting {type(merlion_arima_model).__name__}...&quot;)
forecast_merlion_arima_model, test_err1 = merlion_arima_model.forecast(time_stamps=test_data.time_stamps)

print(f&quot;\nForecasting {type(merlion_prophet_model).__name__}...&quot;)
forecast_merlion_prophet_model, test_err2 = merlion_prophet_model.forecast(time_stamps=test_data.time_stamps)

print(f&quot;\nForecasting {type(merlion_mses_model).__name__}...&quot;)
forecast_merlion_mses_model, test_err3 = merlion_mses_model.forecast(time_stamps=test_data.time_stamps, 
                                                         time_series_prev=train_data)

print(&quot;\nForecasting ensemble model...&quot;)
forecast_merlion_ensemble_model, test_err_e = merlion_ensemble_model.forecast(time_stamps=test_data.time_stamps)

print(&quot;\nForecasting model selector...&quot;)
forecast_merlion_selector_model, test_err_s = merlion_selector_model.forecast(time_stamps=test_data.time_stamps, 
                                                                              time_series_prev=train_data)

print()
print()
print(&quot;Forecasting finished!!&quot;)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p25.png" /></p>
</div>
<div id="model-evaluation" class="section level3">
<h3>5.3.2 Model Evaluation</h3>
<p>Since I don’t feel like doing the same processing steps over and over for each result, I wrote a simple function that does it for me:</p>
<pre class="r"><code>def merlion_forecast_processing_func(x):
    &#39;&#39;&#39;
    This function is adapted to the Facebook dataframe !!  
    Brings the forecast of the Merlion models into a readable format
    
    Args:
        x (df): Y values for the dependent variable (test part), dataframe
    
    Returns:
        Processed dataframe
    &#39;&#39;&#39;   
    x = pd.DataFrame(x).reset_index()
    x.columns = [&#39;index&#39;, &#39;ts&#39;, &#39;Value&#39;]
    x[&#39;Value&#39;] = x[&#39;Value&#39;].astype(str)
    x[&#39;Value&#39;] = x[&#39;Value&#39;].str.replace(&#39;,&#39;, &#39;&#39;)
    x[&#39;Value&#39;] = x[&#39;Value&#39;].str.replace(&#39;(&#39;, &#39;&#39;)
    x[&#39;Value&#39;] = x[&#39;Value&#39;].str.replace(&#39;)&#39;, &#39;&#39;)
    x[&#39;Value&#39;] = x[&#39;Value&#39;].astype(float)
    # Assign correct index to dataframe
    x = x.drop([&#39;ts&#39;, &#39;index&#39;], axis=1)
    x.index = testX.index
    # Rename the column accordingly
    x.columns = [&#39;Close&#39;]
    # Apply inverse_diff function
    x = inverse_diff_func(trainX, x)
    return x</code></pre>
<pre class="r"><code>forecast_merlion_arima_model_df = merlion_forecast_processing_func(forecast_merlion_arima_model)
forecast_merlion_prophet_model_df = merlion_forecast_processing_func(forecast_merlion_prophet_model)
forecast_merlion_mses_model_df = merlion_forecast_processing_func(forecast_merlion_mses_model)
forecast_merlion_ensemble_model_df = merlion_forecast_processing_func(forecast_merlion_ensemble_model)
forecast_merlion_selector_model_df = merlion_forecast_processing_func(forecast_merlion_selector_model)</code></pre>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p.png" /></p>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p.png" /></p>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p.png" /></p>
<p><img src="/post/2022-03-01-automl-for-time-series-analysis_files/p137p.png" /></p>
</div>
</div>
</div>
