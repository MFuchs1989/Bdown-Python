<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.46" />


<title>Introduction to Logistic Regression - Michael Fuchs Python</title>
<meta property="og:title" content="Introduction to Logistic Regression - Michael Fuchs Python">



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/MFuchs.png"
         width="50"
         height="50"
         alt="MFuchs">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/MFuchs1989/Bdown-Python">GitHub</a></li>
    
    <li><a href="https://www.linkedin.com/in/michael-fuchs-139172131/">LinkedIn</a></li>
    
    <li><a href="https://twitter.com/Stat_Michael">Twitter</a></li>
    
    <li><a href="https://www.xing.com/profile/Michael_Fuchs426/cv?sc_o=mxb_p">XING</a></li>
    
    <li><a href="https://michael-fuchs.netlify.com/">zum R-Blog</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Introduction to Logistic Regression</h1>

    
    <span class="article-date">2019-10-31</span>
    

    <div class="article-content">
      <div id="table-of-content" class="section level1">
<h1>Table of Content</h1>
<ul>
<li>1 Introduction</li>
<li>2 Loading the libraries and the data</li>
<li>3 Descriptive statistics</li>
<li>3.1 Mean values of the features</li>
<li>3.2 Description of the target variable</li>
<li>3.3 Description of the predictor variables</li>
<li>4 Data pre-processing</li>
<li>4.1 Conversion of the target variable</li>
<li>4.2 Creation of dummy variables</li>
<li>4.3 Feature Selection</li>
<li>5 Logistic Regression with the statsmodel library</li>
<li>6 Logistic Regression with scikit-learn</li>
<li>6.1 Over-sampling using SMOTE</li>
<li>6.2 Model Fitting</li>
<li>6.3 Model evaluation</li>
<li>6.3.1 Confusion matrix</li>
<li>6.3.2 Further metrics</li>
<li>6.3.3 ROC / AUC</li>
<li>6.3.4 Cross Validation</li>
<li>7 Conclusion</li>
<li>8 Description of the dataframe</li>
</ul>
</div>
<div id="introduction" class="section level1">
<h1>1 Introduction</h1>
<p>My previous posts were mostly about treating regression problems. Now we’ll change from regression to classification. Let’s start with the introduction of a binary classification algorithm: <strong>Logistic Regression</strong></p>
<p>For this post the dataset <em>Bank Data</em> from the platform <a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">“UCI Machine Learning repository”</a> was used. A copy of the record is available at <a href="https://drive.google.com/open?id=1MEt3YiQfNxkCl75WSROWf1L5p9_f4FcD" class="uri">https://drive.google.com/open?id=1MEt3YiQfNxkCl75WSROWf1L5p9_f4FcD</a>.</p>
</div>
<div id="loading-the-libraries-and-the-data" class="section level1">
<h1>2 Loading the libraries and the data</h1>
<pre class="r"><code>import numpy as np
import pandas as pd

import statsmodels.api as sm
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
sns.set(style=&quot;white&quot;)
sns.set(style=&quot;whitegrid&quot;, color_codes=True)


from sklearn.model_selection import train_test_split


#for chapter 4.3  
from sklearn.feature_selection import RFE

#for chapter 4.3 and 6.2
from sklearn.linear_model import LogisticRegression

#for chapter 5
import statsmodels.api as sm

#for chapter 6.1
from imblearn.over_sampling import SMOTE

#for chapter 6.3
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.model_selection import cross_val_score</code></pre>
<pre class="r"><code>bank = pd.read_csv(&quot;bank.csv&quot;, sep = &#39;;&#39;)
bank = bank.rename(columns={&#39;y&#39;:&#39;final_subscribed&#39;})
bank.head().T</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p1.png" />

</div>
<p>Here we have a small overview of the variables from the data set to be analyzed. A detailed description of the variables is given at the end of this publication. Our target variable is <em>final_subscribed</em> which means whether a customer has finally signed or not.</p>
</div>
<div id="descriptive-statistics" class="section level1">
<h1>3 Descriptive statistics</h1>
</div>
<div id="mean-values-of-the-features" class="section level1">
<h1>3.1 Mean values of the features</h1>
<pre class="r"><code>#Overview of the mean values of the features grouped by final_subscribed
df = bank.groupby(&#39;final_subscribed&#39;).mean().T

#Compilation of the difference between the mean values
col_names = df.columns
df = pd.DataFrame(df, columns = col_names)
df[&#39;Score_diff&#39;] = df[&#39;no&#39;] - df[&#39;yes&#39;] 
df</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p2.png" />

</div>
<pre class="r"><code>#Filter for differences below -2 and above 2
threshold = [&#39;2&#39;, &#39;-2&#39;]
df[(df[&quot;Score_diff&quot;] &gt;= float(threshold[0])) | (df[&quot;Score_diff&quot;] &lt;= float(threshold[1]))]</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p3.png" />

</div>
</div>
<div id="description-of-the-target-variable" class="section level1">
<h1>3.2 Description of the target variable</h1>
<pre class="r"><code>sns.countplot(x=&#39;final_subscribed&#39;, data=bank, palette=&#39;hls&#39;)
print(plt.show())
print(bank[&#39;final_subscribed&#39;].value_counts())</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p4.png" />

</div>
<pre class="r"><code>#get percentage of male and female within our dataset

bank[&#39;final_subscribed&#39;].value_counts(normalize=True) * 100</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p5.png" />

</div>
</div>
<div id="description-of-the-predictor-variables" class="section level1">
<h1>3.3 Description of the predictor variables</h1>
<pre class="r"><code>%matplotlib inline
pd.crosstab(bank.job, bank.final_subscribed).plot(kind=&#39;bar&#39;)
plt.title(&#39;Subscription Frequency for Job Title&#39;)
plt.xlabel(&#39;Job&#39;)
plt.ylabel(&#39;Frequency of subscriptions&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p6.png" />

</div>
<p>The job title can be a good predictor for final subscription.</p>
<pre class="r"><code>%matplotlib inline
pd.crosstab(bank.day_of_week, bank.final_subscribed).plot(kind=&#39;bar&#39;)
plt.title(&#39;Subscription Frequency for Day of Week&#39;)
plt.xlabel(&#39;Day of Week&#39;)
plt.ylabel(&#39;Frequency of subscriptions&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p7.png" />

</div>
<p>Day of week may not be a good predictor of for final subscription.</p>
<pre class="r"><code>%matplotlib inline
pd.crosstab(bank.month, bank.final_subscribed).plot(kind=&#39;bar&#39;)
plt.title(&#39;Subscription Frequency for Month&#39;)
plt.xlabel(&#39;Month&#39;)
plt.ylabel(&#39;Frequency of subscriptions&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p8.png" />

</div>
<p>The month can be a good predictor for final subscription.</p>
<pre class="r"><code>%matplotlib inline
pd.crosstab(bank.education, bank.final_subscribed).plot(kind=&#39;bar&#39;)
plt.title(&#39;Subscription Frequency for Education&#39;)
plt.xlabel(&#39;Education&#39;)
plt.ylabel(&#39;Frequency of subscriptions&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p9.png" />

</div>
<p>The Education can be a good predictor for final subscription.</p>
<pre class="r"><code>bank.age.hist()
plt.title(&#39;Histogram of Age&#39;)
plt.xlabel(&#39;Age&#39;)
plt.ylabel(&#39;Frequency&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p10.png" />

</div>
<p>On the more detailed examination of the remaining variables is omitted in this post.</p>
</div>
<div id="data-pre-processing" class="section level1">
<h1>4 Data pre-processing</h1>
</div>
<div id="conversion-of-the-target-variable" class="section level1">
<h1>4.1 Conversion of the target variable</h1>
<pre class="r"><code>vals_to_replace = {&#39;no&#39;:&#39;0&#39;, &#39;yes&#39;:&#39;1&#39;}
bank[&#39;final_subscribed&#39;] = bank[&#39;final_subscribed&#39;].map(vals_to_replace)
bank[&#39;final_subscribed&#39;] = bank.final_subscribed.astype(&#39;int64&#39;)
bank.head()</code></pre>
<p>Now we have 0 and 1 as int64 for our target variable</p>
</div>
<div id="creation-of-dummy-variables" class="section level1">
<h1>4.2 Creation of dummy variables</h1>
<p>There are some categorical variables in the data set. A logistic regression model only works with numeric variables, so we have to convert the non-numeric ones to dummy variables. If you want to learn more about one-hot-encoding / dummy variables, read this post from me: <a href="https://michael-fuchs-python.netlify.com/2019/06/14/the-use-of-dummy-variables/">“The use of dummy variables”</a></p>
<pre class="r"><code>#Just select the categorical variables
cat_col = [&#39;object&#39;]
cat_columns = list(bank.select_dtypes(include=cat_col).columns)
cat_data = bank[cat_columns]
cat_vars = cat_data.columns

#Create dummy variables for each cat. variable
for var in cat_vars:
    cat_list = pd.get_dummies(bank[var], prefix=var)
    bank=bank.join(cat_list)

    
data_vars=bank.columns.values.tolist()
to_keep=[i for i in data_vars if i not in cat_vars]

#Create final dataframe
bank_final=bank[to_keep]
bank_final.columns.values</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p11.png" />

</div>
</div>
<div id="feature-selection" class="section level1">
<h1>4.3 Feature Selection</h1>
<p>Now we have created some new variables. However, not all are relevant for the planned classification. We use the Recursive Feature Elimination (RFE) algorithm to eliminate the redundant features.</p>
<pre class="r"><code>#Here we select 20 best features

x = bank_final.drop(&#39;final_subscribed&#39;, axis=1)
y = bank_final[&#39;final_subscribed&#39;]

trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)

model = LogisticRegression()
rfe = RFE(model, 20)
fit = rfe.fit(trainX, trainY)</code></pre>
<p>How the most important variables can be identified and assigned to an object is explained <a href="https://michael-fuchs-python.netlify.com/2019/09/27/wrapper-methods/">“here (chapter 4.2.3)”</a> step by step.</p>
<pre class="r"><code>Columns = x.columns
RFE_support = rfe.support_
RFE_ranking = rfe.ranking_

dataset = pd.DataFrame({&#39;Columns&#39;: Columns, &#39;RFE_support&#39;: RFE_support, &#39;RFE_ranking&#39;: RFE_ranking}, columns=[&#39;Columns&#39;, &#39;RFE_support&#39;, &#39;RFE_ranking&#39;])
df = dataset[(dataset[&quot;RFE_support&quot;] == True) &amp; (dataset[&quot;RFE_ranking&quot;] == 1)]
filtered_features = df[&#39;Columns&#39;]
filtered_features</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p12.png" />

</div>
<p>Eventually, the features identified as good will be assigned to a new x.</p>
<pre class="r"><code>new_train_x = trainX[filtered_features]
new_test_x = testX[filtered_features]</code></pre>
</div>
<div id="logistic-regression-with-the-statsmodel-library" class="section level1">
<h1>5 Logistic Regression with the statsmodel library</h1>
<p>With the regression model from the statsmodel library I would like to find out which of the remaining variables are significant.</p>
<pre class="r"><code>model = sm.Logit(trainY, new_train_x)
model_fit = model.fit()

print(model_fit.summary())</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p13.png" />

</div>
<p>All significant features (here alpha &lt;0.05) are selected and assigned to a new x.</p>
<pre class="r"><code>#Here we select just significant features


alpha = 0.05

#Creation of a dataframe with the features just used and the associated p-values 
#Filtering this dataframe for p-values &lt; alpha (here 0.05)
df = pd.DataFrame(model_fit.pvalues, columns=[&#39;p-value&#39;]).reset_index().rename(columns={&#39;index&#39;:&#39;features&#39;})
df = df[(df[&quot;p-value&quot;] &lt; alpha)]

#Storage of the remaining features in an obejct
filtered_features2 = df[&#39;features&#39;]

#Creation of a new train and test X
new_train_x2 = new_train_x[filtered_features2]
new_test_x2 = new_test_x[filtered_features2]</code></pre>
</div>
<div id="logistic-regression-with-scikit-learn" class="section level1">
<h1>6 Logistic Regression with scikit-learn</h1>
</div>
<div id="over-sampling-using-smote" class="section level1">
<h1>6.1 Over-sampling using SMOTE</h1>
<p>SMOTE is an over-sampling method and stands for Synthetic Minority Over-sampling Technique . What it does is, it creates synthetic (not duplicate) samples of the minority class. Hence making the minority class equal to the majority class. SMOTE does this by selecting similar records and altering that record one column at a time by a random amount within the difference to the neighbouring records.</p>
<p>There are two <strong>important points</strong> to note here:</p>
<ul>
<li><p>SMOTE is only applied to the training data.Because by oversampling only on the training data, none of the information in the test data is being used to create synthetic observations, therefore, no information will bleed from test data into the model training.</p></li>
<li><p>Do not use SMOTE before using feature selection methods. Performing variable selection after using SMOTE should be done with some care because most variable selection methods assume that the samples are independent.</p></li>
</ul>
<pre class="r"><code>columns_x = new_train_x2.columns


sm = SMOTE(random_state=0)
trainX_smote ,trainY_smote = sm.fit_sample(new_train_x2, trainY)

trainX_smote = pd.DataFrame(data=trainX_smote,columns=columns_x)
trainY_smote = pd.DataFrame(data=trainY_smote,columns=[&#39;final_subscribed&#39;])</code></pre>
<p>The previously imbalanced dataset is now balanced.</p>
<pre class="r"><code>print(&quot;Before OverSampling, counts of label &#39;1&#39;: {}&quot;.format(sum(trainY==1)))
print(&quot;Before OverSampling, counts of label &#39;0&#39;: {} \n&quot;.format(sum(trainY==0)))

print(&quot;After OverSampling, counts of label &#39;1&#39;:&quot;, trainY_smote[(trainY_smote[&quot;final_subscribed&quot;] == 1)].shape[0])
print(&quot;After OverSampling, counts of label &#39;0&#39;:&quot;, trainY_smote[(trainY_smote[&quot;final_subscribed&quot;] == 0)].shape[0])</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p14.png" />

</div>
<pre class="r"><code>sns.countplot(x=&#39;final_subscribed&#39;, data=trainY_smote, palette=&#39;hls&#39;)
print(plt.show())
print(&quot;Proportion of no subscription data in oversampled data is &quot;,len(trainY_smote[trainY_smote[&#39;final_subscribed&#39;]==0])/len(trainX_smote))
print(&quot;Proportion of subscription data in oversampled data is &quot;,len(trainY_smote[trainY_smote[&#39;final_subscribed&#39;]==1])/len(trainX_smote))</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p15.png" />

</div>
<p>The complete dataset has become bigger:</p>
<pre class="r"><code>print(&#39;Shape bevore OverSampling:&#39;)
print(&quot;Number of observations trainX dataset:&quot;, new_train_x2.shape[0])
print(&quot;Number of observations trainY dataset:&quot;, trainY.shape[0])


print(&#39;\nShape after OverSampling:&#39;)
print(&quot;Number of observations trainX_os dataset:&quot;, trainX_smote.shape[0])
print(&quot;Number of observations trainY_os dataset:&quot;, trainY_smote.shape[0])</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p16.png" />

</div>
</div>
<div id="model-fitting" class="section level1">
<h1>6.2 Model Fitting</h1>
<p>After all the selections of the features and creation of the synthetic samples, here again an overview of the train and test predictors as well as the train and test criterion. For a better overview, we assign the objects more descriptive / known names.</p>
<pre class="r"><code>trainX_final = trainX_smote
testX_final = new_test_x2
trainY_final = trainY_smote
testY_final = testY</code></pre>
<pre class="r"><code>logreg = LogisticRegression()
logreg.fit(trainX_final, trainY_final)

y_pred = logreg.predict(testX_final)</code></pre>
<p>Here is a nice overview of the features, their associated coefficients and odds ratios:</p>
<pre class="r"><code>coef = pd.DataFrame({&#39;features&#39;: trainX_final.columns, 
                     &#39;coef&#39;: logreg.coef_[0], 
                     &#39;odds_ratio&#39;: np.exp(logreg.coef_[0])})

coef[[&#39;features&#39;, &#39;coef&#39;, &#39;odds_ratio&#39;]]</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p17.png" />

</div>
</div>
<div id="model-evaluation" class="section level1">
<h1>6.3 Model evaluation</h1>
</div>
<div id="confusion-matrix" class="section level1">
<h1>6.3.1 Confusion matrix</h1>
<p>To evaluate classification models we usualy use a confusion matrix. This can be requested in python as follows:</p>
<pre class="r"><code>confusion_matrix = confusion_matrix(testY_final, y_pred)
print(confusion_matrix)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p19.png" />

</div>
<p>Or in this way (maybe a little more appealing):</p>
<pre class="r"><code>fig, ax = plt.subplots()

class_names=[0,1]
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=&quot;YlGnBu&quot; ,fmt=&#39;g&#39;)
ax.xaxis.set_label_position(&quot;top&quot;)
plt.tight_layout()
plt.title(&#39;Confusion matrix&#39;, y=1.1)
plt.ylabel(&#39;Actual label&#39;)
plt.xlabel(&#39;Predicted label&#39;)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p20.png" />

</div>
<p>But what does the confusion matrix tell us? To explain this we look at the following graphic:</p>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24s1.png" />

</div>
<ul>
<li><p>True Positives(TP)= are the cases in which we predicted yes they have subscibed and in reality, they do have subscription.</p></li>
<li><p>True Negative(TN)= are the cases in which we predicted no they don’t have subscibed and in reality, they don’t have subscription.</p></li>
<li><p>False Positive(FP) = are the cases in which we predicted yes they have subscibed and in reality, they don’t have subscription. This is also known as Type 1 Error.</p></li>
<li><p>False Negative(FN)= are the cases in which we predicted no they don’t have subscibed and in reality, they do have subscription. This is also known as the Type 2 Error.</p></li>
</ul>
</div>
<div id="further-metrics" class="section level1">
<h1>6.3.2 Further metrics</h1>
<p>Based on the values from the confusion matrix, the following metrics can be calculated:</p>
<pre class="r"><code>print(&#39;Accuracy: {:.2f}&#39;.format(accuracy_score(testY_final, y_pred)))
print(&#39;Error rate: {:.2f}&#39;.format(1 - accuracy_score(testY_final, y_pred)))
print(&#39;Precision: {:.2f}&#39;.format(precision_score(testY_final, y_pred)))
print(&#39;Recall: {:.2f}&#39;.format(recall_score(testY_final, y_pred)))
print(&#39;f1_score: {:.2f}&#39;.format(f1_score(testY_final, y_pred)))</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p18.png" />

</div>
<ul>
<li><p>Accuracy is the fraction of predictions our model got right.</p></li>
<li><p>Error rate is the fraction of predictions our model got wrong.</p></li>
<li><p>The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.</p></li>
<li><p>The recall is intuitively the ability of the classifier to find all the positive samples.</p></li>
<li><p>The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.</p></li>
</ul>
</div>
<div id="roc-auc" class="section level1">
<h1>6.3.3 ROC / AUC</h1>
<pre class="r"><code>logit_roc_auc = roc_auc_score(testY_final, logreg.predict(testX_final))
fpr, tpr, thresholds = roc_curve(testY_final, logreg.predict_proba(testX_final)[:,1])
plt.figure()
plt.plot(fpr, tpr, label=&#39;Logistic Regression (area = %0.2f)&#39; % logit_roc_auc)
plt.plot([0, 1], [0, 1],&#39;r--&#39;)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel(&#39;False Positive Rate&#39;)
plt.ylabel(&#39;True Positive Rate&#39;)
plt.title(&#39;Receiver operating characteristic ROC&#39;)
plt.legend(loc=&quot;lower right&quot;)

plt.show()</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p21.png" />

</div>
<p>The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. It shows the tradeoff between sensitivity and specificity. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible. This means that the top left corner of the chart is the “ideal” point - a false positive rate of zero and a true positive rate of one. This is not very realistic, but it means that a larger area under the curve (AUC) is usually better.</p>
<p>We can calculate AUC as follows:</p>
<pre class="r"><code>y_pred_proba = logreg.predict_proba(testX_final)[::,1]
roc_auc_score(testY_final, y_pred_proba)</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24p22.png" />

</div>
<p>AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier.</p>
</div>
<div id="cross-validation" class="section level1">
<h1>6.3.4 Cross Validation</h1>
<p>Another option for model evaluation is the use of Cross Validation (CV).</p>
<p>With CV we try to validate the stability of the machine learning model-how well it would generalize to new data. It needs to be sure that the model has got most of the patterns from the data correct, and its not picking up too much on the noise, or in other words its low on bias and variance.</p>
<p>Here is an overview how Cross Valitation works:</p>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24z1.png" />

</div>
<pre class="r"><code>clf = LogisticRegression()
scores = cross_val_score(clf, trainX_final, trainY_final, cv=5)
scores</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24z2.png" />

</div>
<p>We see that the accuracy values do not have a high variance. That’s good !</p>
<pre class="r"><code>print(&quot;Accuracy: %0.2f (+/- %0.2f)&quot; % (scores.mean(), scores.std() * 2))</code></pre>
<div class="figure">
<img src="/post/2019-10-31-introduction-to-logistic-regression_files/p24z3.png" />

</div>
</div>
<div id="conclusion" class="section level1">
<h1>7 Conclusion</h1>
<p>The logistic regression was the first classification algorithm that was dealt with in my posts. Although this algorithm is not one of the most complex of its kind, it is often used because of its simplicity and delivers very satisfactory values.</p>
</div>
<div id="description-of-the-dataframe" class="section level1">
<h1>8 Description of the dataframe</h1>
<p>Predictors variables:</p>
<ul>
<li>age (numeric)</li>
<li>job (categorical)</li>
<li>marital (categorical)</li>
<li>education (categorical)</li>
<li>default: has credit in default? (categorical: “no”, “yes”, “unknown”)</li>
<li>housing: has housing loan? (categorical: “no”, “yes”, “unknown”)</li>
<li>loan: has personal loan? (categorical: “no”, “yes”, “unknown”)</li>
<li>contact: contact communication type (categorical: “cellular”, “telephone”)</li>
<li>month: last contact month of year (categorical: “jan”, “feb”, “mar”, …, “nov”, “dec”)</li>
<li>day_of_week: last contact day of the week (categorical: “mon”, “tue”, “wed”, “thu”, “fri”)</li>
<li>duration: last contact duration, in seconds (numeric)</li>
<li>campaign: number of contacts performed during this campaign and for this client (numeric)</li>
<li>pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric)</li>
<li>previous: number of contacts performed before this campaign and for this client (numeric)</li>
<li>poutcome: outcome of the previous marketing campaign (categorical)</li>
<li>emp.var.rate: employment variation rate (numeric)</li>
<li>cons.price.idx: consumer price index (numeric)</li>
<li>cons.conf.idx: consumer confidence index (numeric)</li>
<li>euribor3m (numeric)</li>
<li>nr.employed (numeric)</li>
</ul>
<p>Target variable:</p>
<ul>
<li>final subscribed: has the client subscribed a term deposit? (binary: “1”, means “Yes”, “0” means “No”)</li>
</ul>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

