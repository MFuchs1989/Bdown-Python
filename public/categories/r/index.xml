<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Michael Fuchs Python</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Michael Fuchs Python</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Check for normal distribution</title>
      <link>/2019/09/13/check-for-normal-distribution/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/09/13/check-for-normal-distribution/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature Scaling with Scikit-Learn</title>
      <link>/2019/08/31/feature-scaling-with-scikit-learn/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/31/feature-scaling-with-scikit-learn/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Scaling methods3.1 Standard Scaler3.2 Min-Max Scaler3.3 Robust Scaler3.4 Comparison of the previously shown scaling methods4 Conclusion1 IntroductionFeature scaling can be an important part for many machine learning algorithms. It’s a step of data pre-processing which is applied to independent variables or features of data. It basically helps to normalise the data within a particular range.</description>
    </item>
    
    <item>
      <title>Dealing with outliers</title>
      <link>/2019/08/20/dealing-with-outliers/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/20/dealing-with-outliers/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Boxplots - Method4 Z-score method5 IQR method5.1 Detect outlier for column ‘age’5.2 Detect outlier for column ‘salary’5.3 Remove outlier from dataframe6 Conclusion1 IntroductionNext to “higly correlated” and “constant” features outlier detection is also a central element of data pre-processing.
In statistics, outliers are data points that do not belong to any particular population.</description>
    </item>
    
    <item>
      <title>Dealing with constant and duplicate features</title>
      <link>/2019/08/09/dealing-with-constant-and-duplicate-features/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/09/dealing-with-constant-and-duplicate-features/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Removing Constant features4 Removing Quasi-Constant features5 Removing Duplicate Features6 Conclusion1 IntroductionIn addition to “removing highly correlated features” as one of the data pre processing steps we also have to take care of constant and duplicate features. Constant features have a variance close to zero and duplicate features are too similar to other variables in the record.</description>
    </item>
    
    <item>
      <title>Dealing with highly correlated features</title>
      <link>/2019/07/28/dealing-with-highly-correlated-features/</link>
      <pubDate>Sun, 28 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/28/dealing-with-highly-correlated-features/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Preparation4 Correlations with the output variable5 Identification of highly correlated features6 Removing highly correlated features6.1 Selecting numerical variables6.2 Train / Test Split7 Conclusion1 IntroductionOne of the points to remember about data pre-processing for regression analysis is multicollinearity. This post is about finding highly correlated predictors within a dataframe.</description>
    </item>
    
    <item>
      <title>Non-linear regression analysis</title>
      <link>/2019/07/14/non-linear-regression-analysis/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/14/non-linear-regression-analysis/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Data Preparation4 Hypothesis: a non-linear relationship5 Linear model6 Non linear models6.1 Quadratic Function6.2 Exponential Function6.3 Logarithm Function6.4 Polynomials Function7 Conclusion1 IntroductionIn my previous post “Introduction to regression analysis and predictions” I showed how to create linear regression models. But what can be done if the data is not distributed linearly?</description>
    </item>
    
    <item>
      <title>Introduction to regression analysis and predictions</title>
      <link>/2019/06/28/introduction-to-regression-analysis-and-predictions/</link>
      <pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/28/introduction-to-regression-analysis-and-predictions/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Implementing linear regression with the statsmodel library3.1 Simple linear Regression3.2 Multiple Regression3.3 Model validation4 Linear Regression with scikit-learn5 Conclusion1 IntroductionRegression analyzes are very common and should therefore be mastered by every data scientist.
For this post the dataset House Sales in King County, USA from the statistic platform “Kaggle” was used.</description>
    </item>
    
    <item>
      <title>The use of dummy variables</title>
      <link>/2019/06/14/the-use-of-dummy-variables/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/14/the-use-of-dummy-variables/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Preparation of the dataframe4 How to create dummy variables5 Use dummy variables in a regression analysis6 Dummy variables with more than two characteristics7 Conclusion1 IntroductionIn a nutshell: a dummy variable is a numeric variable that represents categorical data. For example, if you want to calculate a linear regression, you need numerical predictors.</description>
    </item>
    
    <item>
      <title>The use of the groupby function</title>
      <link>/2019/05/30/the-use-of-the-groupby-function/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/30/the-use-of-the-groupby-function/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Group by3.1 with size3.2 with count3.2.1 Count Non - Zero Observations3.3 with sum3.4 with nunique3.5 with mean3.6 with agg.4 Conclusion1 IntroductionGoupby is one of the most used functions in data analysis. Therefore, it is worth to take a closer look at their functioning.
For this post the dataset flight from the statistic platform “Kaggle” was used.</description>
    </item>
    
    <item>
      <title>Random sampling</title>
      <link>/2019/05/16/random-sampling/</link>
      <pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/16/random-sampling/</guid>
      <description>Table of Content1 Introduction2 Preparation3 Method 1 - Customer Churn Model4 Method 2 - sklearn5 Conclusion1 IntroductionSplitting the dataset in training and testing the dataset is one operation every Data Scientist has to perform befor applying any models. The training dataset is the one on which the model is built and the testing dataset is used to check the accuracy of the model.</description>
    </item>
    
    <item>
      <title>NumPy. An intuition.</title>
      <link>/2019/05/07/numpy-an-intuition/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/07/numpy-an-intuition/</guid>
      <description>Table of Content1 Introduction2 Attributes of NumPy Arrays3 Indexing of Arrays3.1 Access to individual elements3.2 via Slicing3.3 Multidimensional subsets of an Array4 Reshape5 Concatenate Arrays6 Split Arrays7 UFuncs7.1 Array-Arithmetik7.2 Exponential function7.3 Logarithm7.4 Comparison operators8 Aggregation8.1 Multi-dimensional aggregation9 Timing of functions10 Conclusion1 IntroductionNumPy is a library of Python that makes it easy to handle vectors, matrices, or large multidimensional arrays in general.</description>
    </item>
    
    <item>
      <title>Pivot Tables with Python</title>
      <link>/2019/04/24/pivot-tables-with-python/</link>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/24/pivot-tables-with-python/</guid>
      <description>Table of Content1 Introduction2 Getting an overview of our data3 Categorizing the data by Year and Region4 Creating a multi-index pivot table5 Manipulating the data using aggfunc6 Applying a custom function to remove outlier7 Categorizing using string manipulation8 Conclusion1 IntroductionMany people like to work with pivot tables in Excel. This possibility also exists in Python.
For this post the dataset WorldHappinessReport from the statistic platform “Kaggle” was used.</description>
    </item>
    
    <item>
      <title>Data Management</title>
      <link>/2019/04/16/data-management/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/16/data-management/</guid>
      <description>Table of Content1 Introduction2 Join the two dataframes along rows3 Merge two dataframes3.1 Merge with inner join3.2 Merge with outer join4 Merge multiple data frames4.1 Preparation4.2 Merge up to 3 data frames4.3 Merge more than 3 data frames5 Conclusion1 IntroductionOne of the essential skills of a data scientist is to generate and bring together data from different sources.</description>
    </item>
    
    <item>
      <title>Python&#39;s Pipe - Operator</title>
      <link>/2019/04/04/python-s-pipe-operator/</link>
      <pubDate>Thu, 04 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/04/python-s-pipe-operator/</guid>
      <description>Table of Content1 Introduction2 Python’s Pipe - Operator like R’s %&amp;gt;%2.1 Filter and select2.2 Multiple filter and select2.3 Sample and sort2.4 Multiple group by and summarize2.5 Group by and multiple summarize3 Conclusion1 IntroductionAnyone who has ever worked with R probably knows the very useful pipe operator %&amp;gt;%. Python also has a similar one that will be presented in different versions below.</description>
    </item>
    
    <item>
      <title>String Manipulation. An intuition.</title>
      <link>/2019/03/27/string-manipulation-an-intuition/</link>
      <pubDate>Wed, 27 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/27/string-manipulation-an-intuition/</guid>
      <description>Table of Content1 Introduction2 Separate2.1 via map - function2.2 via string function3 Unite3.1 two columns3.2 three and more columns4 add_prefix5 add_suffix6 Conclusion1 IntroductionIt happens again and again that in the course of the planned analysis text variables are unfavorably filled and therefore have to be changed. Here are some useful build in methods for string manipulation from Python.</description>
    </item>
    
    <item>
      <title>Dealing with missing values</title>
      <link>/2019/03/18/dealing-with-missing-values/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/18/dealing-with-missing-values/</guid>
      <description>Table of Content1 Introduction2 Checking for missing values2.1 Missing Value Function3 Deletion of missing values4 Replace missings with values4.1 Variant 14.2 Variant 25 Replace values with missings5.1 Variant 15.2 Variant 26 Further imputations6.1 with mean6.2 with ffill6.3 with backfill7 Conclusion1 IntroductionIn the real world, there is virtually no record that has no missing values.</description>
    </item>
    
    <item>
      <title>Data Manipulation</title>
      <link>/2019/03/12/data-manipulation/</link>
      <pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/12/data-manipulation/</guid>
      <description>Table of Content1 Introduction2 Index2.1 Resetting index2.2 Resetting multiindex2.3 Setting index3 Modifying Columns3.1 Rename Columns3.1.1 add_prefix3.3 Add columns3.4 Drop and Delete Columns3.5 Insert Columns3.6 Rearrange Columns4 Modifying Rows4.1 Round each column4.2 Round columns differently within a df5 Replacing Values5.1 One by One5.2 Collective replacement6 Conclusion1 IntroductionData manipulation is an elementary component in the data science field that requires the most time, among other things.</description>
    </item>
    
    <item>
      <title>Add new columns</title>
      <link>/2019/03/06/add-new-columns/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/06/add-new-columns/</guid>
      <description>Table of Content1 Introduction2 Normal Calculation3 If-else statements4 Multiple If-else statements5 Row Sum6 With a defined list7 Conclusion1 IntroductionThere are several ways to generate new variables in Python. Below the most common methods will be shown.
For this post the dataset flight from the statistic platform “Kaggle” was used. A copy of the record is available at https://drive.google.com/open?id=1w3c818UAJW4VVqwYmgDIsn-b8WqcZQzL.</description>
    </item>
    
    <item>
      <title>Data Wrangling</title>
      <link>/2019/03/03/data-wrangling/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/03/data-wrangling/</guid>
      <description>Table of Content1 Introduction2 Loading the libraries and the data3 Overview of the data4 Get some statistics5 Select data5.1 Easy selection5.2 Conditional selection5.3 Set option6 Filter6.1 Normal filter6.2 Filter with a defined list6.3 Exclude some columns with a defined list7 Panda’s query8 Conclusion1 IntroductionNever stop learning !
The entry into the field of data science with “R / R-Studio” was a smart matter.</description>
    </item>
    
  </channel>
</rss>